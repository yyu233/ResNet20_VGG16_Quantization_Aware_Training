{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "radical-fifty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Building model...\n",
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (16): ReLU(inplace=True)\n",
      "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (19): ReLU(inplace=True)\n",
      "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (26): ReLU(inplace=True)\n",
      "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (32): ReLU(inplace=True)\n",
      "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (36): ReLU(inplace=True)\n",
      "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (39): ReLU(inplace=True)\n",
      "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (42): ReLU(inplace=True)\n",
      "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (44): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
      "  )\n",
      "  (classifier): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "     \n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from models import *\n",
    "\n",
    "\n",
    "global best_prec\n",
    "use_gpu = torch.cuda.is_available()\n",
    "print('=> Building model...')\n",
    "    \n",
    "    \n",
    "    \n",
    "batch_size = 128\n",
    "model_name = \"VGG16_loss2_with_gammar\"\n",
    "#model = VGG16_quant()\n",
    "#model_name = \"resnet20_quant\"\n",
    "model = VGG16()\n",
    "print(model)\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.491, 0.482, 0.447], std=[0.247, 0.243, 0.262])\n",
    "\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "print_freq = 100 # every 100 batches, accuracy printed. Here, each batch includes \"batch_size\" data points\n",
    "# CIFAR10 has 50,000 training data, and 10,000 validation data.\n",
    "\n",
    "def train(trainloader, model, criterion, optimizer, epoch):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(trainloader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        input, target = input.cuda(), target.cuda()\n",
    "\n",
    "        # compute output\n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec = accuracy(output, target)[0]\n",
    "        losses.update(loss.item(), input.size(0))\n",
    "        top1.update(prec.item(), input.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "\n",
    "        if i % print_freq == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec {top1.val:.3f}% ({top1.avg:.3f}%)'.format(\n",
    "                   epoch, i, len(trainloader), batch_time=batch_time,\n",
    "                   data_time=data_time, loss=losses, top1=top1))\n",
    "\n",
    "            \n",
    "\n",
    "def validate(val_loader, model, criterion ):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(val_loader):\n",
    "         \n",
    "            input, target = input.cuda(), target.cuda()\n",
    "\n",
    "            # compute output\n",
    "            output = model(input)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            prec = accuracy(output, target)[0]\n",
    "            losses.update(loss.item(), input.size(0))\n",
    "            top1.update(prec.item(), input.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % print_freq == 0:  # This line shows how frequently print out the status. e.g., i%5 => every 5 batch, prints out\n",
    "                print('Test: [{0}/{1}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec {top1.val:.3f}% ({top1.avg:.3f}%)'.format(\n",
    "                   i, len(val_loader), batch_time=batch_time, loss=losses,\n",
    "                   top1=top1))\n",
    "\n",
    "    print(' * Prec {top1.avg:.3f}% '.format(top1=top1))\n",
    "    return top1.avg\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "        \n",
    "def save_checkpoint(state, is_best, fdir):\n",
    "    filepath = os.path.join(fdir, 'checkpoint.pth')\n",
    "    torch.save(state, filepath)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filepath, os.path.join(fdir, 'model_best.pth.tar'))\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"For resnet, the lr starts from 0.1, and is divided by 10 at 80 and 120 epochs\"\"\"\n",
    "    #adjust_list = [150, 225]\n",
    "    adjust_list = [80, 120]\n",
    "    if epoch in adjust_list:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = param_group['lr'] * 0.1        \n",
    "\n",
    "#model = nn.DataParallel(model).cuda()\n",
    "#all_params = checkpoint['state_dict']\n",
    "#model.load_state_dict(all_params, strict=False)\n",
    "#criterion = nn.CrossEntropyLoss().cuda()\n",
    "#validate(testloader, model, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163a70fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85196996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Loss 2 with gammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1fe6196",
   "metadata": {},
   "outputs": [],
   "source": [
    "gammar = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9501359",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loss2(trainloader, model, criterion, optimizer, epoch):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(trainloader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        input, target = input.cuda(), target.cuda()\n",
    "\n",
    "        # compute output\n",
    "        output = model(input)\n",
    "        loss1 = criterion(output, target)\n",
    "        loss2 = model.features[0].weight.abs().sum()\n",
    "        loss = loss1 + gammar * loss2\n",
    "        \n",
    "        # measure accuracy and record loss\n",
    "        prec = accuracy(output, target)[0]\n",
    "        losses.update(loss.item(), input.size(0))\n",
    "        top1.update(prec.item(), input.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "\n",
    "        if i % print_freq == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec {top1.val:.3f}% ({top1.avg:.3f}%)'.format(\n",
    "                   epoch, i, len(trainloader), batch_time=batch_time,\n",
    "                   data_time=data_time, loss=losses, top1=top1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb3c8eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][0/391]\tTime 0.693 (0.693)\tData 0.543 (0.543)\tLoss 11.0525 (11.0525)\tPrec 3.906% (3.906%)\n",
      "Epoch: [0][100/391]\tTime 0.095 (0.100)\tData 0.001 (0.007)\tLoss 7.1221 (8.7832)\tPrec 11.719% (11.680%)\n",
      "Epoch: [0][200/391]\tTime 0.095 (0.097)\tData 0.002 (0.004)\tLoss 4.2916 (6.9747)\tPrec 24.219% (14.412%)\n",
      "Epoch: [0][300/391]\tTime 0.095 (0.097)\tData 0.001 (0.004)\tLoss 3.3388 (5.9401)\tPrec 25.781% (15.885%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.449 (0.449)\tLoss 2.4740 (2.4740)\tPrec 13.281% (13.281%)\n",
      " * Prec 12.540% \n",
      "best acc: 12.540000\n",
      "Epoch: [1][0/391]\tTime 0.595 (0.595)\tData 0.552 (0.552)\tLoss 4.3482 (4.3482)\tPrec 19.531% (19.531%)\n",
      "Epoch: [1][100/391]\tTime 0.094 (0.099)\tData 0.002 (0.007)\tLoss 3.2926 (3.8897)\tPrec 22.656% (20.343%)\n",
      "Epoch: [1][200/391]\tTime 0.094 (0.097)\tData 0.002 (0.004)\tLoss 2.9989 (3.7132)\tPrec 21.094% (21.311%)\n",
      "Epoch: [1][300/391]\tTime 0.094 (0.096)\tData 0.002 (0.004)\tLoss 3.5383 (3.6260)\tPrec 25.000% (21.810%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.417 (0.417)\tLoss 2.2027 (2.2027)\tPrec 14.844% (14.844%)\n",
      " * Prec 21.520% \n",
      "best acc: 21.520000\n",
      "Epoch: [2][0/391]\tTime 0.657 (0.657)\tData 0.616 (0.616)\tLoss 3.4750 (3.4750)\tPrec 21.875% (21.875%)\n",
      "Epoch: [2][100/391]\tTime 0.094 (0.100)\tData 0.001 (0.008)\tLoss 3.7850 (3.0793)\tPrec 40.625% (27.282%)\n",
      "Epoch: [2][200/391]\tTime 0.094 (0.097)\tData 0.002 (0.005)\tLoss 2.8029 (3.2340)\tPrec 39.062% (28.541%)\n",
      "Epoch: [2][300/391]\tTime 0.094 (0.096)\tData 0.002 (0.004)\tLoss 3.1212 (3.1790)\tPrec 36.719% (29.934%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.367 (0.367)\tLoss 2.3747 (2.3747)\tPrec 17.969% (17.969%)\n",
      " * Prec 19.990% \n",
      "best acc: 21.520000\n",
      "Epoch: [3][0/391]\tTime 0.699 (0.699)\tData 0.614 (0.614)\tLoss 2.8718 (2.8718)\tPrec 34.375% (34.375%)\n",
      "Epoch: [3][100/391]\tTime 0.094 (0.100)\tData 0.001 (0.008)\tLoss 2.7910 (2.9592)\tPrec 46.094% (37.299%)\n",
      "Epoch: [3][200/391]\tTime 0.095 (0.098)\tData 0.002 (0.005)\tLoss 2.9119 (3.0148)\tPrec 43.750% (37.959%)\n",
      "Epoch: [3][300/391]\tTime 0.094 (0.097)\tData 0.002 (0.004)\tLoss 2.4960 (2.9902)\tPrec 45.312% (38.829%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.481 (0.481)\tLoss 1.5771 (1.5771)\tPrec 42.188% (42.188%)\n",
      " * Prec 40.510% \n",
      "best acc: 40.510000\n",
      "Epoch: [4][0/391]\tTime 0.413 (0.413)\tData 0.370 (0.370)\tLoss 3.0877 (3.0877)\tPrec 39.844% (39.844%)\n",
      "Epoch: [4][100/391]\tTime 0.098 (0.098)\tData 0.002 (0.005)\tLoss 2.9346 (2.8227)\tPrec 40.625% (42.768%)\n",
      "Epoch: [4][200/391]\tTime 0.095 (0.096)\tData 0.002 (0.004)\tLoss 2.4630 (2.7372)\tPrec 38.281% (44.504%)\n",
      "Epoch: [4][300/391]\tTime 0.091 (0.096)\tData 0.002 (0.003)\tLoss 2.7176 (2.7444)\tPrec 42.969% (45.206%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.304 (0.304)\tLoss 1.6225 (1.6225)\tPrec 35.938% (35.938%)\n",
      " * Prec 40.090% \n",
      "best acc: 40.510000\n",
      "Epoch: [5][0/391]\tTime 0.818 (0.818)\tData 0.774 (0.774)\tLoss 2.3994 (2.3994)\tPrec 56.250% (56.250%)\n",
      "Epoch: [5][100/391]\tTime 0.093 (0.102)\tData 0.002 (0.009)\tLoss 3.4730 (2.5309)\tPrec 52.344% (51.307%)\n",
      "Epoch: [5][200/391]\tTime 0.095 (0.098)\tData 0.002 (0.005)\tLoss 3.7599 (3.6173)\tPrec 51.562% (51.901%)\n",
      "Epoch: [5][300/391]\tTime 0.095 (0.097)\tData 0.001 (0.004)\tLoss 2.3431 (3.3031)\tPrec 58.594% (52.738%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.573 (0.573)\tLoss 1.6223 (1.6223)\tPrec 44.531% (44.531%)\n",
      " * Prec 43.240% \n",
      "best acc: 43.240000\n",
      "Epoch: [6][0/391]\tTime 0.627 (0.627)\tData 0.579 (0.579)\tLoss 3.9803 (3.9803)\tPrec 53.906% (53.906%)\n",
      "Epoch: [6][100/391]\tTime 0.095 (0.100)\tData 0.002 (0.007)\tLoss 2.3951 (2.6002)\tPrec 56.250% (57.294%)\n",
      "Epoch: [6][200/391]\tTime 0.095 (0.097)\tData 0.002 (0.005)\tLoss 4.3771 (3.9939)\tPrec 66.406% (57.945%)\n",
      "Epoch: [6][300/391]\tTime 0.093 (0.096)\tData 0.002 (0.004)\tLoss 2.0636 (3.7247)\tPrec 66.406% (58.778%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.567 (0.567)\tLoss 1.2463 (1.2463)\tPrec 55.469% (55.469%)\n",
      " * Prec 56.860% \n",
      "best acc: 56.860000\n",
      "Epoch: [7][0/391]\tTime 0.602 (0.602)\tData 0.563 (0.563)\tLoss 2.0922 (2.0922)\tPrec 64.062% (64.062%)\n",
      "Epoch: [7][100/391]\tTime 0.095 (0.100)\tData 0.002 (0.007)\tLoss 2.0964 (2.1488)\tPrec 60.156% (63.266%)\n",
      "Epoch: [7][200/391]\tTime 0.092 (0.097)\tData 0.002 (0.005)\tLoss 1.8845 (2.1317)\tPrec 64.062% (63.689%)\n",
      "Epoch: [7][300/391]\tTime 0.096 (0.096)\tData 0.002 (0.004)\tLoss 1.9440 (2.0926)\tPrec 62.500% (63.956%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.286 (0.286)\tLoss 1.0211 (1.0211)\tPrec 65.625% (65.625%)\n",
      " * Prec 60.670% \n",
      "best acc: 60.670000\n",
      "Epoch: [8][0/391]\tTime 0.652 (0.652)\tData 0.613 (0.613)\tLoss 1.7926 (1.7926)\tPrec 74.219% (74.219%)\n",
      "Epoch: [8][100/391]\tTime 0.094 (0.100)\tData 0.002 (0.008)\tLoss 1.8514 (2.0303)\tPrec 64.844% (67.118%)\n",
      "Epoch: [8][200/391]\tTime 0.097 (0.097)\tData 0.004 (0.005)\tLoss 2.0986 (1.9344)\tPrec 71.094% (68.046%)\n",
      "Epoch: [8][300/391]\tTime 0.095 (0.097)\tData 0.002 (0.004)\tLoss 1.8552 (1.9296)\tPrec 65.625% (68.335%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 1.049 (1.049)\tLoss 0.8805 (0.8805)\tPrec 68.750% (68.750%)\n",
      " * Prec 66.340% \n",
      "best acc: 66.340000\n",
      "Epoch: [9][0/391]\tTime 0.618 (0.618)\tData 0.578 (0.578)\tLoss 1.6676 (1.6676)\tPrec 69.531% (69.531%)\n",
      "Epoch: [9][100/391]\tTime 0.095 (0.100)\tData 0.002 (0.007)\tLoss 1.8152 (1.8071)\tPrec 67.969% (71.496%)\n",
      "Epoch: [9][200/391]\tTime 0.095 (0.097)\tData 0.002 (0.005)\tLoss 1.6158 (1.7256)\tPrec 69.531% (72.077%)\n",
      "Epoch: [9][300/391]\tTime 0.095 (0.096)\tData 0.002 (0.004)\tLoss 1.7489 (1.7505)\tPrec 70.312% (71.987%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.367 (0.367)\tLoss 0.8443 (0.8443)\tPrec 73.438% (73.438%)\n",
      " * Prec 65.280% \n",
      "best acc: 66.340000\n",
      "Epoch: [10][0/391]\tTime 0.469 (0.469)\tData 0.432 (0.432)\tLoss 1.7388 (1.7388)\tPrec 74.219% (74.219%)\n",
      "Epoch: [10][100/391]\tTime 0.094 (0.098)\tData 0.002 (0.006)\tLoss 1.3930 (1.7298)\tPrec 82.031% (73.963%)\n",
      "Epoch: [10][200/391]\tTime 0.095 (0.097)\tData 0.002 (0.004)\tLoss 1.8258 (1.6250)\tPrec 68.750% (74.584%)\n",
      "Epoch: [10][300/391]\tTime 0.094 (0.096)\tData 0.002 (0.003)\tLoss 1.3738 (1.6228)\tPrec 85.938% (74.546%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.340 (0.340)\tLoss 1.7659 (1.7659)\tPrec 40.625% (40.625%)\n",
      " * Prec 42.770% \n",
      "best acc: 66.340000\n",
      "Epoch: [11][0/391]\tTime 0.664 (0.664)\tData 0.621 (0.621)\tLoss 1.6758 (1.6758)\tPrec 80.469% (80.469%)\n",
      "Epoch: [11][100/391]\tTime 0.095 (0.100)\tData 0.002 (0.008)\tLoss 1.2826 (1.4585)\tPrec 81.250% (76.802%)\n",
      "Epoch: [11][200/391]\tTime 0.095 (0.097)\tData 0.001 (0.005)\tLoss 1.4344 (1.4780)\tPrec 74.219% (76.912%)\n",
      "Epoch: [11][300/391]\tTime 0.095 (0.097)\tData 0.002 (0.004)\tLoss 3.3973 (1.7970)\tPrec 72.656% (76.591%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.766 (0.766)\tLoss 1.5240 (1.5240)\tPrec 50.000% (50.000%)\n",
      " * Prec 51.090% \n",
      "best acc: 66.340000\n",
      "Epoch: [12][0/391]\tTime 0.643 (0.643)\tData 0.576 (0.576)\tLoss 1.4319 (1.4319)\tPrec 79.688% (79.688%)\n",
      "Epoch: [12][100/391]\tTime 0.095 (0.100)\tData 0.001 (0.007)\tLoss 2.6159 (1.8371)\tPrec 76.562% (78.380%)\n",
      "Epoch: [12][200/391]\tTime 0.092 (0.097)\tData 0.001 (0.005)\tLoss 1.0987 (1.6830)\tPrec 82.812% (78.436%)\n",
      "Epoch: [12][300/391]\tTime 0.095 (0.096)\tData 0.002 (0.004)\tLoss 1.2309 (1.5682)\tPrec 78.906% (78.857%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.566 (0.566)\tLoss 0.5748 (0.5748)\tPrec 83.594% (83.594%)\n",
      " * Prec 76.820% \n",
      "best acc: 76.820000\n",
      "Epoch: [13][0/391]\tTime 0.597 (0.597)\tData 0.558 (0.558)\tLoss 1.2618 (1.2618)\tPrec 73.438% (73.438%)\n",
      "Epoch: [13][100/391]\tTime 0.094 (0.100)\tData 0.002 (0.007)\tLoss 1.3138 (1.4329)\tPrec 78.906% (79.858%)\n",
      "Epoch: [13][200/391]\tTime 0.094 (0.097)\tData 0.002 (0.005)\tLoss 1.1096 (1.3323)\tPrec 81.250% (79.750%)\n",
      "Epoch: [13][300/391]\tTime 0.097 (0.096)\tData 0.002 (0.004)\tLoss 1.3113 (1.3294)\tPrec 78.125% (79.957%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.425 (0.425)\tLoss 1.0284 (1.0284)\tPrec 64.844% (64.844%)\n",
      " * Prec 64.700% \n",
      "best acc: 76.820000\n",
      "Epoch: [14][0/391]\tTime 0.567 (0.567)\tData 0.528 (0.528)\tLoss 1.3430 (1.3430)\tPrec 74.219% (74.219%)\n",
      "Epoch: [14][100/391]\tTime 0.097 (0.099)\tData 0.002 (0.007)\tLoss 1.2120 (1.2046)\tPrec 77.344% (80.917%)\n",
      "Epoch: [14][200/391]\tTime 0.095 (0.097)\tData 0.002 (0.004)\tLoss 1.2208 (1.2120)\tPrec 78.906% (81.176%)\n",
      "Epoch: [14][300/391]\tTime 0.095 (0.096)\tData 0.002 (0.004)\tLoss 1.2033 (1.2020)\tPrec 75.781% (81.432%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.589 (0.589)\tLoss 0.6494 (0.6494)\tPrec 78.125% (78.125%)\n",
      " * Prec 76.060% \n",
      "best acc: 76.820000\n",
      "Epoch: [15][0/391]\tTime 0.522 (0.522)\tData 0.456 (0.456)\tLoss 1.1369 (1.1369)\tPrec 79.688% (79.688%)\n",
      "Epoch: [15][100/391]\tTime 0.095 (0.099)\tData 0.002 (0.006)\tLoss 1.1546 (1.1407)\tPrec 80.469% (83.099%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [15][200/391]\tTime 0.094 (0.097)\tData 0.001 (0.004)\tLoss 1.2951 (1.1507)\tPrec 78.125% (82.941%)\n",
      "Epoch: [15][300/391]\tTime 0.095 (0.096)\tData 0.002 (0.003)\tLoss 1.1410 (1.1483)\tPrec 84.375% (82.922%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.373 (0.373)\tLoss 0.7043 (0.7043)\tPrec 74.219% (74.219%)\n",
      " * Prec 69.870% \n",
      "best acc: 76.820000\n",
      "Epoch: [16][0/391]\tTime 0.650 (0.650)\tData 0.607 (0.607)\tLoss 1.2433 (1.2433)\tPrec 77.344% (77.344%)\n",
      "Epoch: [16][100/391]\tTime 0.094 (0.100)\tData 0.002 (0.008)\tLoss 1.0169 (1.0874)\tPrec 83.594% (83.973%)\n",
      "Epoch: [16][200/391]\tTime 0.095 (0.097)\tData 0.001 (0.005)\tLoss 1.0815 (1.4197)\tPrec 83.594% (83.151%)\n",
      "Epoch: [16][300/391]\tTime 0.095 (0.096)\tData 0.002 (0.004)\tLoss 2.6762 (1.3582)\tPrec 80.469% (83.282%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.313 (0.313)\tLoss 1.2721 (1.2721)\tPrec 59.375% (59.375%)\n",
      " * Prec 56.250% \n",
      "best acc: 76.820000\n",
      "Epoch: [17][0/391]\tTime 0.924 (0.924)\tData 0.884 (0.884)\tLoss 0.9231 (0.9231)\tPrec 89.062% (89.062%)\n",
      "Epoch: [17][100/391]\tTime 0.094 (0.103)\tData 0.002 (0.011)\tLoss 1.0118 (1.0393)\tPrec 86.719% (84.522%)\n",
      "Epoch: [17][200/391]\tTime 0.095 (0.099)\tData 0.002 (0.006)\tLoss 0.9414 (1.0315)\tPrec 87.500% (84.468%)\n",
      "Epoch: [17][300/391]\tTime 0.094 (0.097)\tData 0.002 (0.005)\tLoss 1.2003 (1.0363)\tPrec 82.031% (84.699%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.451 (0.451)\tLoss 0.7039 (0.7039)\tPrec 75.000% (75.000%)\n",
      " * Prec 72.130% \n",
      "best acc: 76.820000\n",
      "Epoch: [18][0/391]\tTime 0.600 (0.600)\tData 0.565 (0.565)\tLoss 0.8124 (0.8124)\tPrec 88.281% (88.281%)\n",
      "Epoch: [18][100/391]\tTime 0.095 (0.100)\tData 0.001 (0.007)\tLoss 1.3968 (1.0486)\tPrec 87.500% (85.744%)\n",
      "Epoch: [18][200/391]\tTime 0.092 (0.097)\tData 0.002 (0.005)\tLoss 1.0939 (1.0635)\tPrec 86.719% (85.483%)\n",
      "Epoch: [18][300/391]\tTime 0.092 (0.096)\tData 0.002 (0.004)\tLoss 0.9299 (1.0847)\tPrec 86.719% (85.058%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.536 (0.536)\tLoss 0.8446 (0.8446)\tPrec 75.000% (75.000%)\n",
      " * Prec 70.430% \n",
      "best acc: 76.820000\n",
      "Epoch: [19][0/391]\tTime 0.600 (0.600)\tData 0.551 (0.551)\tLoss 0.9191 (0.9191)\tPrec 86.719% (86.719%)\n",
      "Epoch: [19][100/391]\tTime 0.094 (0.100)\tData 0.002 (0.007)\tLoss 1.0063 (0.9431)\tPrec 85.938% (86.781%)\n",
      "Epoch: [19][200/391]\tTime 0.092 (0.097)\tData 0.002 (0.004)\tLoss 1.0464 (0.9855)\tPrec 86.719% (86.497%)\n",
      "Epoch: [19][300/391]\tTime 0.095 (0.096)\tData 0.002 (0.004)\tLoss 1.0601 (0.9855)\tPrec 84.375% (86.350%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.337 (0.337)\tLoss 0.6340 (0.6340)\tPrec 78.125% (78.125%)\n",
      " * Prec 78.200% \n",
      "best acc: 78.200000\n",
      "Epoch: [20][0/391]\tTime 0.608 (0.608)\tData 0.569 (0.569)\tLoss 1.0847 (1.0847)\tPrec 85.156% (85.156%)\n",
      "Epoch: [20][100/391]\tTime 0.095 (0.100)\tData 0.001 (0.007)\tLoss 0.9858 (0.9775)\tPrec 82.812% (87.098%)\n",
      "Epoch: [20][200/391]\tTime 0.094 (0.097)\tData 0.002 (0.004)\tLoss 1.2417 (1.0050)\tPrec 86.719% (86.796%)\n",
      "Epoch: [20][300/391]\tTime 0.095 (0.096)\tData 0.002 (0.004)\tLoss 0.9438 (1.0050)\tPrec 87.500% (86.685%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.823 (0.823)\tLoss 0.6683 (0.6683)\tPrec 77.344% (77.344%)\n",
      " * Prec 76.160% \n",
      "best acc: 78.200000\n",
      "Epoch: [21][0/391]\tTime 0.700 (0.700)\tData 0.656 (0.656)\tLoss 0.9075 (0.9075)\tPrec 90.625% (90.625%)\n",
      "Epoch: [21][100/391]\tTime 0.092 (0.100)\tData 0.002 (0.008)\tLoss 1.0199 (0.9892)\tPrec 88.281% (87.570%)\n",
      "Epoch: [21][200/391]\tTime 0.095 (0.098)\tData 0.001 (0.005)\tLoss 1.4011 (1.3390)\tPrec 85.938% (86.975%)\n",
      "Epoch: [21][300/391]\tTime 0.093 (0.097)\tData 0.002 (0.004)\tLoss 1.0186 (1.2368)\tPrec 85.938% (86.996%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.677 (0.677)\tLoss 0.8634 (0.8634)\tPrec 72.656% (72.656%)\n",
      " * Prec 67.860% \n",
      "best acc: 78.200000\n",
      "Epoch: [22][0/391]\tTime 0.601 (0.601)\tData 0.558 (0.558)\tLoss 0.9576 (0.9576)\tPrec 88.281% (88.281%)\n",
      "Epoch: [22][100/391]\tTime 0.095 (0.100)\tData 0.002 (0.007)\tLoss 0.8477 (0.9624)\tPrec 89.062% (87.570%)\n",
      "Epoch: [22][200/391]\tTime 0.095 (0.097)\tData 0.001 (0.004)\tLoss 1.1841 (0.9499)\tPrec 81.250% (87.706%)\n",
      "Epoch: [22][300/391]\tTime 0.095 (0.096)\tData 0.002 (0.004)\tLoss 0.9063 (0.9492)\tPrec 90.625% (87.819%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.411 (0.411)\tLoss 0.6845 (0.6845)\tPrec 74.219% (74.219%)\n",
      " * Prec 77.740% \n",
      "best acc: 78.200000\n",
      "Epoch: [23][0/391]\tTime 0.749 (0.749)\tData 0.708 (0.708)\tLoss 0.9662 (0.9662)\tPrec 82.031% (82.031%)\n",
      "Epoch: [23][100/391]\tTime 0.095 (0.101)\tData 0.002 (0.009)\tLoss 0.9762 (0.9795)\tPrec 82.812% (88.274%)\n",
      "Epoch: [23][200/391]\tTime 0.095 (0.098)\tData 0.002 (0.005)\tLoss 0.9763 (0.9574)\tPrec 84.375% (88.172%)\n",
      "Epoch: [23][300/391]\tTime 0.094 (0.097)\tData 0.002 (0.004)\tLoss 0.7861 (0.9417)\tPrec 89.844% (88.320%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.499 (0.499)\tLoss 0.4988 (0.4988)\tPrec 83.594% (83.594%)\n",
      " * Prec 79.210% \n",
      "best acc: 79.210000\n",
      "Epoch: [24][0/391]\tTime 0.819 (0.819)\tData 0.775 (0.775)\tLoss 0.9616 (0.9616)\tPrec 89.062% (89.062%)\n",
      "Epoch: [24][100/391]\tTime 0.094 (0.102)\tData 0.001 (0.009)\tLoss 0.9617 (0.8933)\tPrec 82.812% (89.179%)\n",
      "Epoch: [24][200/391]\tTime 0.100 (0.098)\tData 0.002 (0.006)\tLoss 0.8507 (0.8900)\tPrec 92.188% (89.082%)\n",
      "Epoch: [24][300/391]\tTime 0.094 (0.097)\tData 0.002 (0.004)\tLoss 0.9266 (0.8913)\tPrec 84.375% (88.992%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.288 (0.288)\tLoss 0.5195 (0.5195)\tPrec 81.250% (81.250%)\n",
      " * Prec 79.890% \n",
      "best acc: 79.890000\n",
      "Epoch: [25][0/391]\tTime 0.575 (0.575)\tData 0.532 (0.532)\tLoss 0.8196 (0.8196)\tPrec 88.281% (88.281%)\n",
      "Epoch: [25][100/391]\tTime 0.094 (0.099)\tData 0.002 (0.007)\tLoss 0.9645 (0.8685)\tPrec 86.719% (89.519%)\n",
      "Epoch: [25][200/391]\tTime 0.095 (0.097)\tData 0.002 (0.004)\tLoss 0.8410 (0.8790)\tPrec 86.719% (89.642%)\n",
      "Epoch: [25][300/391]\tTime 0.095 (0.096)\tData 0.002 (0.004)\tLoss 0.8783 (0.8946)\tPrec 89.062% (89.454%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.333 (0.333)\tLoss 0.8506 (0.8506)\tPrec 72.656% (72.656%)\n",
      " * Prec 72.610% \n",
      "best acc: 79.890000\n",
      "Epoch: [26][0/391]\tTime 0.767 (0.767)\tData 0.727 (0.727)\tLoss 1.1407 (1.1407)\tPrec 89.062% (89.062%)\n",
      "Epoch: [26][100/391]\tTime 0.092 (0.101)\tData 0.002 (0.009)\tLoss 1.2697 (1.0372)\tPrec 88.281% (89.898%)\n",
      "Epoch: [26][200/391]\tTime 0.095 (0.098)\tData 0.002 (0.005)\tLoss 0.9576 (1.0032)\tPrec 86.719% (89.665%)\n",
      "Epoch: [26][300/391]\tTime 0.097 (0.097)\tData 0.002 (0.004)\tLoss 0.7705 (0.9616)\tPrec 92.188% (89.672%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.371 (0.371)\tLoss 0.5248 (0.5248)\tPrec 84.375% (84.375%)\n",
      " * Prec 80.640% \n",
      "best acc: 80.640000\n",
      "Epoch: [27][0/391]\tTime 0.705 (0.705)\tData 0.661 (0.661)\tLoss 0.9450 (0.9450)\tPrec 84.375% (84.375%)\n",
      "Epoch: [27][100/391]\tTime 0.095 (0.101)\tData 0.002 (0.008)\tLoss 0.7295 (0.8347)\tPrec 90.625% (90.323%)\n",
      "Epoch: [27][200/391]\tTime 0.095 (0.098)\tData 0.002 (0.005)\tLoss 0.9341 (0.8437)\tPrec 89.844% (90.314%)\n",
      "Epoch: [27][300/391]\tTime 0.094 (0.097)\tData 0.002 (0.004)\tLoss 0.9590 (0.8622)\tPrec 92.188% (90.158%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.485 (0.485)\tLoss 0.6111 (0.6111)\tPrec 78.906% (78.906%)\n",
      " * Prec 81.420% \n",
      "best acc: 81.420000\n",
      "Epoch: [28][0/391]\tTime 0.901 (0.901)\tData 0.855 (0.855)\tLoss 0.8586 (0.8586)\tPrec 89.844% (89.844%)\n",
      "Epoch: [28][100/391]\tTime 0.096 (0.103)\tData 0.001 (0.010)\tLoss 0.7984 (0.8579)\tPrec 94.531% (91.182%)\n",
      "Epoch: [28][200/391]\tTime 0.095 (0.099)\tData 0.003 (0.006)\tLoss 0.7565 (0.8625)\tPrec 94.531% (90.617%)\n",
      "Epoch: [28][300/391]\tTime 0.286 (0.098)\tData 0.003 (0.005)\tLoss 1.0262 (0.8435)\tPrec 85.938% (90.661%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.518 (0.518)\tLoss 0.6652 (0.6652)\tPrec 75.781% (75.781%)\n",
      " * Prec 76.580% \n",
      "best acc: 81.420000\n",
      "Epoch: [29][0/391]\tTime 0.552 (0.552)\tData 0.483 (0.483)\tLoss 0.8670 (0.8670)\tPrec 89.844% (89.844%)\n",
      "Epoch: [29][100/391]\tTime 0.094 (0.099)\tData 0.001 (0.007)\tLoss 1.0479 (0.8059)\tPrec 89.844% (91.298%)\n",
      "Epoch: [29][200/391]\tTime 0.097 (0.097)\tData 0.001 (0.004)\tLoss 0.7606 (0.8224)\tPrec 90.625% (91.099%)\n",
      "Epoch: [29][300/391]\tTime 0.043 (0.096)\tData 0.003 (0.003)\tLoss 0.7284 (0.8371)\tPrec 93.750% (90.807%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.459 (0.459)\tLoss 0.8699 (0.8699)\tPrec 71.094% (71.094%)\n",
      " * Prec 75.240% \n",
      "best acc: 81.420000\n",
      "Epoch: [30][0/391]\tTime 0.613 (0.613)\tData 0.566 (0.566)\tLoss 0.7968 (0.7968)\tPrec 90.625% (90.625%)\n",
      "Epoch: [30][100/391]\tTime 0.095 (0.100)\tData 0.002 (0.007)\tLoss 0.9042 (0.8439)\tPrec 87.500% (91.182%)\n",
      "Epoch: [30][200/391]\tTime 0.087 (0.097)\tData 0.004 (0.004)\tLoss 0.8002 (0.8336)\tPrec 90.625% (91.262%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [30][300/391]\tTime 0.179 (0.097)\tData 0.003 (0.004)\tLoss 0.7298 (0.8354)\tPrec 95.312% (90.988%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.504 (0.504)\tLoss 1.5634 (1.5634)\tPrec 54.688% (54.688%)\n",
      " * Prec 55.510% \n",
      "best acc: 81.420000\n",
      "Epoch: [31][0/391]\tTime 0.838 (0.838)\tData 0.796 (0.796)\tLoss 0.8552 (0.8552)\tPrec 86.719% (86.719%)\n",
      "Epoch: [31][100/391]\tTime 0.095 (0.102)\tData 0.002 (0.010)\tLoss 0.8128 (0.7922)\tPrec 91.406% (91.515%)\n",
      "Epoch: [31][200/391]\tTime 0.097 (0.098)\tData 0.002 (0.006)\tLoss 0.7222 (0.8034)\tPrec 92.188% (91.659%)\n",
      "Epoch: [31][300/391]\tTime 0.094 (0.097)\tData 0.001 (0.004)\tLoss 1.1375 (0.8019)\tPrec 91.406% (91.629%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.344 (0.344)\tLoss 0.2977 (0.2977)\tPrec 90.625% (90.625%)\n",
      " * Prec 85.610% \n",
      "best acc: 85.610000\n",
      "Epoch: [32][0/391]\tTime 0.562 (0.562)\tData 0.519 (0.519)\tLoss 0.7619 (0.7619)\tPrec 91.406% (91.406%)\n",
      "Epoch: [32][100/391]\tTime 0.095 (0.099)\tData 0.002 (0.007)\tLoss 0.6973 (0.7988)\tPrec 94.531% (91.754%)\n",
      "Epoch: [32][200/391]\tTime 0.095 (0.097)\tData 0.002 (0.004)\tLoss 0.8016 (0.7910)\tPrec 92.188% (91.795%)\n",
      "Epoch: [32][300/391]\tTime 0.163 (0.096)\tData 0.002 (0.003)\tLoss 0.8611 (0.7982)\tPrec 95.312% (91.663%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.490 (0.490)\tLoss 0.5253 (0.5253)\tPrec 84.375% (84.375%)\n",
      " * Prec 82.750% \n",
      "best acc: 85.610000\n",
      "Epoch: [33][0/391]\tTime 0.670 (0.670)\tData 0.611 (0.611)\tLoss 0.7366 (0.7366)\tPrec 92.188% (92.188%)\n",
      "Epoch: [33][100/391]\tTime 0.095 (0.100)\tData 0.001 (0.008)\tLoss 0.7394 (0.9100)\tPrec 95.312% (92.118%)\n",
      "Epoch: [33][200/391]\tTime 0.094 (0.097)\tData 0.002 (0.005)\tLoss 0.7814 (0.8594)\tPrec 92.188% (92.335%)\n",
      "Epoch: [33][300/391]\tTime 0.155 (0.096)\tData 0.001 (0.004)\tLoss 0.7987 (0.8422)\tPrec 89.844% (92.063%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.420 (0.420)\tLoss 0.4425 (0.4425)\tPrec 83.594% (83.594%)\n",
      " * Prec 82.330% \n",
      "best acc: 85.610000\n",
      "Epoch: [34][0/391]\tTime 0.697 (0.697)\tData 0.654 (0.654)\tLoss 0.7239 (0.7239)\tPrec 92.969% (92.969%)\n",
      "Epoch: [34][100/391]\tTime 0.093 (0.101)\tData 0.001 (0.008)\tLoss 0.6606 (0.7701)\tPrec 91.406% (92.744%)\n",
      "Epoch: [34][200/391]\tTime 0.095 (0.098)\tData 0.002 (0.005)\tLoss 0.7209 (0.7869)\tPrec 93.750% (92.436%)\n",
      "Epoch: [34][300/391]\tTime 0.064 (0.096)\tData 0.002 (0.004)\tLoss 0.9049 (0.7925)\tPrec 88.281% (92.221%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.560 (0.560)\tLoss 0.6618 (0.6618)\tPrec 76.562% (76.562%)\n",
      " * Prec 77.970% \n",
      "best acc: 85.610000\n",
      "Epoch: [35][0/391]\tTime 0.871 (0.871)\tData 0.831 (0.831)\tLoss 1.1535 (1.1535)\tPrec 85.156% (85.156%)\n",
      "Epoch: [35][100/391]\tTime 0.095 (0.102)\tData 0.002 (0.010)\tLoss 0.6999 (0.7865)\tPrec 92.188% (92.976%)\n",
      "Epoch: [35][200/391]\tTime 0.094 (0.098)\tData 0.001 (0.006)\tLoss 0.7036 (0.7812)\tPrec 89.844% (92.732%)\n",
      "Epoch: [35][300/391]\tTime 0.098 (0.097)\tData 0.003 (0.005)\tLoss 0.6653 (0.7821)\tPrec 92.188% (92.600%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.388 (0.388)\tLoss 0.4588 (0.4588)\tPrec 85.156% (85.156%)\n",
      " * Prec 84.950% \n",
      "best acc: 85.610000\n",
      "Epoch: [36][0/391]\tTime 1.227 (1.227)\tData 1.188 (1.188)\tLoss 0.7182 (0.7182)\tPrec 95.312% (95.312%)\n",
      "Epoch: [36][100/391]\tTime 0.092 (0.106)\tData 0.001 (0.013)\tLoss 0.8274 (0.7254)\tPrec 88.281% (93.472%)\n",
      "Epoch: [36][200/391]\tTime 0.095 (0.100)\tData 0.001 (0.008)\tLoss 0.7654 (0.7369)\tPrec 95.312% (93.027%)\n",
      "Epoch: [36][300/391]\tTime 0.093 (0.098)\tData 0.002 (0.006)\tLoss 0.8379 (0.7581)\tPrec 85.938% (92.771%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.647 (0.647)\tLoss 0.5416 (0.5416)\tPrec 84.375% (84.375%)\n",
      " * Prec 80.660% \n",
      "best acc: 85.610000\n",
      "Epoch: [37][0/391]\tTime 0.465 (0.465)\tData 0.430 (0.430)\tLoss 0.7233 (0.7233)\tPrec 94.531% (94.531%)\n",
      "Epoch: [37][100/391]\tTime 0.094 (0.098)\tData 0.002 (0.006)\tLoss 0.6879 (1.3691)\tPrec 96.875% (90.447%)\n",
      "Epoch: [37][200/391]\tTime 0.095 (0.096)\tData 0.001 (0.004)\tLoss 0.7933 (1.0650)\tPrec 91.406% (91.632%)\n",
      "Epoch: [37][300/391]\tTime 0.081 (0.096)\tData 0.003 (0.003)\tLoss 0.8111 (0.9656)\tPrec 94.531% (92.190%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.615 (0.615)\tLoss 0.4957 (0.4957)\tPrec 86.719% (86.719%)\n",
      " * Prec 81.750% \n",
      "best acc: 85.610000\n",
      "Epoch: [38][0/391]\tTime 0.626 (0.626)\tData 0.583 (0.583)\tLoss 0.7014 (0.7014)\tPrec 95.312% (95.312%)\n",
      "Epoch: [38][100/391]\tTime 0.095 (0.100)\tData 0.002 (0.007)\tLoss 0.6731 (0.7519)\tPrec 98.438% (93.139%)\n",
      "Epoch: [38][200/391]\tTime 0.099 (0.097)\tData 0.002 (0.005)\tLoss 0.8443 (0.7526)\tPrec 90.625% (93.218%)\n",
      "Epoch: [38][300/391]\tTime 0.090 (0.096)\tData 0.001 (0.004)\tLoss 0.7537 (0.7548)\tPrec 92.969% (93.213%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.655 (0.655)\tLoss 0.9265 (0.9265)\tPrec 76.562% (76.562%)\n",
      " * Prec 77.320% \n",
      "best acc: 85.610000\n",
      "Epoch: [39][0/391]\tTime 0.613 (0.613)\tData 0.547 (0.547)\tLoss 0.9642 (0.9642)\tPrec 92.969% (92.969%)\n",
      "Epoch: [39][100/391]\tTime 0.095 (0.100)\tData 0.002 (0.007)\tLoss 0.7244 (0.7831)\tPrec 92.969% (93.178%)\n",
      "Epoch: [39][200/391]\tTime 0.095 (0.097)\tData 0.001 (0.004)\tLoss 0.6559 (0.7845)\tPrec 94.531% (93.144%)\n",
      "Epoch: [39][300/391]\tTime 0.090 (0.096)\tData 0.002 (0.004)\tLoss 0.7408 (0.7803)\tPrec 93.750% (93.101%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.454 (0.454)\tLoss 0.5518 (0.5518)\tPrec 81.250% (81.250%)\n",
      " * Prec 81.950% \n",
      "best acc: 85.610000\n",
      "Epoch: [40][0/391]\tTime 0.674 (0.674)\tData 0.628 (0.628)\tLoss 0.6485 (0.6485)\tPrec 94.531% (94.531%)\n",
      "Epoch: [40][100/391]\tTime 0.096 (0.100)\tData 0.002 (0.008)\tLoss 0.7651 (0.7170)\tPrec 91.406% (94.106%)\n",
      "Epoch: [40][200/391]\tTime 0.094 (0.097)\tData 0.001 (0.005)\tLoss 0.6510 (0.7329)\tPrec 95.312% (93.478%)\n",
      "Epoch: [40][300/391]\tTime 0.075 (0.096)\tData 0.002 (0.004)\tLoss 0.6850 (0.7310)\tPrec 92.969% (93.516%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.314 (0.314)\tLoss 0.6511 (0.6511)\tPrec 78.906% (78.906%)\n",
      " * Prec 77.750% \n",
      "best acc: 85.610000\n",
      "Epoch: [41][0/391]\tTime 0.512 (0.512)\tData 0.483 (0.483)\tLoss 0.6702 (0.6702)\tPrec 95.312% (95.312%)\n",
      "Epoch: [41][100/391]\tTime 0.047 (0.049)\tData 0.002 (0.006)\tLoss 0.6495 (0.7172)\tPrec 96.875% (94.144%)\n",
      "Epoch: [41][200/391]\tTime 0.048 (0.047)\tData 0.001 (0.004)\tLoss 0.6756 (0.7023)\tPrec 92.969% (94.092%)\n",
      "Epoch: [41][300/391]\tTime 0.044 (0.046)\tData 0.002 (0.003)\tLoss 0.8789 (0.7061)\tPrec 89.062% (93.807%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.523 (0.523)\tLoss 0.4742 (0.4742)\tPrec 86.719% (86.719%)\n",
      " * Prec 78.500% \n",
      "best acc: 85.610000\n",
      "Epoch: [42][0/391]\tTime 0.580 (0.580)\tData 0.553 (0.553)\tLoss 0.7353 (0.7353)\tPrec 99.219% (99.219%)\n",
      "Epoch: [42][100/391]\tTime 0.041 (0.050)\tData 0.002 (0.007)\tLoss 0.7460 (0.7290)\tPrec 92.188% (93.874%)\n",
      "Epoch: [42][200/391]\tTime 0.045 (0.047)\tData 0.002 (0.004)\tLoss 0.6600 (0.7333)\tPrec 96.875% (93.777%)\n",
      "Epoch: [42][300/391]\tTime 0.045 (0.046)\tData 0.001 (0.004)\tLoss 0.6415 (0.7284)\tPrec 97.656% (93.732%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.383 (0.383)\tLoss 0.6147 (0.6147)\tPrec 85.156% (85.156%)\n",
      " * Prec 80.470% \n",
      "best acc: 85.610000\n",
      "Epoch: [43][0/391]\tTime 0.462 (0.462)\tData 0.430 (0.430)\tLoss 0.6324 (0.6324)\tPrec 95.312% (95.312%)\n",
      "Epoch: [43][100/391]\tTime 0.045 (0.049)\tData 0.002 (0.006)\tLoss 0.7741 (0.6908)\tPrec 92.969% (94.315%)\n",
      "Epoch: [43][200/391]\tTime 0.045 (0.047)\tData 0.001 (0.004)\tLoss 0.7357 (0.6963)\tPrec 92.188% (94.213%)\n",
      "Epoch: [43][300/391]\tTime 0.045 (0.046)\tData 0.002 (0.003)\tLoss 1.1015 (0.7226)\tPrec 88.281% (93.859%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.516 (0.516)\tLoss 0.5060 (0.5060)\tPrec 85.156% (85.156%)\n",
      " * Prec 80.750% \n",
      "best acc: 85.610000\n",
      "Epoch: [44][0/391]\tTime 0.553 (0.553)\tData 0.524 (0.524)\tLoss 0.7222 (0.7222)\tPrec 93.750% (93.750%)\n",
      "Epoch: [44][100/391]\tTime 0.045 (0.050)\tData 0.002 (0.007)\tLoss 0.6935 (0.7015)\tPrec 94.531% (93.982%)\n",
      "Epoch: [44][200/391]\tTime 0.043 (0.047)\tData 0.001 (0.004)\tLoss 0.6941 (0.7074)\tPrec 96.875% (94.108%)\n",
      "Epoch: [44][300/391]\tTime 0.045 (0.046)\tData 0.001 (0.003)\tLoss 0.7438 (0.7146)\tPrec 93.750% (93.978%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.375 (0.375)\tLoss 0.8101 (0.8101)\tPrec 75.781% (75.781%)\n",
      " * Prec 77.670% \n",
      "best acc: 85.610000\n",
      "Epoch: [45][0/391]\tTime 0.502 (0.502)\tData 0.478 (0.478)\tLoss 0.7225 (0.7225)\tPrec 93.750% (93.750%)\n",
      "Epoch: [45][100/391]\tTime 0.045 (0.049)\tData 0.001 (0.006)\tLoss 0.6773 (0.6898)\tPrec 94.531% (94.462%)\n",
      "Epoch: [45][200/391]\tTime 0.045 (0.047)\tData 0.001 (0.004)\tLoss 0.5565 (0.6980)\tPrec 97.656% (94.325%)\n",
      "Epoch: [45][300/391]\tTime 0.045 (0.046)\tData 0.002 (0.003)\tLoss 0.6909 (0.7412)\tPrec 95.312% (94.090%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation starts\n",
      "Test: [0/79]\tTime 0.441 (0.441)\tLoss 0.3744 (0.3744)\tPrec 86.719% (86.719%)\n",
      " * Prec 83.560% \n",
      "best acc: 85.610000\n",
      "Epoch: [46][0/391]\tTime 0.626 (0.626)\tData 0.598 (0.598)\tLoss 0.6424 (0.6424)\tPrec 94.531% (94.531%)\n",
      "Epoch: [46][100/391]\tTime 0.045 (0.050)\tData 0.001 (0.008)\tLoss 0.6385 (0.6744)\tPrec 96.094% (95.003%)\n",
      "Epoch: [46][200/391]\tTime 0.043 (0.048)\tData 0.002 (0.005)\tLoss 0.6015 (0.6911)\tPrec 95.312% (94.648%)\n",
      "Epoch: [46][300/391]\tTime 0.045 (0.047)\tData 0.002 (0.004)\tLoss 0.6050 (0.7182)\tPrec 98.438% (94.243%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.327 (0.327)\tLoss 0.5044 (0.5044)\tPrec 82.031% (82.031%)\n",
      " * Prec 79.870% \n",
      "best acc: 85.610000\n",
      "Epoch: [47][0/391]\tTime 0.408 (0.408)\tData 0.386 (0.386)\tLoss 0.6509 (0.6509)\tPrec 92.969% (92.969%)\n",
      "Epoch: [47][100/391]\tTime 0.044 (0.048)\tData 0.002 (0.006)\tLoss 0.8112 (0.7405)\tPrec 93.750% (94.299%)\n",
      "Epoch: [47][200/391]\tTime 0.044 (0.046)\tData 0.002 (0.004)\tLoss 0.7551 (0.7212)\tPrec 91.406% (94.181%)\n",
      "Epoch: [47][300/391]\tTime 0.045 (0.046)\tData 0.002 (0.003)\tLoss 0.6602 (0.7250)\tPrec 93.750% (94.181%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.460 (0.460)\tLoss 1.1624 (1.1624)\tPrec 71.094% (71.094%)\n",
      " * Prec 69.210% \n",
      "best acc: 85.610000\n",
      "Epoch: [48][0/391]\tTime 0.564 (0.564)\tData 0.538 (0.538)\tLoss 0.7813 (0.7813)\tPrec 96.094% (96.094%)\n",
      "Epoch: [48][100/391]\tTime 0.045 (0.050)\tData 0.001 (0.007)\tLoss 0.7771 (0.6596)\tPrec 88.281% (94.972%)\n",
      "Epoch: [48][200/391]\tTime 0.048 (0.047)\tData 0.002 (0.004)\tLoss 0.6938 (0.7527)\tPrec 93.750% (94.586%)\n",
      "Epoch: [48][300/391]\tTime 0.045 (0.046)\tData 0.001 (0.003)\tLoss 0.6311 (0.7579)\tPrec 97.656% (94.420%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.298 (0.298)\tLoss 0.5450 (0.5450)\tPrec 85.156% (85.156%)\n",
      " * Prec 81.310% \n",
      "best acc: 85.610000\n",
      "Epoch: [49][0/391]\tTime 0.547 (0.547)\tData 0.523 (0.523)\tLoss 0.7888 (0.7888)\tPrec 94.531% (94.531%)\n",
      "Epoch: [49][100/391]\tTime 0.044 (0.050)\tData 0.001 (0.007)\tLoss 0.6641 (0.6476)\tPrec 93.750% (95.227%)\n",
      "Epoch: [49][200/391]\tTime 0.045 (0.047)\tData 0.001 (0.004)\tLoss 0.7504 (0.6725)\tPrec 96.875% (94.850%)\n",
      "Epoch: [49][300/391]\tTime 0.045 (0.046)\tData 0.001 (0.003)\tLoss 0.6690 (0.7005)\tPrec 93.750% (94.596%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.328 (0.328)\tLoss 0.3152 (0.3152)\tPrec 89.062% (89.062%)\n",
      " * Prec 85.090% \n",
      "best acc: 85.610000\n",
      "Epoch: [50][0/391]\tTime 0.596 (0.596)\tData 0.569 (0.569)\tLoss 0.6720 (0.6720)\tPrec 95.312% (95.312%)\n",
      "Epoch: [50][100/391]\tTime 0.045 (0.050)\tData 0.001 (0.007)\tLoss 0.6615 (0.7097)\tPrec 96.875% (95.135%)\n",
      "Epoch: [50][200/391]\tTime 0.045 (0.047)\tData 0.002 (0.005)\tLoss 0.6875 (0.6980)\tPrec 93.750% (95.118%)\n",
      "Epoch: [50][300/391]\tTime 0.045 (0.046)\tData 0.001 (0.004)\tLoss 0.6652 (0.6875)\tPrec 93.750% (94.962%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.606 (0.606)\tLoss 0.4786 (0.4786)\tPrec 84.375% (84.375%)\n",
      " * Prec 76.200% \n",
      "best acc: 85.610000\n",
      "Epoch: [51][0/391]\tTime 0.410 (0.410)\tData 0.365 (0.365)\tLoss 0.7116 (0.7116)\tPrec 97.656% (97.656%)\n",
      "Epoch: [51][100/391]\tTime 0.045 (0.048)\tData 0.001 (0.005)\tLoss 0.8897 (0.6357)\tPrec 92.188% (95.173%)\n",
      "Epoch: [51][200/391]\tTime 0.045 (0.047)\tData 0.002 (0.003)\tLoss 0.7079 (0.6930)\tPrec 95.312% (94.858%)\n",
      "Epoch: [51][300/391]\tTime 0.045 (0.046)\tData 0.002 (0.003)\tLoss 0.7652 (0.6881)\tPrec 93.750% (94.908%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.534 (0.534)\tLoss 0.5773 (0.5773)\tPrec 83.594% (83.594%)\n",
      " * Prec 82.930% \n",
      "best acc: 85.610000\n",
      "Epoch: [52][0/391]\tTime 0.486 (0.486)\tData 0.460 (0.460)\tLoss 0.5890 (0.5890)\tPrec 96.875% (96.875%)\n",
      "Epoch: [52][100/391]\tTime 0.044 (0.049)\tData 0.002 (0.006)\tLoss 0.7386 (0.7009)\tPrec 95.312% (94.926%)\n",
      "Epoch: [52][200/391]\tTime 0.045 (0.047)\tData 0.002 (0.004)\tLoss 0.9595 (0.7015)\tPrec 90.625% (94.834%)\n",
      "Epoch: [52][300/391]\tTime 0.044 (0.046)\tData 0.002 (0.003)\tLoss 0.6916 (0.7293)\tPrec 93.750% (94.666%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.313 (0.313)\tLoss 0.6569 (0.6569)\tPrec 86.719% (86.719%)\n",
      " * Prec 82.200% \n",
      "best acc: 85.610000\n",
      "Epoch: [53][0/391]\tTime 0.531 (0.531)\tData 0.508 (0.508)\tLoss 0.7696 (0.7696)\tPrec 92.969% (92.969%)\n",
      "Epoch: [53][100/391]\tTime 0.045 (0.050)\tData 0.002 (0.007)\tLoss 0.7159 (0.6612)\tPrec 96.875% (95.274%)\n",
      "Epoch: [53][200/391]\tTime 0.045 (0.047)\tData 0.002 (0.004)\tLoss 0.9719 (0.6691)\tPrec 93.750% (95.161%)\n",
      "Epoch: [53][300/391]\tTime 0.044 (0.046)\tData 0.002 (0.003)\tLoss 0.6391 (0.7645)\tPrec 96.875% (94.887%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.264 (0.264)\tLoss 1.0811 (1.0811)\tPrec 67.188% (67.188%)\n",
      " * Prec 68.990% \n",
      "best acc: 85.610000\n",
      "Epoch: [54][0/391]\tTime 0.721 (0.721)\tData 0.627 (0.627)\tLoss 0.6302 (0.6302)\tPrec 94.531% (94.531%)\n",
      "Epoch: [54][100/391]\tTime 0.045 (0.051)\tData 0.002 (0.008)\tLoss 0.7787 (0.7185)\tPrec 92.188% (94.872%)\n",
      "Epoch: [54][200/391]\tTime 0.045 (0.048)\tData 0.002 (0.005)\tLoss 0.7988 (0.6776)\tPrec 90.625% (95.184%)\n",
      "Epoch: [54][300/391]\tTime 0.045 (0.047)\tData 0.002 (0.004)\tLoss 0.6769 (0.6768)\tPrec 94.531% (94.988%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.552 (0.552)\tLoss 1.0550 (1.0550)\tPrec 71.094% (71.094%)\n",
      " * Prec 70.010% \n",
      "best acc: 85.610000\n",
      "Epoch: [55][0/391]\tTime 0.510 (0.510)\tData 0.487 (0.487)\tLoss 0.8006 (0.8006)\tPrec 94.531% (94.531%)\n",
      "Epoch: [55][100/391]\tTime 0.045 (0.049)\tData 0.002 (0.006)\tLoss 0.5500 (0.6354)\tPrec 99.219% (95.405%)\n",
      "Epoch: [55][200/391]\tTime 0.045 (0.047)\tData 0.002 (0.004)\tLoss 0.7004 (0.6619)\tPrec 94.531% (95.099%)\n",
      "Epoch: [55][300/391]\tTime 0.048 (0.046)\tData 0.001 (0.003)\tLoss 0.5555 (0.6707)\tPrec 95.312% (95.076%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.610 (0.610)\tLoss 1.1677 (1.1677)\tPrec 70.312% (70.312%)\n",
      " * Prec 74.310% \n",
      "best acc: 85.610000\n",
      "Epoch: [56][0/391]\tTime 0.644 (0.644)\tData 0.614 (0.614)\tLoss 0.7968 (0.7968)\tPrec 92.188% (92.188%)\n",
      "Epoch: [56][100/391]\tTime 0.045 (0.051)\tData 0.002 (0.008)\tLoss 0.5940 (0.6637)\tPrec 94.531% (95.746%)\n",
      "Epoch: [56][200/391]\tTime 0.048 (0.048)\tData 0.001 (0.005)\tLoss 0.8144 (0.6769)\tPrec 91.406% (95.406%)\n",
      "Epoch: [56][300/391]\tTime 0.045 (0.047)\tData 0.001 (0.004)\tLoss 0.6063 (0.6848)\tPrec 93.750% (95.170%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.501 (0.501)\tLoss 0.6142 (0.6142)\tPrec 82.031% (82.031%)\n",
      " * Prec 79.250% \n",
      "best acc: 85.610000\n",
      "Epoch: [57][0/391]\tTime 0.463 (0.463)\tData 0.437 (0.437)\tLoss 0.6880 (0.6880)\tPrec 94.531% (94.531%)\n",
      "Epoch: [57][100/391]\tTime 0.045 (0.049)\tData 0.001 (0.006)\tLoss 0.8342 (0.6363)\tPrec 92.969% (95.661%)\n",
      "Epoch: [57][200/391]\tTime 0.046 (0.047)\tData 0.002 (0.004)\tLoss 0.7655 (0.6544)\tPrec 96.094% (95.507%)\n",
      "Epoch: [57][300/391]\tTime 0.045 (0.046)\tData 0.002 (0.003)\tLoss 0.6576 (0.6487)\tPrec 95.312% (95.390%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.306 (0.306)\tLoss 0.3155 (0.3155)\tPrec 92.188% (92.188%)\n",
      " * Prec 86.790% \n",
      "best acc: 86.790000\n",
      "Epoch: [58][0/391]\tTime 0.704 (0.704)\tData 0.675 (0.675)\tLoss 0.5783 (0.5783)\tPrec 96.094% (96.094%)\n",
      "Epoch: [58][100/391]\tTime 0.045 (0.051)\tData 0.002 (0.008)\tLoss 0.6427 (0.6026)\tPrec 95.312% (95.753%)\n",
      "Epoch: [58][200/391]\tTime 0.046 (0.048)\tData 0.002 (0.005)\tLoss 0.6357 (0.6085)\tPrec 96.094% (95.884%)\n",
      "Epoch: [58][300/391]\tTime 0.045 (0.047)\tData 0.002 (0.004)\tLoss 0.6128 (0.6366)\tPrec 93.750% (95.673%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.291 (0.291)\tLoss 0.4765 (0.4765)\tPrec 84.375% (84.375%)\n",
      " * Prec 81.100% \n",
      "best acc: 86.790000\n",
      "Epoch: [59][0/391]\tTime 0.495 (0.495)\tData 0.466 (0.466)\tLoss 0.6369 (0.6369)\tPrec 96.094% (96.094%)\n",
      "Epoch: [59][100/391]\tTime 0.044 (0.049)\tData 0.002 (0.006)\tLoss 0.5970 (0.6393)\tPrec 93.750% (95.637%)\n",
      "Epoch: [59][200/391]\tTime 0.048 (0.047)\tData 0.001 (0.004)\tLoss 0.6987 (0.6326)\tPrec 95.312% (95.623%)\n",
      "Epoch: [59][300/391]\tTime 0.044 (0.046)\tData 0.002 (0.003)\tLoss 0.7108 (0.6426)\tPrec 96.875% (95.450%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.285 (0.285)\tLoss 0.5284 (0.5284)\tPrec 82.031% (82.031%)\n",
      " * Prec 79.030% \n",
      "best acc: 86.790000\n",
      "Epoch: [60][0/391]\tTime 0.517 (0.517)\tData 0.491 (0.491)\tLoss 0.8694 (0.8694)\tPrec 95.312% (95.312%)\n",
      "Epoch: [60][100/391]\tTime 0.045 (0.049)\tData 0.002 (0.006)\tLoss 0.6143 (0.6568)\tPrec 96.094% (95.722%)\n",
      "Epoch: [60][200/391]\tTime 0.046 (0.047)\tData 0.002 (0.004)\tLoss 0.5871 (0.6391)\tPrec 96.094% (95.522%)\n",
      "Epoch: [60][300/391]\tTime 0.044 (0.046)\tData 0.002 (0.003)\tLoss 1.0692 (0.6496)\tPrec 95.312% (95.518%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.264 (0.264)\tLoss 0.4336 (0.4336)\tPrec 89.062% (89.062%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Prec 86.300% \n",
      "best acc: 86.790000\n",
      "Epoch: [61][0/391]\tTime 0.469 (0.469)\tData 0.447 (0.447)\tLoss 0.6309 (0.6309)\tPrec 96.875% (96.875%)\n",
      "Epoch: [61][100/391]\tTime 0.044 (0.049)\tData 0.002 (0.006)\tLoss 0.6638 (0.6268)\tPrec 94.531% (95.993%)\n",
      "Epoch: [61][200/391]\tTime 0.044 (0.047)\tData 0.002 (0.004)\tLoss 1.2987 (0.6724)\tPrec 97.656% (95.787%)\n",
      "Epoch: [61][300/391]\tTime 0.045 (0.046)\tData 0.001 (0.003)\tLoss 0.5701 (0.7100)\tPrec 95.312% (95.694%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.445 (0.445)\tLoss 0.3692 (0.3692)\tPrec 87.500% (87.500%)\n",
      " * Prec 86.370% \n",
      "best acc: 86.790000\n",
      "Epoch: [62][0/391]\tTime 0.451 (0.451)\tData 0.425 (0.425)\tLoss 0.5555 (0.5555)\tPrec 98.438% (98.438%)\n",
      "Epoch: [62][100/391]\tTime 0.045 (0.049)\tData 0.002 (0.006)\tLoss 0.6546 (0.6181)\tPrec 95.312% (95.854%)\n",
      "Epoch: [62][200/391]\tTime 0.045 (0.047)\tData 0.002 (0.004)\tLoss 0.6577 (0.6320)\tPrec 95.312% (95.709%)\n",
      "Epoch: [62][300/391]\tTime 0.045 (0.046)\tData 0.002 (0.003)\tLoss 0.7157 (0.6533)\tPrec 92.188% (95.590%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.336 (0.336)\tLoss 0.3233 (0.3233)\tPrec 86.719% (86.719%)\n",
      " * Prec 84.920% \n",
      "best acc: 86.790000\n",
      "Epoch: [63][0/391]\tTime 0.442 (0.442)\tData 0.416 (0.416)\tLoss 0.6023 (0.6023)\tPrec 97.656% (97.656%)\n",
      "Epoch: [63][100/391]\tTime 0.045 (0.049)\tData 0.002 (0.006)\tLoss 0.6851 (0.6115)\tPrec 93.750% (96.001%)\n",
      "Epoch: [63][200/391]\tTime 0.044 (0.047)\tData 0.002 (0.004)\tLoss 0.5858 (0.6174)\tPrec 97.656% (95.896%)\n",
      "Epoch: [63][300/391]\tTime 0.045 (0.046)\tData 0.001 (0.003)\tLoss 0.9419 (0.6474)\tPrec 92.969% (95.637%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.370 (0.370)\tLoss 1.2227 (1.2227)\tPrec 67.188% (67.188%)\n",
      " * Prec 67.860% \n",
      "best acc: 86.790000\n",
      "Epoch: [64][0/391]\tTime 0.505 (0.505)\tData 0.480 (0.480)\tLoss 0.6033 (0.6033)\tPrec 96.875% (96.875%)\n",
      "Epoch: [64][100/391]\tTime 0.042 (0.049)\tData 0.001 (0.006)\tLoss 0.9161 (0.6262)\tPrec 95.312% (96.334%)\n",
      "Epoch: [64][200/391]\tTime 0.045 (0.047)\tData 0.002 (0.004)\tLoss 0.5862 (0.6318)\tPrec 95.312% (96.105%)\n",
      "Epoch: [64][300/391]\tTime 0.045 (0.046)\tData 0.002 (0.003)\tLoss 0.7404 (0.6555)\tPrec 93.750% (95.720%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.367 (0.367)\tLoss 0.8677 (0.8677)\tPrec 78.125% (78.125%)\n",
      " * Prec 76.530% \n",
      "best acc: 86.790000\n",
      "Epoch: [65][0/391]\tTime 0.610 (0.610)\tData 0.553 (0.553)\tLoss 0.6352 (0.6352)\tPrec 99.219% (99.219%)\n",
      "Epoch: [65][100/391]\tTime 0.044 (0.051)\tData 0.002 (0.007)\tLoss 0.6769 (0.6574)\tPrec 95.312% (96.140%)\n",
      "Epoch: [65][200/391]\tTime 0.045 (0.048)\tData 0.002 (0.005)\tLoss 0.6336 (0.6518)\tPrec 96.094% (95.892%)\n",
      "Epoch: [65][300/391]\tTime 0.044 (0.047)\tData 0.006 (0.004)\tLoss 0.7759 (0.6806)\tPrec 94.531% (95.762%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.580 (0.580)\tLoss 1.1650 (1.1650)\tPrec 71.875% (71.875%)\n",
      " * Prec 69.580% \n",
      "best acc: 86.790000\n",
      "Epoch: [66][0/391]\tTime 0.577 (0.577)\tData 0.551 (0.551)\tLoss 0.6233 (0.6233)\tPrec 95.312% (95.312%)\n",
      "Epoch: [66][100/391]\tTime 0.044 (0.050)\tData 0.002 (0.007)\tLoss 0.6538 (0.5956)\tPrec 94.531% (96.248%)\n",
      "Epoch: [66][200/391]\tTime 0.045 (0.047)\tData 0.002 (0.004)\tLoss 0.5345 (0.6144)\tPrec 99.219% (95.853%)\n",
      "Epoch: [66][300/391]\tTime 0.047 (0.046)\tData 0.002 (0.003)\tLoss 0.7069 (0.6342)\tPrec 91.406% (95.751%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.312 (0.312)\tLoss 0.4640 (0.4640)\tPrec 89.844% (89.844%)\n",
      " * Prec 85.300% \n",
      "best acc: 86.790000\n",
      "Epoch: [67][0/391]\tTime 0.811 (0.811)\tData 0.747 (0.747)\tLoss 0.6191 (0.6191)\tPrec 97.656% (97.656%)\n",
      "Epoch: [67][100/391]\tTime 0.045 (0.052)\tData 0.002 (0.009)\tLoss 0.6011 (0.5881)\tPrec 93.750% (96.218%)\n",
      "Epoch: [67][200/391]\tTime 0.045 (0.048)\tData 0.002 (0.006)\tLoss 0.6978 (0.6140)\tPrec 93.750% (95.829%)\n",
      "Epoch: [67][300/391]\tTime 0.051 (0.047)\tData 0.002 (0.004)\tLoss 0.7218 (0.6123)\tPrec 92.188% (95.728%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.347 (0.347)\tLoss 0.4512 (0.4512)\tPrec 85.938% (85.938%)\n",
      " * Prec 82.210% \n",
      "best acc: 86.790000\n",
      "Epoch: [68][0/391]\tTime 0.480 (0.480)\tData 0.456 (0.456)\tLoss 0.6854 (0.6854)\tPrec 96.875% (96.875%)\n",
      "Epoch: [68][100/391]\tTime 0.045 (0.049)\tData 0.002 (0.006)\tLoss 0.6257 (0.6060)\tPrec 95.312% (95.769%)\n",
      "Epoch: [68][200/391]\tTime 0.045 (0.047)\tData 0.002 (0.004)\tLoss 0.5362 (0.6142)\tPrec 99.219% (95.973%)\n",
      "Epoch: [68][300/391]\tTime 0.042 (0.046)\tData 0.002 (0.003)\tLoss 0.5898 (0.6219)\tPrec 100.000% (95.982%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.372 (0.372)\tLoss 0.8953 (0.8953)\tPrec 76.562% (76.562%)\n",
      " * Prec 78.910% \n",
      "best acc: 86.790000\n",
      "Epoch: [69][0/391]\tTime 0.532 (0.532)\tData 0.504 (0.504)\tLoss 0.5714 (0.5714)\tPrec 95.312% (95.312%)\n",
      "Epoch: [69][100/391]\tTime 0.045 (0.050)\tData 0.001 (0.006)\tLoss 0.6210 (0.6210)\tPrec 93.750% (96.341%)\n",
      "Epoch: [69][200/391]\tTime 0.045 (0.047)\tData 0.002 (0.004)\tLoss 0.5254 (0.6733)\tPrec 97.656% (96.102%)\n",
      "Epoch: [69][300/391]\tTime 0.045 (0.046)\tData 0.002 (0.003)\tLoss 0.6707 (0.6546)\tPrec 90.625% (95.993%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.364 (0.364)\tLoss 0.6710 (0.6710)\tPrec 80.469% (80.469%)\n",
      " * Prec 81.150% \n",
      "best acc: 86.790000\n",
      "Epoch: [70][0/391]\tTime 0.732 (0.732)\tData 0.701 (0.701)\tLoss 0.6040 (0.6040)\tPrec 96.094% (96.094%)\n",
      "Epoch: [70][100/391]\tTime 0.045 (0.051)\tData 0.002 (0.009)\tLoss 0.6659 (0.7076)\tPrec 96.094% (95.838%)\n",
      "Epoch: [70][200/391]\tTime 0.044 (0.048)\tData 0.001 (0.005)\tLoss 0.5935 (0.6763)\tPrec 96.094% (95.888%)\n",
      "Epoch: [70][300/391]\tTime 0.045 (0.047)\tData 0.002 (0.004)\tLoss 0.7537 (0.6771)\tPrec 96.094% (95.902%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.592 (0.592)\tLoss 0.4633 (0.4633)\tPrec 82.031% (82.031%)\n",
      " * Prec 81.420% \n",
      "best acc: 86.790000\n",
      "Epoch: [71][0/391]\tTime 0.547 (0.547)\tData 0.474 (0.474)\tLoss 0.6019 (0.6019)\tPrec 96.094% (96.094%)\n",
      "Epoch: [71][100/391]\tTime 0.045 (0.050)\tData 0.001 (0.007)\tLoss 0.6503 (0.6330)\tPrec 93.750% (96.573%)\n",
      "Epoch: [71][200/391]\tTime 0.044 (0.047)\tData 0.002 (0.004)\tLoss 0.6881 (0.6433)\tPrec 95.312% (96.191%)\n",
      "Epoch: [71][300/391]\tTime 0.046 (0.046)\tData 0.001 (0.003)\tLoss 0.6057 (0.6355)\tPrec 93.750% (95.993%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.235 (0.235)\tLoss 0.3950 (0.3950)\tPrec 85.938% (85.938%)\n",
      " * Prec 84.180% \n",
      "best acc: 86.790000\n",
      "Epoch: [72][0/391]\tTime 0.537 (0.537)\tData 0.510 (0.510)\tLoss 0.7561 (0.7561)\tPrec 97.656% (97.656%)\n",
      "Epoch: [72][100/391]\tTime 0.045 (0.050)\tData 0.002 (0.007)\tLoss 0.7853 (0.6227)\tPrec 95.312% (96.256%)\n",
      "Epoch: [72][200/391]\tTime 0.046 (0.047)\tData 0.002 (0.004)\tLoss 0.7106 (0.6384)\tPrec 96.094% (95.997%)\n",
      "Epoch: [72][300/391]\tTime 0.046 (0.046)\tData 0.002 (0.003)\tLoss 0.6478 (0.6322)\tPrec 96.094% (96.026%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.565 (0.565)\tLoss 0.3586 (0.3586)\tPrec 89.844% (89.844%)\n",
      " * Prec 86.590% \n",
      "best acc: 86.790000\n",
      "Epoch: [73][0/391]\tTime 0.795 (0.795)\tData 0.766 (0.766)\tLoss 0.6172 (0.6172)\tPrec 96.875% (96.875%)\n",
      "Epoch: [73][100/391]\tTime 0.043 (0.052)\tData 0.001 (0.009)\tLoss 0.6727 (0.6515)\tPrec 96.094% (96.055%)\n",
      "Epoch: [73][200/391]\tTime 0.044 (0.048)\tData 0.001 (0.005)\tLoss 0.5786 (0.6602)\tPrec 98.438% (96.016%)\n",
      "Epoch: [73][300/391]\tTime 0.046 (0.047)\tData 0.001 (0.004)\tLoss 0.6859 (0.6478)\tPrec 94.531% (96.055%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.483 (0.483)\tLoss 0.6211 (0.6211)\tPrec 82.812% (82.812%)\n",
      " * Prec 83.300% \n",
      "best acc: 86.790000\n",
      "Epoch: [74][0/391]\tTime 0.440 (0.440)\tData 0.399 (0.399)\tLoss 0.6077 (0.6077)\tPrec 98.438% (98.438%)\n",
      "Epoch: [74][100/391]\tTime 0.045 (0.049)\tData 0.002 (0.006)\tLoss 0.5807 (0.5864)\tPrec 97.656% (96.689%)\n",
      "Epoch: [74][200/391]\tTime 0.045 (0.047)\tData 0.002 (0.004)\tLoss 0.6543 (0.6305)\tPrec 96.094% (96.187%)\n",
      "Epoch: [74][300/391]\tTime 0.045 (0.046)\tData 0.001 (0.003)\tLoss 0.6245 (0.7129)\tPrec 97.656% (96.016%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.435 (0.435)\tLoss 0.3534 (0.3534)\tPrec 86.719% (86.719%)\n",
      " * Prec 83.110% \n",
      "best acc: 86.790000\n",
      "Epoch: [75][0/391]\tTime 0.605 (0.605)\tData 0.576 (0.576)\tLoss 0.5856 (0.5856)\tPrec 95.312% (95.312%)\n",
      "Epoch: [75][100/391]\tTime 0.046 (0.050)\tData 0.001 (0.007)\tLoss 1.8228 (0.6804)\tPrec 96.094% (96.218%)\n",
      "Epoch: [75][200/391]\tTime 0.045 (0.047)\tData 0.002 (0.004)\tLoss 0.6078 (1.0502)\tPrec 96.875% (96.210%)\n",
      "Epoch: [75][300/391]\tTime 0.045 (0.046)\tData 0.002 (0.004)\tLoss 0.5809 (0.9058)\tPrec 93.750% (96.198%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.453 (0.453)\tLoss 0.8547 (0.8547)\tPrec 80.469% (80.469%)\n",
      " * Prec 74.890% \n",
      "best acc: 86.790000\n",
      "Epoch: [76][0/391]\tTime 0.777 (0.777)\tData 0.747 (0.747)\tLoss 0.7012 (0.7012)\tPrec 93.750% (93.750%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [76][100/391]\tTime 0.045 (0.052)\tData 0.002 (0.009)\tLoss 0.7374 (0.7126)\tPrec 92.969% (96.117%)\n",
      "Epoch: [76][200/391]\tTime 0.045 (0.048)\tData 0.002 (0.005)\tLoss 0.6524 (0.6812)\tPrec 94.531% (96.098%)\n",
      "Epoch: [76][300/391]\tTime 0.044 (0.047)\tData 0.002 (0.004)\tLoss 0.6990 (0.6625)\tPrec 92.969% (96.135%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.378 (0.378)\tLoss 0.5926 (0.5926)\tPrec 82.812% (82.812%)\n",
      " * Prec 81.680% \n",
      "best acc: 86.790000\n",
      "Epoch: [77][0/391]\tTime 0.419 (0.419)\tData 0.390 (0.390)\tLoss 1.0634 (1.0634)\tPrec 92.969% (92.969%)\n",
      "Epoch: [77][100/391]\tTime 0.045 (0.048)\tData 0.002 (0.005)\tLoss 0.5921 (0.7025)\tPrec 95.312% (96.295%)\n",
      "Epoch: [77][200/391]\tTime 0.045 (0.046)\tData 0.002 (0.004)\tLoss 0.5894 (0.6357)\tPrec 97.656% (96.323%)\n",
      "Epoch: [77][300/391]\tTime 0.045 (0.046)\tData 0.001 (0.003)\tLoss 0.6405 (0.6451)\tPrec 96.094% (96.260%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.241 (0.241)\tLoss 0.5503 (0.5503)\tPrec 85.938% (85.938%)\n",
      " * Prec 83.730% \n",
      "best acc: 86.790000\n",
      "Epoch: [78][0/391]\tTime 0.604 (0.604)\tData 0.568 (0.568)\tLoss 0.5753 (0.5753)\tPrec 97.656% (97.656%)\n",
      "Epoch: [78][100/391]\tTime 0.045 (0.050)\tData 0.002 (0.007)\tLoss 0.5648 (0.5749)\tPrec 95.312% (96.550%)\n",
      "Epoch: [78][200/391]\tTime 0.045 (0.047)\tData 0.001 (0.005)\tLoss 0.5467 (0.5877)\tPrec 97.656% (96.315%)\n",
      "Epoch: [78][300/391]\tTime 0.045 (0.047)\tData 0.002 (0.004)\tLoss 0.6989 (0.6035)\tPrec 97.656% (96.179%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.376 (0.376)\tLoss 0.9904 (0.9904)\tPrec 75.000% (75.000%)\n",
      " * Prec 76.660% \n",
      "best acc: 86.790000\n",
      "Epoch: [79][0/391]\tTime 0.704 (0.704)\tData 0.681 (0.681)\tLoss 0.7246 (0.7246)\tPrec 96.094% (96.094%)\n",
      "Epoch: [79][100/391]\tTime 0.045 (0.051)\tData 0.001 (0.008)\tLoss 0.6101 (0.5812)\tPrec 93.750% (96.767%)\n",
      "Epoch: [79][200/391]\tTime 0.044 (0.048)\tData 0.002 (0.005)\tLoss 0.5371 (0.5840)\tPrec 97.656% (96.688%)\n",
      "Epoch: [79][300/391]\tTime 0.045 (0.047)\tData 0.002 (0.004)\tLoss 0.6121 (0.6180)\tPrec 95.312% (96.374%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.393 (0.393)\tLoss 0.6820 (0.6820)\tPrec 84.375% (84.375%)\n",
      " * Prec 78.800% \n",
      "best acc: 86.790000\n",
      "Epoch: [80][0/391]\tTime 0.518 (0.518)\tData 0.489 (0.489)\tLoss 0.5411 (0.5411)\tPrec 99.219% (99.219%)\n",
      "Epoch: [80][100/391]\tTime 0.045 (0.049)\tData 0.001 (0.007)\tLoss 0.1707 (0.2147)\tPrec 97.656% (97.981%)\n",
      "Epoch: [80][200/391]\tTime 0.048 (0.047)\tData 0.001 (0.004)\tLoss 0.1737 (0.1865)\tPrec 98.438% (98.220%)\n",
      "Epoch: [80][300/391]\tTime 0.045 (0.046)\tData 0.002 (0.003)\tLoss 0.1887 (0.1764)\tPrec 98.438% (98.365%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.318 (0.318)\tLoss 0.2343 (0.2343)\tPrec 90.625% (90.625%)\n",
      " * Prec 88.890% \n",
      "best acc: 88.890000\n",
      "Epoch: [81][0/391]\tTime 0.740 (0.740)\tData 0.716 (0.716)\tLoss 0.1536 (0.1536)\tPrec 99.219% (99.219%)\n",
      "Epoch: [81][100/391]\tTime 0.047 (0.052)\tData 0.002 (0.009)\tLoss 0.1319 (0.1625)\tPrec 98.438% (98.909%)\n",
      "Epoch: [81][200/391]\tTime 0.047 (0.048)\tData 0.002 (0.005)\tLoss 0.1548 (0.1539)\tPrec 99.219% (98.927%)\n",
      "Epoch: [81][300/391]\tTime 0.045 (0.047)\tData 0.002 (0.004)\tLoss 0.1440 (0.1592)\tPrec 100.000% (98.858%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.250 (0.250)\tLoss 1.0941 (1.0941)\tPrec 71.875% (71.875%)\n",
      " * Prec 70.000% \n",
      "best acc: 88.890000\n",
      "Epoch: [82][0/391]\tTime 0.420 (0.420)\tData 0.391 (0.391)\tLoss 0.2562 (0.2562)\tPrec 97.656% (97.656%)\n",
      "Epoch: [82][100/391]\tTime 0.044 (0.048)\tData 0.002 (0.005)\tLoss 0.1533 (0.2011)\tPrec 98.438% (98.871%)\n",
      "Epoch: [82][200/391]\tTime 0.045 (0.047)\tData 0.002 (0.003)\tLoss 0.1971 (0.1700)\tPrec 97.656% (98.993%)\n",
      "Epoch: [82][300/391]\tTime 0.044 (0.046)\tData 0.002 (0.003)\tLoss 0.1652 (0.1646)\tPrec 99.219% (99.009%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.407 (0.407)\tLoss 0.4858 (0.4858)\tPrec 85.938% (85.938%)\n",
      " * Prec 86.990% \n",
      "best acc: 88.890000\n",
      "Epoch: [83][0/391]\tTime 0.509 (0.509)\tData 0.452 (0.452)\tLoss 0.1914 (0.1914)\tPrec 98.438% (98.438%)\n",
      "Epoch: [83][100/391]\tTime 0.045 (0.049)\tData 0.001 (0.006)\tLoss 0.1125 (0.1402)\tPrec 100.000% (99.226%)\n",
      "Epoch: [83][200/391]\tTime 0.045 (0.047)\tData 0.002 (0.004)\tLoss 0.1551 (0.1368)\tPrec 98.438% (99.207%)\n",
      "Epoch: [83][300/391]\tTime 0.045 (0.046)\tData 0.002 (0.003)\tLoss 0.1568 (0.1386)\tPrec 98.438% (99.177%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.249 (0.249)\tLoss 0.4647 (0.4647)\tPrec 89.062% (89.062%)\n",
      " * Prec 87.010% \n",
      "best acc: 88.890000\n",
      "Epoch: [84][0/391]\tTime 0.638 (0.638)\tData 0.610 (0.610)\tLoss 0.1323 (0.1323)\tPrec 98.438% (98.438%)\n",
      "Epoch: [84][100/391]\tTime 0.045 (0.051)\tData 0.002 (0.008)\tLoss 0.1254 (0.1289)\tPrec 99.219% (99.335%)\n",
      "Epoch: [84][200/391]\tTime 0.045 (0.048)\tData 0.002 (0.005)\tLoss 0.1471 (0.1351)\tPrec 98.438% (99.215%)\n",
      "Epoch: [84][300/391]\tTime 0.045 (0.047)\tData 0.002 (0.004)\tLoss 0.1428 (0.1371)\tPrec 96.875% (99.216%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.286 (0.286)\tLoss 0.2741 (0.2741)\tPrec 91.406% (91.406%)\n",
      " * Prec 88.310% \n",
      "best acc: 88.890000\n",
      "Epoch: [85][0/391]\tTime 0.473 (0.473)\tData 0.446 (0.446)\tLoss 0.1524 (0.1524)\tPrec 99.219% (99.219%)\n",
      "Epoch: [85][100/391]\tTime 0.044 (0.049)\tData 0.002 (0.006)\tLoss 0.1279 (0.1496)\tPrec 99.219% (99.327%)\n",
      "Epoch: [85][200/391]\tTime 0.045 (0.047)\tData 0.002 (0.004)\tLoss 0.1068 (0.1376)\tPrec 99.219% (99.328%)\n",
      "Epoch: [85][300/391]\tTime 0.045 (0.046)\tData 0.001 (0.003)\tLoss 0.1088 (0.1389)\tPrec 100.000% (99.336%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.384 (0.384)\tLoss 0.3844 (0.3844)\tPrec 88.281% (88.281%)\n",
      " * Prec 88.880% \n",
      "best acc: 88.890000\n",
      "Epoch: [86][0/391]\tTime 0.615 (0.615)\tData 0.586 (0.586)\tLoss 0.1757 (0.1757)\tPrec 96.875% (96.875%)\n",
      "Epoch: [86][100/391]\tTime 0.045 (0.050)\tData 0.002 (0.007)\tLoss 0.1451 (0.1362)\tPrec 99.219% (99.397%)\n",
      "Epoch: [86][200/391]\tTime 0.044 (0.047)\tData 0.002 (0.004)\tLoss 0.2156 (0.1377)\tPrec 96.094% (99.335%)\n",
      "Epoch: [86][300/391]\tTime 0.045 (0.046)\tData 0.002 (0.004)\tLoss 0.1222 (0.1324)\tPrec 100.000% (99.354%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.299 (0.299)\tLoss 0.6570 (0.6570)\tPrec 85.938% (85.938%)\n",
      " * Prec 85.240% \n",
      "best acc: 88.890000\n",
      "Epoch: [87][0/391]\tTime 0.627 (0.627)\tData 0.595 (0.595)\tLoss 0.2357 (0.2357)\tPrec 100.000% (100.000%)\n",
      "Epoch: [87][100/391]\tTime 0.044 (0.050)\tData 0.002 (0.007)\tLoss 0.1914 (0.1810)\tPrec 99.219% (99.296%)\n",
      "Epoch: [87][200/391]\tTime 0.045 (0.047)\tData 0.001 (0.005)\tLoss 0.2309 (0.1772)\tPrec 98.438% (99.308%)\n",
      "Epoch: [87][300/391]\tTime 0.045 (0.047)\tData 0.002 (0.004)\tLoss 0.1091 (0.1754)\tPrec 100.000% (99.299%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.593 (0.593)\tLoss 0.1920 (0.1920)\tPrec 93.750% (93.750%)\n",
      " * Prec 90.120% \n",
      "best acc: 90.120000\n",
      "Epoch: [88][0/391]\tTime 0.556 (0.556)\tData 0.528 (0.528)\tLoss 0.0892 (0.0892)\tPrec 100.000% (100.000%)\n",
      "Epoch: [88][100/391]\tTime 0.045 (0.050)\tData 0.001 (0.007)\tLoss 0.1061 (0.1224)\tPrec 99.219% (99.513%)\n",
      "Epoch: [88][200/391]\tTime 0.047 (0.047)\tData 0.001 (0.004)\tLoss 0.1556 (0.1323)\tPrec 99.219% (99.456%)\n",
      "Epoch: [88][300/391]\tTime 0.045 (0.046)\tData 0.002 (0.003)\tLoss 0.1916 (0.1352)\tPrec 99.219% (99.439%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.252 (0.252)\tLoss 0.5061 (0.5061)\tPrec 87.500% (87.500%)\n",
      " * Prec 87.330% \n",
      "best acc: 90.120000\n",
      "Epoch: [89][0/391]\tTime 0.470 (0.470)\tData 0.440 (0.440)\tLoss 0.2282 (0.2282)\tPrec 100.000% (100.000%)\n",
      "Epoch: [89][100/391]\tTime 0.045 (0.049)\tData 0.002 (0.006)\tLoss 0.1541 (0.1469)\tPrec 99.219% (99.528%)\n",
      "Epoch: [89][200/391]\tTime 0.043 (0.047)\tData 0.002 (0.004)\tLoss 0.1064 (0.1323)\tPrec 99.219% (99.553%)\n",
      "Epoch: [89][300/391]\tTime 0.044 (0.046)\tData 0.002 (0.003)\tLoss 0.1370 (0.1349)\tPrec 99.219% (99.528%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.406 (0.406)\tLoss 0.4002 (0.4002)\tPrec 89.062% (89.062%)\n",
      " * Prec 87.290% \n",
      "best acc: 90.120000\n",
      "Epoch: [90][0/391]\tTime 0.533 (0.533)\tData 0.503 (0.503)\tLoss 0.1736 (0.1736)\tPrec 99.219% (99.219%)\n",
      "Epoch: [90][100/391]\tTime 0.043 (0.049)\tData 0.002 (0.007)\tLoss 0.1020 (0.1239)\tPrec 100.000% (99.629%)\n",
      "Epoch: [90][200/391]\tTime 0.050 (0.047)\tData 0.002 (0.004)\tLoss 0.1071 (0.1172)\tPrec 100.000% (99.596%)\n",
      "Epoch: [90][300/391]\tTime 0.045 (0.046)\tData 0.002 (0.003)\tLoss 0.0975 (0.1199)\tPrec 100.000% (99.567%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.328 (0.328)\tLoss 0.3656 (0.3656)\tPrec 90.625% (90.625%)\n",
      " * Prec 86.730% \n",
      "best acc: 90.120000\n",
      "Epoch: [91][0/391]\tTime 0.461 (0.461)\tData 0.432 (0.432)\tLoss 0.1208 (0.1208)\tPrec 100.000% (100.000%)\n",
      "Epoch: [91][100/391]\tTime 0.045 (0.049)\tData 0.002 (0.006)\tLoss 0.1092 (0.1309)\tPrec 100.000% (99.513%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [91][200/391]\tTime 0.044 (0.047)\tData 0.002 (0.004)\tLoss 0.1216 (0.1316)\tPrec 99.219% (99.510%)\n",
      "Epoch: [91][300/391]\tTime 0.045 (0.046)\tData 0.002 (0.003)\tLoss 0.1368 (0.1652)\tPrec 100.000% (99.496%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.286 (0.286)\tLoss 0.3831 (0.3831)\tPrec 92.188% (92.188%)\n",
      " * Prec 86.860% \n",
      "best acc: 90.120000\n",
      "Epoch: [92][0/391]\tTime 0.540 (0.540)\tData 0.488 (0.488)\tLoss 0.1459 (0.1459)\tPrec 99.219% (99.219%)\n",
      "Epoch: [92][100/391]\tTime 0.045 (0.050)\tData 0.001 (0.006)\tLoss 0.1469 (0.1336)\tPrec 100.000% (99.482%)\n",
      "Epoch: [92][200/391]\tTime 0.045 (0.047)\tData 0.001 (0.004)\tLoss 0.1108 (0.1396)\tPrec 99.219% (99.499%)\n",
      "Epoch: [92][300/391]\tTime 0.045 (0.046)\tData 0.002 (0.003)\tLoss 0.1070 (0.1345)\tPrec 100.000% (99.517%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.361 (0.361)\tLoss 0.5391 (0.5391)\tPrec 86.719% (86.719%)\n",
      " * Prec 82.470% \n",
      "best acc: 90.120000\n",
      "Epoch: [93][0/391]\tTime 0.511 (0.511)\tData 0.451 (0.451)\tLoss 0.1423 (0.1423)\tPrec 99.219% (99.219%)\n",
      "Epoch: [93][100/391]\tTime 0.044 (0.049)\tData 0.002 (0.006)\tLoss 0.5618 (0.6100)\tPrec 97.656% (99.281%)\n",
      "Epoch: [93][200/391]\tTime 0.045 (0.047)\tData 0.002 (0.004)\tLoss 0.2895 (0.5110)\tPrec 100.000% (99.374%)\n",
      "Epoch: [93][300/391]\tTime 0.045 (0.046)\tData 0.001 (0.003)\tLoss 0.0923 (0.4006)\tPrec 100.000% (99.429%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.448 (0.448)\tLoss 0.2263 (0.2263)\tPrec 94.531% (94.531%)\n",
      " * Prec 89.830% \n",
      "best acc: 90.120000\n",
      "Epoch: [94][0/391]\tTime 0.633 (0.633)\tData 0.605 (0.605)\tLoss 0.1235 (0.1235)\tPrec 98.438% (98.438%)\n",
      "Epoch: [94][100/391]\tTime 0.044 (0.051)\tData 0.001 (0.008)\tLoss 0.0931 (0.1133)\tPrec 100.000% (99.536%)\n",
      "Epoch: [94][200/391]\tTime 0.045 (0.048)\tData 0.001 (0.005)\tLoss 0.1179 (0.1137)\tPrec 100.000% (99.565%)\n",
      "Epoch: [94][300/391]\tTime 0.045 (0.047)\tData 0.002 (0.004)\tLoss 0.1106 (0.1156)\tPrec 100.000% (99.561%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.694 (0.694)\tLoss 0.2558 (0.2558)\tPrec 90.625% (90.625%)\n",
      " * Prec 89.390% \n",
      "best acc: 90.120000\n",
      "Epoch: [95][0/391]\tTime 0.521 (0.521)\tData 0.489 (0.489)\tLoss 0.1048 (0.1048)\tPrec 98.438% (98.438%)\n",
      "Epoch: [95][100/391]\tTime 0.046 (0.049)\tData 0.002 (0.007)\tLoss 0.1235 (0.1206)\tPrec 99.219% (99.474%)\n",
      "Epoch: [95][200/391]\tTime 0.045 (0.047)\tData 0.002 (0.004)\tLoss 0.2073 (0.1273)\tPrec 100.000% (99.518%)\n",
      "Epoch: [95][300/391]\tTime 0.045 (0.046)\tData 0.001 (0.003)\tLoss 0.1244 (0.1276)\tPrec 100.000% (99.546%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.353 (0.353)\tLoss 0.4457 (0.4457)\tPrec 89.844% (89.844%)\n",
      " * Prec 85.600% \n",
      "best acc: 90.120000\n",
      "Epoch: [96][0/391]\tTime 0.467 (0.467)\tData 0.437 (0.437)\tLoss 0.1032 (0.1032)\tPrec 100.000% (100.000%)\n",
      "Epoch: [96][100/391]\tTime 0.044 (0.049)\tData 0.001 (0.006)\tLoss 0.4701 (0.2525)\tPrec 99.219% (99.513%)\n",
      "Epoch: [96][200/391]\tTime 0.045 (0.047)\tData 0.002 (0.004)\tLoss 0.2503 (0.3303)\tPrec 98.438% (99.534%)\n",
      "Epoch: [96][300/391]\tTime 0.045 (0.046)\tData 0.001 (0.003)\tLoss 0.1598 (0.2702)\tPrec 100.000% (99.538%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.485 (0.485)\tLoss 0.3769 (0.3769)\tPrec 89.844% (89.844%)\n",
      " * Prec 89.220% \n",
      "best acc: 90.120000\n",
      "Epoch: [97][0/391]\tTime 0.552 (0.552)\tData 0.486 (0.486)\tLoss 0.0978 (0.0978)\tPrec 100.000% (100.000%)\n",
      "Epoch: [97][100/391]\tTime 0.045 (0.050)\tData 0.001 (0.006)\tLoss 0.1474 (0.1189)\tPrec 100.000% (99.636%)\n",
      "Epoch: [97][200/391]\tTime 0.044 (0.047)\tData 0.002 (0.004)\tLoss 0.0718 (0.1300)\tPrec 100.000% (99.619%)\n",
      "Epoch: [97][300/391]\tTime 0.045 (0.046)\tData 0.003 (0.003)\tLoss 0.2001 (0.1478)\tPrec 99.219% (99.603%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.491 (0.491)\tLoss 1.0392 (1.0392)\tPrec 78.125% (78.125%)\n",
      " * Prec 75.050% \n",
      "best acc: 90.120000\n",
      "Epoch: [98][0/391]\tTime 0.713 (0.713)\tData 0.687 (0.687)\tLoss 0.1497 (0.1497)\tPrec 100.000% (100.000%)\n",
      "Epoch: [98][100/391]\tTime 0.047 (0.051)\tData 0.002 (0.008)\tLoss 0.1152 (0.2682)\tPrec 100.000% (99.428%)\n",
      "Epoch: [98][200/391]\tTime 0.045 (0.048)\tData 0.001 (0.005)\tLoss 0.1093 (0.1891)\tPrec 100.000% (99.502%)\n",
      "Epoch: [98][300/391]\tTime 0.044 (0.047)\tData 0.003 (0.004)\tLoss 0.1263 (0.1646)\tPrec 100.000% (99.538%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.398 (0.398)\tLoss 0.5845 (0.5845)\tPrec 86.719% (86.719%)\n",
      " * Prec 85.960% \n",
      "best acc: 90.120000\n",
      "Epoch: [99][0/391]\tTime 0.628 (0.628)\tData 0.600 (0.600)\tLoss 0.1295 (0.1295)\tPrec 100.000% (100.000%)\n",
      "Epoch: [99][100/391]\tTime 0.044 (0.050)\tData 0.002 (0.008)\tLoss 0.1043 (0.1335)\tPrec 100.000% (99.675%)\n",
      "Epoch: [99][200/391]\tTime 0.045 (0.047)\tData 0.002 (0.005)\tLoss 0.1188 (0.1283)\tPrec 99.219% (99.642%)\n",
      "Epoch: [99][300/391]\tTime 0.045 (0.047)\tData 0.002 (0.004)\tLoss 0.1603 (0.1328)\tPrec 99.219% (99.652%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.513 (0.513)\tLoss 0.4250 (0.4250)\tPrec 89.844% (89.844%)\n",
      " * Prec 88.630% \n",
      "best acc: 90.120000\n"
     ]
    }
   ],
   "source": [
    "# This cell won't be given, but students will complete the training\n",
    "\n",
    "lr = 4e-2\n",
    "weight_decay = 1e-4\n",
    "epochs = 100\n",
    "best_prec = 0\n",
    "\n",
    "#model = nn.DataParallel(model).cuda()\n",
    "model.cuda()\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay)\n",
    "#cudnn.benchmark = True\n",
    "\n",
    "if not os.path.exists('result'):\n",
    "    os.makedirs('result')\n",
    "fdir = 'result/'+str(model_name)\n",
    "if not os.path.exists(fdir):\n",
    "    os.makedirs(fdir)\n",
    "        \n",
    "\n",
    "for epoch in range(0, epochs):\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "\n",
    "    train_loss2(trainloader, model, criterion, optimizer, epoch)\n",
    "    \n",
    "    # evaluate on test set\n",
    "    print(\"Validation starts\")\n",
    "    prec = validate(testloader, model, criterion)\n",
    "\n",
    "    # remember best precision and save checkpoint\n",
    "    is_best = prec > best_prec\n",
    "    best_prec = max(prec,best_prec)\n",
    "    print('best acc: {:1f}'.format(best_prec))\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_prec': best_prec,\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }, is_best, fdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8df3afd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Accuracy: 9012/10000 (90%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#PATH = \"result/VGG16_quant/model_best.pth.tar\"\n",
    "PATH = \"result/VGG16_loss2_with_gammar/model_best.pth.tar\"\n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "device = torch.device(\"cuda\") \n",
    "\n",
    "model.cuda()\n",
    "model.eval()\n",
    "\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in testloader:\n",
    "        data, target = data.to(device), target.to(device) # loading to GPU\n",
    "        output = model(data)\n",
    "        pred = output.argmax(dim=1, keepdim=True)  \n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "test_loss /= len(testloader.dataset)\n",
    "\n",
    "print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        correct, len(testloader.dataset),\n",
    "        100. * correct / len(testloader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45c4f822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.7484, device='cuda:0', grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(model.features[0].weight.abs().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d02d055",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
