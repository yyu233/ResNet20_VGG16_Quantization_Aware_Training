{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "radical-fifty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Building model...\n",
      "ResNet_Cifar(\n",
      "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): QuantConv2d(\n",
      "        16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (conv2): QuantConv2d(\n",
      "        16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): QuantConv2d(\n",
      "        16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (conv2): QuantConv2d(\n",
      "        16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): QuantConv2d(\n",
      "        16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (conv2): QuantConv2d(\n",
      "        16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): QuantConv2d(\n",
      "        16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (conv2): QuantConv2d(\n",
      "        32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): QuantConv2d(\n",
      "          16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (weight_quant): weight_quantize_fn()\n",
      "        )\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): QuantConv2d(\n",
      "        32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (conv2): QuantConv2d(\n",
      "        32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): QuantConv2d(\n",
      "        32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (conv2): QuantConv2d(\n",
      "        32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): QuantConv2d(\n",
      "        32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (conv2): QuantConv2d(\n",
      "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): QuantConv2d(\n",
      "          32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (weight_quant): weight_quantize_fn()\n",
      "        )\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): QuantConv2d(\n",
      "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (conv2): QuantConv2d(\n",
      "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): QuantConv2d(\n",
      "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (conv2): QuantConv2d(\n",
      "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AvgPool2d(kernel_size=8, stride=1, padding=0)\n",
      "  (fc): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "     \n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from models import *\n",
    "\n",
    "\n",
    "global best_prec\n",
    "use_gpu = torch.cuda.is_available()\n",
    "print('=> Building model...')\n",
    "    \n",
    "    \n",
    "    \n",
    "batch_size = 128\n",
    "#model_name = \"VGG16_quant\"\n",
    "#model = VGG16_quant()\n",
    "model_name = \"resnet20_quant\"\n",
    "model = resnet20_quant()\n",
    "print(model)\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.491, 0.482, 0.447], std=[0.247, 0.243, 0.262])\n",
    "\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "print_freq = 100 # every 100 batches, accuracy printed. Here, each batch includes \"batch_size\" data points\n",
    "# CIFAR10 has 50,000 training data, and 10,000 validation data.\n",
    "\n",
    "def train(trainloader, model, criterion, optimizer, epoch):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(trainloader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        input, target = input.cuda(), target.cuda()\n",
    "\n",
    "        # compute output\n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec = accuracy(output, target)[0]\n",
    "        losses.update(loss.item(), input.size(0))\n",
    "        top1.update(prec.item(), input.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "\n",
    "        if i % print_freq == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec {top1.val:.3f}% ({top1.avg:.3f}%)'.format(\n",
    "                   epoch, i, len(trainloader), batch_time=batch_time,\n",
    "                   data_time=data_time, loss=losses, top1=top1))\n",
    "\n",
    "            \n",
    "\n",
    "def validate(val_loader, model, criterion ):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(val_loader):\n",
    "         \n",
    "            input, target = input.cuda(), target.cuda()\n",
    "\n",
    "            # compute output\n",
    "            output = model(input)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            prec = accuracy(output, target)[0]\n",
    "            losses.update(loss.item(), input.size(0))\n",
    "            top1.update(prec.item(), input.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % print_freq == 0:  # This line shows how frequently print out the status. e.g., i%5 => every 5 batch, prints out\n",
    "                print('Test: [{0}/{1}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec {top1.val:.3f}% ({top1.avg:.3f}%)'.format(\n",
    "                   i, len(val_loader), batch_time=batch_time, loss=losses,\n",
    "                   top1=top1))\n",
    "\n",
    "    print(' * Prec {top1.avg:.3f}% '.format(top1=top1))\n",
    "    return top1.avg\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "        \n",
    "def save_checkpoint(state, is_best, fdir):\n",
    "    filepath = os.path.join(fdir, 'checkpoint.pth')\n",
    "    torch.save(state, filepath)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filepath, os.path.join(fdir, 'model_best.pth.tar'))\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"For resnet, the lr starts from 0.1, and is divided by 10 at 80 and 120 epochs\"\"\"\n",
    "    #adjust_list = [150, 225]\n",
    "    adjust_list = [80, 120]\n",
    "    if epoch in adjust_list:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = param_group['lr'] * 0.1        \n",
    "\n",
    "#model = nn.DataParallel(model).cuda()\n",
    "#all_params = checkpoint['state_dict']\n",
    "#model.load_state_dict(all_params, strict=False)\n",
    "#criterion = nn.CrossEntropyLoss().cuda()\n",
    "#validate(testloader, model, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "313a05ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QuantConv2d(\n",
      "  3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "  (weight_quant): weight_quantize_fn()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model.conv1 = QuantConv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "print(model.conv1)\n",
    "\n",
    "for layer in model.modules():\n",
    "    if isinstance(layer, torch.nn.Conv2d):\n",
    "        layer.bit = 2\n",
    "        layer.act_alpha = torch.nn.Parameter(torch.tensor(4.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b02b313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet_Cifar(\n",
      "  (conv1): QuantConv2d(\n",
      "    3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "    (weight_quant): weight_quantize_fn()\n",
      "  )\n",
      "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): QuantConv2d(\n",
      "        16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (conv2): QuantConv2d(\n",
      "        16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): QuantConv2d(\n",
      "        16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (conv2): QuantConv2d(\n",
      "        16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): QuantConv2d(\n",
      "        16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (conv2): QuantConv2d(\n",
      "        16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): QuantConv2d(\n",
      "        16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (conv2): QuantConv2d(\n",
      "        32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): QuantConv2d(\n",
      "          16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (weight_quant): weight_quantize_fn()\n",
      "        )\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): QuantConv2d(\n",
      "        32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (conv2): QuantConv2d(\n",
      "        32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): QuantConv2d(\n",
      "        32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (conv2): QuantConv2d(\n",
      "        32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): QuantConv2d(\n",
      "        32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (conv2): QuantConv2d(\n",
      "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): QuantConv2d(\n",
      "          32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (weight_quant): weight_quantize_fn()\n",
      "        )\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): QuantConv2d(\n",
      "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (conv2): QuantConv2d(\n",
      "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): QuantConv2d(\n",
      "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (conv2): QuantConv2d(\n",
      "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AvgPool2d(kernel_size=8, stride=1, padding=0)\n",
      "  (fc): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "junior-reminder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][0/391]\tTime 0.604 (0.604)\tData 0.473 (0.473)\tLoss 2.4749 (2.4749)\tPrec 11.719% (11.719%)\n",
      "Epoch: [0][100/391]\tTime 0.052 (0.055)\tData 0.002 (0.007)\tLoss 1.7646 (1.9481)\tPrec 32.812% (26.261%)\n",
      "Epoch: [0][200/391]\tTime 0.058 (0.051)\tData 0.003 (0.005)\tLoss 1.5181 (1.7958)\tPrec 45.312% (32.424%)\n",
      "Epoch: [0][300/391]\tTime 0.051 (0.050)\tData 0.003 (0.004)\tLoss 1.4983 (1.6921)\tPrec 49.219% (36.836%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.344 (0.344)\tLoss 1.4855 (1.4855)\tPrec 42.969% (42.969%)\n",
      " * Prec 48.730% \n",
      "best acc: 48.730000\n",
      "Epoch: [1][0/391]\tTime 0.739 (0.739)\tData 0.682 (0.682)\tLoss 1.2946 (1.2946)\tPrec 50.000% (50.000%)\n",
      "Epoch: [1][100/391]\tTime 0.045 (0.053)\tData 0.002 (0.009)\tLoss 1.2185 (1.2413)\tPrec 58.594% (55.585%)\n",
      "Epoch: [1][200/391]\tTime 0.053 (0.050)\tData 0.002 (0.006)\tLoss 1.0442 (1.2019)\tPrec 63.281% (57.156%)\n",
      "Epoch: [1][300/391]\tTime 0.047 (0.049)\tData 0.002 (0.004)\tLoss 1.0309 (1.1710)\tPrec 64.062% (58.127%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.481 (0.481)\tLoss 0.9814 (0.9814)\tPrec 67.188% (67.188%)\n",
      " * Prec 62.150% \n",
      "best acc: 62.150000\n",
      "Epoch: [2][0/391]\tTime 0.839 (0.839)\tData 0.773 (0.773)\tLoss 1.0551 (1.0551)\tPrec 60.156% (60.156%)\n",
      "Epoch: [2][100/391]\tTime 0.041 (0.055)\tData 0.002 (0.010)\tLoss 0.8564 (1.0026)\tPrec 71.094% (64.047%)\n",
      "Epoch: [2][200/391]\tTime 0.050 (0.051)\tData 0.002 (0.006)\tLoss 0.9968 (0.9840)\tPrec 68.750% (65.046%)\n",
      "Epoch: [2][300/391]\tTime 0.046 (0.049)\tData 0.002 (0.005)\tLoss 0.8963 (0.9722)\tPrec 68.750% (65.415%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.703 (0.703)\tLoss 0.9642 (0.9642)\tPrec 71.094% (71.094%)\n",
      " * Prec 64.220% \n",
      "best acc: 64.220000\n",
      "Epoch: [3][0/391]\tTime 0.517 (0.517)\tData 0.452 (0.452)\tLoss 0.8455 (0.8455)\tPrec 69.531% (69.531%)\n",
      "Epoch: [3][100/391]\tTime 0.050 (0.050)\tData 0.003 (0.006)\tLoss 0.9371 (0.8576)\tPrec 65.625% (69.817%)\n",
      "Epoch: [3][200/391]\tTime 0.047 (0.047)\tData 0.002 (0.004)\tLoss 0.8873 (0.8570)\tPrec 71.875% (69.877%)\n",
      "Epoch: [3][300/391]\tTime 0.045 (0.047)\tData 0.002 (0.003)\tLoss 0.8095 (0.8415)\tPrec 76.562% (70.364%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.365 (0.365)\tLoss 0.8315 (0.8315)\tPrec 67.969% (67.969%)\n",
      " * Prec 69.040% \n",
      "best acc: 69.040000\n",
      "Epoch: [4][0/391]\tTime 0.650 (0.650)\tData 0.585 (0.585)\tLoss 0.6991 (0.6991)\tPrec 76.562% (76.562%)\n",
      "Epoch: [4][100/391]\tTime 0.046 (0.053)\tData 0.002 (0.008)\tLoss 0.7712 (0.7664)\tPrec 75.000% (73.205%)\n",
      "Epoch: [4][200/391]\tTime 0.037 (0.050)\tData 0.003 (0.005)\tLoss 0.7297 (0.7651)\tPrec 71.094% (73.266%)\n",
      "Epoch: [4][300/391]\tTime 0.048 (0.049)\tData 0.002 (0.004)\tLoss 0.7506 (0.7555)\tPrec 76.562% (73.521%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.397 (0.397)\tLoss 0.7167 (0.7167)\tPrec 75.000% (75.000%)\n",
      " * Prec 72.120% \n",
      "best acc: 72.120000\n",
      "Epoch: [5][0/391]\tTime 0.580 (0.580)\tData 0.514 (0.514)\tLoss 0.7390 (0.7390)\tPrec 72.656% (72.656%)\n",
      "Epoch: [5][100/391]\tTime 0.050 (0.050)\tData 0.002 (0.007)\tLoss 0.5947 (0.6898)\tPrec 79.688% (75.797%)\n",
      "Epoch: [5][200/391]\tTime 0.056 (0.050)\tData 0.002 (0.005)\tLoss 0.7455 (0.6768)\tPrec 71.875% (76.391%)\n",
      "Epoch: [5][300/391]\tTime 0.052 (0.050)\tData 0.002 (0.004)\tLoss 0.6183 (0.6763)\tPrec 79.688% (76.537%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.234 (0.234)\tLoss 0.6820 (0.6820)\tPrec 77.344% (77.344%)\n",
      " * Prec 72.140% \n",
      "best acc: 72.140000\n",
      "Epoch: [6][0/391]\tTime 0.642 (0.642)\tData 0.579 (0.579)\tLoss 0.5070 (0.5070)\tPrec 83.594% (83.594%)\n",
      "Epoch: [6][100/391]\tTime 0.041 (0.054)\tData 0.002 (0.008)\tLoss 0.5045 (0.6254)\tPrec 78.906% (78.148%)\n",
      "Epoch: [6][200/391]\tTime 0.040 (0.050)\tData 0.002 (0.005)\tLoss 0.7054 (0.6196)\tPrec 70.312% (78.354%)\n",
      "Epoch: [6][300/391]\tTime 0.049 (0.050)\tData 0.002 (0.004)\tLoss 0.6511 (0.6305)\tPrec 78.906% (78.047%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.613 (0.613)\tLoss 0.6473 (0.6473)\tPrec 75.781% (75.781%)\n",
      " * Prec 75.770% \n",
      "best acc: 75.770000\n",
      "Epoch: [7][0/391]\tTime 0.606 (0.606)\tData 0.556 (0.556)\tLoss 0.5065 (0.5065)\tPrec 82.812% (82.812%)\n",
      "Epoch: [7][100/391]\tTime 0.045 (0.053)\tData 0.002 (0.008)\tLoss 0.5868 (0.5891)\tPrec 82.812% (79.672%)\n",
      "Epoch: [7][200/391]\tTime 0.050 (0.050)\tData 0.002 (0.005)\tLoss 0.6737 (0.5862)\tPrec 75.781% (79.769%)\n",
      "Epoch: [7][300/391]\tTime 0.039 (0.049)\tData 0.001 (0.004)\tLoss 0.5370 (0.5886)\tPrec 76.562% (79.765%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.392 (0.392)\tLoss 0.5880 (0.5880)\tPrec 78.906% (78.906%)\n",
      " * Prec 78.030% \n",
      "best acc: 78.030000\n",
      "Epoch: [8][0/391]\tTime 0.565 (0.565)\tData 0.499 (0.499)\tLoss 0.5293 (0.5293)\tPrec 82.031% (82.031%)\n",
      "Epoch: [8][100/391]\tTime 0.043 (0.050)\tData 0.002 (0.007)\tLoss 0.4999 (0.5657)\tPrec 85.156% (80.422%)\n",
      "Epoch: [8][200/391]\tTime 0.049 (0.053)\tData 0.002 (0.005)\tLoss 0.6839 (0.5603)\tPrec 78.125% (80.857%)\n",
      "Epoch: [8][300/391]\tTime 0.052 (0.053)\tData 0.003 (0.004)\tLoss 0.6762 (0.5615)\tPrec 80.469% (80.614%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.466 (0.466)\tLoss 0.8087 (0.8087)\tPrec 77.344% (77.344%)\n",
      " * Prec 74.630% \n",
      "best acc: 78.030000\n",
      "Epoch: [9][0/391]\tTime 0.574 (0.574)\tData 0.507 (0.507)\tLoss 0.5742 (0.5742)\tPrec 82.031% (82.031%)\n",
      "Epoch: [9][100/391]\tTime 0.039 (0.052)\tData 0.001 (0.007)\tLoss 0.5329 (0.5178)\tPrec 82.031% (82.495%)\n",
      "Epoch: [9][200/391]\tTime 0.055 (0.050)\tData 0.002 (0.004)\tLoss 0.5143 (0.5317)\tPrec 79.688% (81.814%)\n",
      "Epoch: [9][300/391]\tTime 0.045 (0.049)\tData 0.001 (0.004)\tLoss 0.5711 (0.5331)\tPrec 84.375% (81.696%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.516 (0.516)\tLoss 0.4706 (0.4706)\tPrec 82.031% (82.031%)\n",
      " * Prec 80.400% \n",
      "best acc: 80.400000\n",
      "Epoch: [10][0/391]\tTime 0.633 (0.633)\tData 0.533 (0.533)\tLoss 0.4475 (0.4475)\tPrec 85.938% (85.938%)\n",
      "Epoch: [10][100/391]\tTime 0.044 (0.049)\tData 0.002 (0.007)\tLoss 0.3698 (0.5050)\tPrec 86.719% (82.387%)\n",
      "Epoch: [10][200/391]\tTime 0.043 (0.048)\tData 0.002 (0.005)\tLoss 0.5468 (0.5137)\tPrec 78.125% (82.027%)\n",
      "Epoch: [10][300/391]\tTime 0.044 (0.047)\tData 0.002 (0.004)\tLoss 0.4122 (0.5129)\tPrec 86.719% (82.148%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.460 (0.460)\tLoss 0.5032 (0.5032)\tPrec 82.812% (82.812%)\n",
      " * Prec 79.880% \n",
      "best acc: 80.400000\n",
      "Epoch: [11][0/391]\tTime 0.647 (0.647)\tData 0.584 (0.584)\tLoss 0.3987 (0.3987)\tPrec 86.719% (86.719%)\n",
      "Epoch: [11][100/391]\tTime 0.050 (0.056)\tData 0.002 (0.008)\tLoss 0.4820 (0.4819)\tPrec 79.688% (83.277%)\n",
      "Epoch: [11][200/391]\tTime 0.046 (0.051)\tData 0.002 (0.005)\tLoss 0.5326 (0.4799)\tPrec 80.469% (83.392%)\n",
      "Epoch: [11][300/391]\tTime 0.049 (0.049)\tData 0.002 (0.004)\tLoss 0.3783 (0.4858)\tPrec 89.062% (83.300%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.368 (0.368)\tLoss 0.5697 (0.5697)\tPrec 83.594% (83.594%)\n",
      " * Prec 80.820% \n",
      "best acc: 80.820000\n",
      "Epoch: [12][0/391]\tTime 0.700 (0.700)\tData 0.635 (0.635)\tLoss 0.4066 (0.4066)\tPrec 86.719% (86.719%)\n",
      "Epoch: [12][100/391]\tTime 0.049 (0.052)\tData 0.002 (0.008)\tLoss 0.5809 (0.4722)\tPrec 76.562% (83.555%)\n",
      "Epoch: [12][200/391]\tTime 0.048 (0.049)\tData 0.002 (0.005)\tLoss 0.4592 (0.4746)\tPrec 82.031% (83.532%)\n",
      "Epoch: [12][300/391]\tTime 0.042 (0.048)\tData 0.002 (0.004)\tLoss 0.3949 (0.4742)\tPrec 82.812% (83.630%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.379 (0.379)\tLoss 0.4409 (0.4409)\tPrec 85.938% (85.938%)\n",
      " * Prec 80.150% \n",
      "best acc: 80.820000\n",
      "Epoch: [13][0/391]\tTime 0.642 (0.642)\tData 0.591 (0.591)\tLoss 0.3804 (0.3804)\tPrec 85.938% (85.938%)\n",
      "Epoch: [13][100/391]\tTime 0.052 (0.052)\tData 0.003 (0.008)\tLoss 0.4902 (0.4432)\tPrec 83.594% (84.793%)\n",
      "Epoch: [13][200/391]\tTime 0.049 (0.051)\tData 0.002 (0.005)\tLoss 0.4287 (0.4533)\tPrec 87.500% (84.383%)\n",
      "Epoch: [13][300/391]\tTime 0.047 (0.049)\tData 0.003 (0.004)\tLoss 0.6866 (0.4516)\tPrec 75.000% (84.380%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.339 (0.339)\tLoss 0.5921 (0.5921)\tPrec 74.219% (74.219%)\n",
      " * Prec 80.430% \n",
      "best acc: 80.820000\n",
      "Epoch: [14][0/391]\tTime 0.881 (0.881)\tData 0.816 (0.816)\tLoss 0.3513 (0.3513)\tPrec 89.062% (89.062%)\n",
      "Epoch: [14][100/391]\tTime 0.045 (0.052)\tData 0.002 (0.010)\tLoss 0.2871 (0.4224)\tPrec 92.188% (85.489%)\n",
      "Epoch: [14][200/391]\tTime 0.049 (0.048)\tData 0.002 (0.006)\tLoss 0.5687 (0.4349)\tPrec 78.906% (85.012%)\n",
      "Epoch: [14][300/391]\tTime 0.044 (0.047)\tData 0.002 (0.005)\tLoss 0.3729 (0.4382)\tPrec 88.281% (84.806%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.398 (0.398)\tLoss 0.7551 (0.7551)\tPrec 78.125% (78.125%)\n",
      " * Prec 77.940% \n",
      "best acc: 80.820000\n",
      "Epoch: [15][0/391]\tTime 0.449 (0.449)\tData 0.385 (0.385)\tLoss 0.5059 (0.5059)\tPrec 82.812% (82.812%)\n",
      "Epoch: [15][100/391]\tTime 0.045 (0.049)\tData 0.002 (0.006)\tLoss 0.3129 (0.4443)\tPrec 86.719% (84.406%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [15][200/391]\tTime 0.040 (0.048)\tData 0.002 (0.004)\tLoss 0.3820 (0.4340)\tPrec 85.156% (84.888%)\n",
      "Epoch: [15][300/391]\tTime 0.044 (0.046)\tData 0.001 (0.003)\tLoss 0.3717 (0.4330)\tPrec 88.281% (84.969%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.728 (0.728)\tLoss 0.5524 (0.5524)\tPrec 82.812% (82.812%)\n",
      " * Prec 82.460% \n",
      "best acc: 82.460000\n",
      "Epoch: [16][0/391]\tTime 0.609 (0.609)\tData 0.541 (0.541)\tLoss 0.3919 (0.3919)\tPrec 85.938% (85.938%)\n",
      "Epoch: [16][100/391]\tTime 0.053 (0.052)\tData 0.002 (0.007)\tLoss 0.3739 (0.4152)\tPrec 87.500% (85.558%)\n",
      "Epoch: [16][200/391]\tTime 0.045 (0.049)\tData 0.002 (0.004)\tLoss 0.4845 (0.4141)\tPrec 83.594% (85.560%)\n",
      "Epoch: [16][300/391]\tTime 0.042 (0.047)\tData 0.001 (0.004)\tLoss 0.6894 (0.4179)\tPrec 78.906% (85.437%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.335 (0.335)\tLoss 0.5601 (0.5601)\tPrec 78.125% (78.125%)\n",
      " * Prec 80.520% \n",
      "best acc: 82.460000\n",
      "Epoch: [17][0/391]\tTime 0.715 (0.715)\tData 0.647 (0.647)\tLoss 0.3407 (0.3407)\tPrec 87.500% (87.500%)\n",
      "Epoch: [17][100/391]\tTime 0.046 (0.053)\tData 0.002 (0.008)\tLoss 0.2745 (0.4061)\tPrec 92.188% (85.914%)\n",
      "Epoch: [17][200/391]\tTime 0.043 (0.049)\tData 0.001 (0.005)\tLoss 0.3025 (0.4018)\tPrec 89.062% (86.070%)\n",
      "Epoch: [17][300/391]\tTime 0.039 (0.048)\tData 0.002 (0.004)\tLoss 0.4173 (0.4033)\tPrec 83.594% (86.002%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.433 (0.433)\tLoss 0.6609 (0.6609)\tPrec 77.344% (77.344%)\n",
      " * Prec 80.550% \n",
      "best acc: 82.460000\n",
      "Epoch: [18][0/391]\tTime 0.543 (0.543)\tData 0.487 (0.487)\tLoss 0.3311 (0.3311)\tPrec 88.281% (88.281%)\n",
      "Epoch: [18][100/391]\tTime 0.050 (0.049)\tData 0.002 (0.007)\tLoss 0.3933 (0.3911)\tPrec 84.375% (86.494%)\n",
      "Epoch: [18][200/391]\tTime 0.044 (0.047)\tData 0.002 (0.004)\tLoss 0.3403 (0.3905)\tPrec 88.281% (86.439%)\n",
      "Epoch: [18][300/391]\tTime 0.053 (0.048)\tData 0.002 (0.004)\tLoss 0.3747 (0.3941)\tPrec 87.500% (86.361%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.331 (0.331)\tLoss 0.4635 (0.4635)\tPrec 84.375% (84.375%)\n",
      " * Prec 82.410% \n",
      "best acc: 82.460000\n",
      "Epoch: [19][0/391]\tTime 0.700 (0.700)\tData 0.636 (0.636)\tLoss 0.3472 (0.3472)\tPrec 86.719% (86.719%)\n",
      "Epoch: [19][100/391]\tTime 0.044 (0.051)\tData 0.002 (0.008)\tLoss 0.3544 (0.3727)\tPrec 89.062% (87.136%)\n",
      "Epoch: [19][200/391]\tTime 0.051 (0.049)\tData 0.002 (0.005)\tLoss 0.2493 (0.3794)\tPrec 91.406% (86.882%)\n",
      "Epoch: [19][300/391]\tTime 0.039 (0.049)\tData 0.002 (0.004)\tLoss 0.4398 (0.3833)\tPrec 83.594% (86.693%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.349 (0.349)\tLoss 0.3880 (0.3880)\tPrec 86.719% (86.719%)\n",
      " * Prec 83.190% \n",
      "best acc: 83.190000\n",
      "Epoch: [20][0/391]\tTime 0.598 (0.598)\tData 0.526 (0.526)\tLoss 0.3414 (0.3414)\tPrec 86.719% (86.719%)\n",
      "Epoch: [20][100/391]\tTime 0.052 (0.051)\tData 0.003 (0.007)\tLoss 0.3330 (0.3649)\tPrec 85.938% (87.260%)\n",
      "Epoch: [20][200/391]\tTime 0.049 (0.049)\tData 0.002 (0.005)\tLoss 0.4802 (0.3736)\tPrec 82.031% (86.971%)\n",
      "Epoch: [20][300/391]\tTime 0.048 (0.048)\tData 0.002 (0.004)\tLoss 0.5406 (0.3759)\tPrec 78.906% (86.887%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.516 (0.516)\tLoss 0.5088 (0.5088)\tPrec 84.375% (84.375%)\n",
      " * Prec 79.690% \n",
      "best acc: 83.190000\n",
      "Epoch: [21][0/391]\tTime 0.714 (0.714)\tData 0.648 (0.648)\tLoss 0.3575 (0.3575)\tPrec 88.281% (88.281%)\n",
      "Epoch: [21][100/391]\tTime 0.045 (0.054)\tData 0.002 (0.008)\tLoss 0.3611 (0.3564)\tPrec 86.719% (87.330%)\n",
      "Epoch: [21][200/391]\tTime 0.042 (0.050)\tData 0.001 (0.005)\tLoss 0.2935 (0.3597)\tPrec 88.281% (87.177%)\n",
      "Epoch: [21][300/391]\tTime 0.044 (0.049)\tData 0.002 (0.004)\tLoss 0.2917 (0.3613)\tPrec 89.062% (87.178%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.855 (0.855)\tLoss 0.6255 (0.6255)\tPrec 81.250% (81.250%)\n",
      " * Prec 81.580% \n",
      "best acc: 83.190000\n",
      "Epoch: [22][0/391]\tTime 0.479 (0.479)\tData 0.428 (0.428)\tLoss 0.2689 (0.2689)\tPrec 89.062% (89.062%)\n",
      "Epoch: [22][100/391]\tTime 0.052 (0.054)\tData 0.002 (0.006)\tLoss 0.3990 (0.3618)\tPrec 83.594% (87.245%)\n",
      "Epoch: [22][200/391]\tTime 0.041 (0.050)\tData 0.002 (0.004)\tLoss 0.4251 (0.3619)\tPrec 87.500% (87.325%)\n",
      "Epoch: [22][300/391]\tTime 0.042 (0.048)\tData 0.002 (0.003)\tLoss 0.2595 (0.3595)\tPrec 91.406% (87.471%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.552 (0.552)\tLoss 0.4766 (0.4766)\tPrec 85.156% (85.156%)\n",
      " * Prec 82.660% \n",
      "best acc: 83.190000\n",
      "Epoch: [23][0/391]\tTime 0.638 (0.638)\tData 0.575 (0.575)\tLoss 0.2980 (0.2980)\tPrec 89.062% (89.062%)\n",
      "Epoch: [23][100/391]\tTime 0.049 (0.051)\tData 0.002 (0.008)\tLoss 0.3865 (0.3336)\tPrec 84.375% (88.482%)\n",
      "Epoch: [23][200/391]\tTime 0.047 (0.050)\tData 0.002 (0.005)\tLoss 0.4292 (0.3369)\tPrec 84.375% (88.382%)\n",
      "Epoch: [23][300/391]\tTime 0.046 (0.050)\tData 0.002 (0.004)\tLoss 0.3568 (0.3436)\tPrec 88.281% (88.224%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.294 (0.294)\tLoss 0.4144 (0.4144)\tPrec 85.938% (85.938%)\n",
      " * Prec 81.630% \n",
      "best acc: 83.190000\n",
      "Epoch: [24][0/391]\tTime 0.468 (0.468)\tData 0.416 (0.416)\tLoss 0.4175 (0.4175)\tPrec 80.469% (80.469%)\n",
      "Epoch: [24][100/391]\tTime 0.040 (0.047)\tData 0.002 (0.006)\tLoss 0.3407 (0.3379)\tPrec 86.719% (88.382%)\n",
      "Epoch: [24][200/391]\tTime 0.046 (0.046)\tData 0.002 (0.004)\tLoss 0.4002 (0.3399)\tPrec 86.719% (88.165%)\n",
      "Epoch: [24][300/391]\tTime 0.042 (0.045)\tData 0.002 (0.003)\tLoss 0.3102 (0.3398)\tPrec 89.062% (88.198%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.293 (0.293)\tLoss 0.3309 (0.3309)\tPrec 89.844% (89.844%)\n",
      " * Prec 82.770% \n",
      "best acc: 83.190000\n",
      "Epoch: [25][0/391]\tTime 0.510 (0.510)\tData 0.445 (0.445)\tLoss 0.4107 (0.4107)\tPrec 86.719% (86.719%)\n",
      "Epoch: [25][100/391]\tTime 0.058 (0.052)\tData 0.002 (0.006)\tLoss 0.4472 (0.3252)\tPrec 85.156% (88.776%)\n",
      "Epoch: [25][200/391]\tTime 0.050 (0.049)\tData 0.002 (0.004)\tLoss 0.5135 (0.3396)\tPrec 84.375% (88.238%)\n",
      "Epoch: [25][300/391]\tTime 0.046 (0.047)\tData 0.002 (0.003)\tLoss 0.3611 (0.3386)\tPrec 87.500% (88.284%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.329 (0.329)\tLoss 0.3109 (0.3109)\tPrec 89.062% (89.062%)\n",
      " * Prec 84.220% \n",
      "best acc: 84.220000\n",
      "Epoch: [26][0/391]\tTime 0.617 (0.617)\tData 0.553 (0.553)\tLoss 0.3432 (0.3432)\tPrec 90.625% (90.625%)\n",
      "Epoch: [26][100/391]\tTime 0.045 (0.052)\tData 0.002 (0.008)\tLoss 0.4549 (0.3397)\tPrec 83.594% (88.057%)\n",
      "Epoch: [26][200/391]\tTime 0.043 (0.048)\tData 0.002 (0.005)\tLoss 0.2650 (0.3317)\tPrec 92.188% (88.343%)\n",
      "Epoch: [26][300/391]\tTime 0.045 (0.046)\tData 0.002 (0.004)\tLoss 0.2120 (0.3361)\tPrec 92.188% (88.268%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.272 (0.272)\tLoss 0.4970 (0.4970)\tPrec 83.594% (83.594%)\n",
      " * Prec 83.850% \n",
      "best acc: 84.220000\n",
      "Epoch: [27][0/391]\tTime 0.669 (0.669)\tData 0.603 (0.603)\tLoss 0.2902 (0.2902)\tPrec 88.281% (88.281%)\n",
      "Epoch: [27][100/391]\tTime 0.054 (0.051)\tData 0.002 (0.008)\tLoss 0.2623 (0.3209)\tPrec 90.625% (88.753%)\n",
      "Epoch: [27][200/391]\tTime 0.044 (0.048)\tData 0.002 (0.005)\tLoss 0.4568 (0.3236)\tPrec 82.031% (88.713%)\n",
      "Epoch: [27][300/391]\tTime 0.051 (0.047)\tData 0.002 (0.004)\tLoss 0.3999 (0.3251)\tPrec 86.719% (88.606%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.408 (0.408)\tLoss 0.4927 (0.4927)\tPrec 82.031% (82.031%)\n",
      " * Prec 82.460% \n",
      "best acc: 84.220000\n",
      "Epoch: [28][0/391]\tTime 0.762 (0.762)\tData 0.695 (0.695)\tLoss 0.3020 (0.3020)\tPrec 86.719% (86.719%)\n",
      "Epoch: [28][100/391]\tTime 0.046 (0.051)\tData 0.002 (0.009)\tLoss 0.2077 (0.3123)\tPrec 93.750% (89.124%)\n",
      "Epoch: [28][200/391]\tTime 0.043 (0.048)\tData 0.002 (0.005)\tLoss 0.3635 (0.3135)\tPrec 89.844% (88.934%)\n",
      "Epoch: [28][300/391]\tTime 0.040 (0.046)\tData 0.002 (0.004)\tLoss 0.2618 (0.3140)\tPrec 90.625% (88.922%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.322 (0.322)\tLoss 0.6129 (0.6129)\tPrec 81.250% (81.250%)\n",
      " * Prec 82.740% \n",
      "best acc: 84.220000\n",
      "Epoch: [29][0/391]\tTime 0.906 (0.906)\tData 0.848 (0.848)\tLoss 0.3733 (0.3733)\tPrec 85.156% (85.156%)\n",
      "Epoch: [29][100/391]\tTime 0.042 (0.053)\tData 0.002 (0.010)\tLoss 0.2378 (0.3079)\tPrec 90.625% (89.403%)\n",
      "Epoch: [29][200/391]\tTime 0.040 (0.049)\tData 0.002 (0.006)\tLoss 0.3641 (0.3121)\tPrec 89.062% (89.160%)\n",
      "Epoch: [29][300/391]\tTime 0.046 (0.047)\tData 0.001 (0.005)\tLoss 0.3203 (0.3120)\tPrec 85.938% (89.107%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.399 (0.399)\tLoss 0.3182 (0.3182)\tPrec 88.281% (88.281%)\n",
      " * Prec 84.660% \n",
      "best acc: 84.660000\n",
      "Epoch: [30][0/391]\tTime 0.776 (0.776)\tData 0.714 (0.714)\tLoss 0.1643 (0.1643)\tPrec 94.531% (94.531%)\n",
      "Epoch: [30][100/391]\tTime 0.051 (0.055)\tData 0.002 (0.009)\tLoss 0.2690 (0.2889)\tPrec 90.625% (89.937%)\n",
      "Epoch: [30][200/391]\tTime 0.041 (0.050)\tData 0.002 (0.006)\tLoss 0.2660 (0.2970)\tPrec 89.844% (89.646%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [30][300/391]\tTime 0.042 (0.048)\tData 0.002 (0.004)\tLoss 0.3388 (0.3048)\tPrec 90.625% (89.371%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.499 (0.499)\tLoss 0.3089 (0.3089)\tPrec 88.281% (88.281%)\n",
      " * Prec 84.410% \n",
      "best acc: 84.660000\n",
      "Epoch: [31][0/391]\tTime 0.561 (0.561)\tData 0.471 (0.471)\tLoss 0.3385 (0.3385)\tPrec 89.062% (89.062%)\n",
      "Epoch: [31][100/391]\tTime 0.048 (0.052)\tData 0.002 (0.007)\tLoss 0.2508 (0.2995)\tPrec 91.406% (89.836%)\n",
      "Epoch: [31][200/391]\tTime 0.050 (0.051)\tData 0.003 (0.005)\tLoss 0.2211 (0.3037)\tPrec 92.969% (89.486%)\n",
      "Epoch: [31][300/391]\tTime 0.040 (0.050)\tData 0.002 (0.004)\tLoss 0.2368 (0.3083)\tPrec 91.406% (89.231%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.345 (0.345)\tLoss 0.4305 (0.4305)\tPrec 86.719% (86.719%)\n",
      " * Prec 83.760% \n",
      "best acc: 84.660000\n",
      "Epoch: [32][0/391]\tTime 0.509 (0.509)\tData 0.446 (0.446)\tLoss 0.2512 (0.2512)\tPrec 91.406% (91.406%)\n",
      "Epoch: [32][100/391]\tTime 0.044 (0.049)\tData 0.002 (0.006)\tLoss 0.2219 (0.2965)\tPrec 91.406% (89.519%)\n",
      "Epoch: [32][200/391]\tTime 0.039 (0.046)\tData 0.002 (0.004)\tLoss 0.4294 (0.2989)\tPrec 86.719% (89.506%)\n",
      "Epoch: [32][300/391]\tTime 0.047 (0.045)\tData 0.002 (0.003)\tLoss 0.2792 (0.3001)\tPrec 89.062% (89.441%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.255 (0.255)\tLoss 0.3531 (0.3531)\tPrec 87.500% (87.500%)\n",
      " * Prec 86.150% \n",
      "best acc: 86.150000\n",
      "Epoch: [33][0/391]\tTime 0.576 (0.576)\tData 0.508 (0.508)\tLoss 0.2307 (0.2307)\tPrec 92.969% (92.969%)\n",
      "Epoch: [33][100/391]\tTime 0.044 (0.051)\tData 0.002 (0.007)\tLoss 0.3455 (0.3076)\tPrec 85.938% (89.558%)\n",
      "Epoch: [33][200/391]\tTime 0.043 (0.048)\tData 0.002 (0.004)\tLoss 0.2647 (0.2986)\tPrec 90.625% (89.595%)\n",
      "Epoch: [33][300/391]\tTime 0.045 (0.047)\tData 0.001 (0.003)\tLoss 0.3356 (0.3003)\tPrec 85.156% (89.457%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.339 (0.339)\tLoss 0.2994 (0.2994)\tPrec 89.844% (89.844%)\n",
      " * Prec 85.150% \n",
      "best acc: 86.150000\n",
      "Epoch: [34][0/391]\tTime 0.792 (0.792)\tData 0.725 (0.725)\tLoss 0.2576 (0.2576)\tPrec 90.625% (90.625%)\n",
      "Epoch: [34][100/391]\tTime 0.045 (0.052)\tData 0.001 (0.009)\tLoss 0.3895 (0.2805)\tPrec 84.375% (90.269%)\n",
      "Epoch: [34][200/391]\tTime 0.041 (0.049)\tData 0.002 (0.005)\tLoss 0.2667 (0.2821)\tPrec 89.844% (90.124%)\n",
      "Epoch: [34][300/391]\tTime 0.042 (0.047)\tData 0.002 (0.004)\tLoss 0.4691 (0.2909)\tPrec 82.812% (89.815%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.389 (0.389)\tLoss 0.3093 (0.3093)\tPrec 88.281% (88.281%)\n",
      " * Prec 85.350% \n",
      "best acc: 86.150000\n",
      "Epoch: [35][0/391]\tTime 0.522 (0.522)\tData 0.460 (0.460)\tLoss 0.2393 (0.2393)\tPrec 92.969% (92.969%)\n",
      "Epoch: [35][100/391]\tTime 0.049 (0.049)\tData 0.002 (0.006)\tLoss 0.3421 (0.2882)\tPrec 90.625% (90.029%)\n",
      "Epoch: [35][200/391]\tTime 0.047 (0.049)\tData 0.002 (0.004)\tLoss 0.3280 (0.2875)\tPrec 90.625% (89.863%)\n",
      "Epoch: [35][300/391]\tTime 0.041 (0.049)\tData 0.002 (0.004)\tLoss 0.2652 (0.2868)\tPrec 89.062% (89.909%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.679 (0.679)\tLoss 0.2954 (0.2954)\tPrec 89.844% (89.844%)\n",
      " * Prec 84.430% \n",
      "best acc: 86.150000\n",
      "Epoch: [36][0/391]\tTime 0.851 (0.851)\tData 0.784 (0.784)\tLoss 0.2817 (0.2817)\tPrec 91.406% (91.406%)\n",
      "Epoch: [36][100/391]\tTime 0.047 (0.053)\tData 0.002 (0.010)\tLoss 0.2853 (0.2799)\tPrec 90.625% (90.114%)\n",
      "Epoch: [36][200/391]\tTime 0.043 (0.050)\tData 0.002 (0.006)\tLoss 0.3171 (0.2849)\tPrec 87.500% (89.953%)\n",
      "Epoch: [36][300/391]\tTime 0.044 (0.048)\tData 0.002 (0.005)\tLoss 0.2232 (0.2849)\tPrec 91.406% (90.051%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.375 (0.375)\tLoss 0.3611 (0.3611)\tPrec 88.281% (88.281%)\n",
      " * Prec 85.920% \n",
      "best acc: 86.150000\n",
      "Epoch: [37][0/391]\tTime 0.624 (0.624)\tData 0.560 (0.560)\tLoss 0.2250 (0.2250)\tPrec 92.188% (92.188%)\n",
      "Epoch: [37][100/391]\tTime 0.049 (0.053)\tData 0.002 (0.007)\tLoss 0.2724 (0.2629)\tPrec 89.062% (90.818%)\n",
      "Epoch: [37][200/391]\tTime 0.056 (0.050)\tData 0.002 (0.004)\tLoss 0.2011 (0.2715)\tPrec 94.531% (90.497%)\n",
      "Epoch: [37][300/391]\tTime 0.040 (0.047)\tData 0.001 (0.003)\tLoss 0.2060 (0.2779)\tPrec 93.750% (90.225%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.356 (0.356)\tLoss 0.2855 (0.2855)\tPrec 90.625% (90.625%)\n",
      " * Prec 85.550% \n",
      "best acc: 86.150000\n",
      "Epoch: [38][0/391]\tTime 0.721 (0.721)\tData 0.657 (0.657)\tLoss 0.3247 (0.3247)\tPrec 87.500% (87.500%)\n",
      "Epoch: [38][100/391]\tTime 0.039 (0.053)\tData 0.001 (0.008)\tLoss 0.1859 (0.2720)\tPrec 95.312% (90.540%)\n",
      "Epoch: [38][200/391]\tTime 0.054 (0.050)\tData 0.002 (0.005)\tLoss 0.3168 (0.2689)\tPrec 91.406% (90.691%)\n",
      "Epoch: [38][300/391]\tTime 0.047 (0.049)\tData 0.002 (0.004)\tLoss 0.3206 (0.2716)\tPrec 89.062% (90.529%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.317 (0.317)\tLoss 0.2770 (0.2770)\tPrec 89.844% (89.844%)\n",
      " * Prec 85.820% \n",
      "best acc: 86.150000\n",
      "Epoch: [39][0/391]\tTime 0.673 (0.673)\tData 0.621 (0.621)\tLoss 0.3319 (0.3319)\tPrec 88.281% (88.281%)\n",
      "Epoch: [39][100/391]\tTime 0.050 (0.056)\tData 0.002 (0.008)\tLoss 0.3293 (0.2784)\tPrec 89.844% (90.447%)\n",
      "Epoch: [39][200/391]\tTime 0.051 (0.053)\tData 0.002 (0.005)\tLoss 0.2032 (0.2721)\tPrec 90.625% (90.555%)\n",
      "Epoch: [39][300/391]\tTime 0.052 (0.052)\tData 0.002 (0.004)\tLoss 0.3528 (0.2757)\tPrec 88.281% (90.365%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.528 (0.528)\tLoss 0.3509 (0.3509)\tPrec 88.281% (88.281%)\n",
      " * Prec 85.360% \n",
      "best acc: 86.150000\n",
      "Epoch: [40][0/391]\tTime 0.524 (0.524)\tData 0.477 (0.477)\tLoss 0.2776 (0.2776)\tPrec 89.844% (89.844%)\n",
      "Epoch: [40][100/391]\tTime 0.049 (0.049)\tData 0.002 (0.007)\tLoss 0.1565 (0.2623)\tPrec 94.531% (90.834%)\n",
      "Epoch: [40][200/391]\tTime 0.038 (0.046)\tData 0.002 (0.004)\tLoss 0.1608 (0.2676)\tPrec 96.094% (90.707%)\n",
      "Epoch: [40][300/391]\tTime 0.049 (0.045)\tData 0.002 (0.003)\tLoss 0.1912 (0.2665)\tPrec 94.531% (90.729%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.326 (0.326)\tLoss 0.5326 (0.5326)\tPrec 84.375% (84.375%)\n",
      " * Prec 82.730% \n",
      "best acc: 86.150000\n",
      "Epoch: [41][0/391]\tTime 0.598 (0.598)\tData 0.531 (0.531)\tLoss 0.2342 (0.2342)\tPrec 91.406% (91.406%)\n",
      "Epoch: [41][100/391]\tTime 0.043 (0.051)\tData 0.002 (0.007)\tLoss 0.2350 (0.2648)\tPrec 92.188% (90.478%)\n",
      "Epoch: [41][200/391]\tTime 0.048 (0.048)\tData 0.002 (0.005)\tLoss 0.3122 (0.2685)\tPrec 89.844% (90.415%)\n",
      "Epoch: [41][300/391]\tTime 0.045 (0.047)\tData 0.002 (0.004)\tLoss 0.1614 (0.2667)\tPrec 92.969% (90.529%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.369 (0.369)\tLoss 0.3390 (0.3390)\tPrec 91.406% (91.406%)\n",
      " * Prec 85.990% \n",
      "best acc: 86.150000\n",
      "Epoch: [42][0/391]\tTime 0.578 (0.578)\tData 0.511 (0.511)\tLoss 0.1711 (0.1711)\tPrec 93.750% (93.750%)\n",
      "Epoch: [42][100/391]\tTime 0.050 (0.051)\tData 0.002 (0.007)\tLoss 0.2858 (0.2538)\tPrec 90.625% (91.228%)\n",
      "Epoch: [42][200/391]\tTime 0.049 (0.049)\tData 0.002 (0.005)\tLoss 0.2479 (0.2602)\tPrec 91.406% (90.924%)\n",
      "Epoch: [42][300/391]\tTime 0.050 (0.048)\tData 0.002 (0.004)\tLoss 0.3431 (0.2598)\tPrec 87.500% (90.825%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.430 (0.430)\tLoss 0.3055 (0.3055)\tPrec 90.625% (90.625%)\n",
      " * Prec 87.010% \n",
      "best acc: 87.010000\n",
      "Epoch: [43][0/391]\tTime 0.708 (0.708)\tData 0.649 (0.649)\tLoss 0.2362 (0.2362)\tPrec 92.188% (92.188%)\n",
      "Epoch: [43][100/391]\tTime 0.046 (0.051)\tData 0.002 (0.008)\tLoss 0.2919 (0.2490)\tPrec 89.062% (91.228%)\n",
      "Epoch: [43][200/391]\tTime 0.050 (0.049)\tData 0.003 (0.005)\tLoss 0.2834 (0.2542)\tPrec 89.844% (91.115%)\n",
      "Epoch: [43][300/391]\tTime 0.048 (0.048)\tData 0.002 (0.004)\tLoss 0.2878 (0.2588)\tPrec 89.844% (90.833%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.363 (0.363)\tLoss 0.4915 (0.4915)\tPrec 85.938% (85.938%)\n",
      " * Prec 84.360% \n",
      "best acc: 87.010000\n",
      "Epoch: [44][0/391]\tTime 0.539 (0.539)\tData 0.479 (0.479)\tLoss 0.3472 (0.3472)\tPrec 89.844% (89.844%)\n",
      "Epoch: [44][100/391]\tTime 0.048 (0.050)\tData 0.002 (0.006)\tLoss 0.2324 (0.2440)\tPrec 92.969% (91.213%)\n",
      "Epoch: [44][200/391]\tTime 0.044 (0.047)\tData 0.002 (0.004)\tLoss 0.2338 (0.2519)\tPrec 95.312% (90.971%)\n",
      "Epoch: [44][300/391]\tTime 0.049 (0.046)\tData 0.002 (0.003)\tLoss 0.2352 (0.2519)\tPrec 93.750% (91.043%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.385 (0.385)\tLoss 0.3812 (0.3812)\tPrec 87.500% (87.500%)\n",
      " * Prec 84.900% \n",
      "best acc: 87.010000\n",
      "Epoch: [45][0/391]\tTime 0.472 (0.472)\tData 0.409 (0.409)\tLoss 0.2724 (0.2724)\tPrec 91.406% (91.406%)\n",
      "Epoch: [45][100/391]\tTime 0.048 (0.051)\tData 0.002 (0.006)\tLoss 0.1519 (0.2447)\tPrec 92.969% (91.368%)\n",
      "Epoch: [45][200/391]\tTime 0.048 (0.049)\tData 0.001 (0.004)\tLoss 0.1984 (0.2464)\tPrec 94.531% (91.379%)\n",
      "Epoch: [45][300/391]\tTime 0.053 (0.049)\tData 0.002 (0.003)\tLoss 0.2251 (0.2491)\tPrec 92.969% (91.310%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation starts\n",
      "Test: [0/79]\tTime 0.356 (0.356)\tLoss 0.3609 (0.3609)\tPrec 85.938% (85.938%)\n",
      " * Prec 85.380% \n",
      "best acc: 87.010000\n",
      "Epoch: [46][0/391]\tTime 0.469 (0.469)\tData 0.374 (0.374)\tLoss 0.1617 (0.1617)\tPrec 93.750% (93.750%)\n",
      "Epoch: [46][100/391]\tTime 0.052 (0.052)\tData 0.002 (0.006)\tLoss 0.1948 (0.2436)\tPrec 92.188% (91.615%)\n",
      "Epoch: [46][200/391]\tTime 0.045 (0.049)\tData 0.002 (0.004)\tLoss 0.3070 (0.2408)\tPrec 87.500% (91.585%)\n",
      "Epoch: [46][300/391]\tTime 0.045 (0.046)\tData 0.002 (0.003)\tLoss 0.2141 (0.2501)\tPrec 92.969% (91.243%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.327 (0.327)\tLoss 0.3609 (0.3609)\tPrec 87.500% (87.500%)\n",
      " * Prec 85.470% \n",
      "best acc: 87.010000\n",
      "Epoch: [47][0/391]\tTime 0.563 (0.563)\tData 0.510 (0.510)\tLoss 0.1964 (0.1964)\tPrec 92.969% (92.969%)\n",
      "Epoch: [47][100/391]\tTime 0.046 (0.050)\tData 0.002 (0.007)\tLoss 0.2707 (0.2363)\tPrec 89.844% (91.692%)\n",
      "Epoch: [47][200/391]\tTime 0.045 (0.048)\tData 0.002 (0.004)\tLoss 0.2359 (0.2380)\tPrec 92.969% (91.647%)\n",
      "Epoch: [47][300/391]\tTime 0.036 (0.048)\tData 0.001 (0.003)\tLoss 0.2511 (0.2466)\tPrec 91.406% (91.393%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.233 (0.233)\tLoss 0.4173 (0.4173)\tPrec 84.375% (84.375%)\n",
      " * Prec 83.340% \n",
      "best acc: 87.010000\n",
      "Epoch: [48][0/391]\tTime 0.564 (0.564)\tData 0.493 (0.493)\tLoss 0.1707 (0.1707)\tPrec 94.531% (94.531%)\n",
      "Epoch: [48][100/391]\tTime 0.050 (0.055)\tData 0.002 (0.007)\tLoss 0.2533 (0.2243)\tPrec 89.844% (92.126%)\n",
      "Epoch: [48][200/391]\tTime 0.041 (0.048)\tData 0.002 (0.004)\tLoss 0.2392 (0.2312)\tPrec 94.531% (91.931%)\n",
      "Epoch: [48][300/391]\tTime 0.047 (0.047)\tData 0.003 (0.003)\tLoss 0.2118 (0.2424)\tPrec 93.750% (91.526%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.452 (0.452)\tLoss 0.3352 (0.3352)\tPrec 88.281% (88.281%)\n",
      " * Prec 85.180% \n",
      "best acc: 87.010000\n",
      "Epoch: [49][0/391]\tTime 0.478 (0.478)\tData 0.404 (0.404)\tLoss 0.2668 (0.2668)\tPrec 89.844% (89.844%)\n",
      "Epoch: [49][100/391]\tTime 0.048 (0.052)\tData 0.001 (0.006)\tLoss 0.1727 (0.2324)\tPrec 95.312% (92.041%)\n",
      "Epoch: [49][200/391]\tTime 0.044 (0.048)\tData 0.002 (0.004)\tLoss 0.2163 (0.2341)\tPrec 93.750% (91.849%)\n",
      "Epoch: [49][300/391]\tTime 0.043 (0.048)\tData 0.002 (0.003)\tLoss 0.1979 (0.2401)\tPrec 94.531% (91.635%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.383 (0.383)\tLoss 0.3047 (0.3047)\tPrec 89.844% (89.844%)\n",
      " * Prec 86.630% \n",
      "best acc: 87.010000\n",
      "Epoch: [50][0/391]\tTime 0.613 (0.613)\tData 0.547 (0.547)\tLoss 0.2040 (0.2040)\tPrec 93.750% (93.750%)\n",
      "Epoch: [50][100/391]\tTime 0.046 (0.053)\tData 0.002 (0.007)\tLoss 0.1502 (0.2240)\tPrec 95.312% (92.288%)\n",
      "Epoch: [50][200/391]\tTime 0.041 (0.049)\tData 0.002 (0.005)\tLoss 0.1534 (0.2365)\tPrec 94.531% (91.729%)\n",
      "Epoch: [50][300/391]\tTime 0.040 (0.048)\tData 0.002 (0.004)\tLoss 0.2057 (0.2398)\tPrec 92.188% (91.575%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.322 (0.322)\tLoss 0.3655 (0.3655)\tPrec 90.625% (90.625%)\n",
      " * Prec 86.640% \n",
      "best acc: 87.010000\n",
      "Epoch: [51][0/391]\tTime 0.413 (0.413)\tData 0.347 (0.347)\tLoss 0.2193 (0.2193)\tPrec 93.750% (93.750%)\n",
      "Epoch: [51][100/391]\tTime 0.050 (0.049)\tData 0.002 (0.005)\tLoss 0.2784 (0.2242)\tPrec 89.844% (92.087%)\n",
      "Epoch: [51][200/391]\tTime 0.049 (0.049)\tData 0.002 (0.004)\tLoss 0.2940 (0.2289)\tPrec 85.156% (91.908%)\n",
      "Epoch: [51][300/391]\tTime 0.046 (0.049)\tData 0.002 (0.003)\tLoss 0.2615 (0.2346)\tPrec 89.844% (91.749%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.289 (0.289)\tLoss 0.3062 (0.3062)\tPrec 88.281% (88.281%)\n",
      " * Prec 86.160% \n",
      "best acc: 87.010000\n",
      "Epoch: [52][0/391]\tTime 0.449 (0.449)\tData 0.349 (0.349)\tLoss 0.2676 (0.2676)\tPrec 89.844% (89.844%)\n",
      "Epoch: [52][100/391]\tTime 0.044 (0.048)\tData 0.002 (0.005)\tLoss 0.2645 (0.2205)\tPrec 92.188% (92.273%)\n",
      "Epoch: [52][200/391]\tTime 0.045 (0.046)\tData 0.002 (0.004)\tLoss 0.1639 (0.2266)\tPrec 94.531% (92.121%)\n",
      "Epoch: [52][300/391]\tTime 0.049 (0.046)\tData 0.002 (0.003)\tLoss 0.2629 (0.2296)\tPrec 91.406% (92.003%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.441 (0.441)\tLoss 0.3550 (0.3550)\tPrec 87.500% (87.500%)\n",
      " * Prec 86.150% \n",
      "best acc: 87.010000\n",
      "Epoch: [53][0/391]\tTime 0.818 (0.818)\tData 0.744 (0.744)\tLoss 0.2003 (0.2003)\tPrec 92.969% (92.969%)\n",
      "Epoch: [53][100/391]\tTime 0.049 (0.055)\tData 0.002 (0.009)\tLoss 0.2064 (0.2233)\tPrec 92.188% (92.226%)\n",
      "Epoch: [53][200/391]\tTime 0.043 (0.050)\tData 0.002 (0.006)\tLoss 0.2068 (0.2278)\tPrec 92.188% (92.048%)\n",
      "Epoch: [53][300/391]\tTime 0.040 (0.048)\tData 0.002 (0.004)\tLoss 0.2484 (0.2340)\tPrec 89.062% (91.855%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.394 (0.394)\tLoss 0.4389 (0.4389)\tPrec 83.594% (83.594%)\n",
      " * Prec 85.910% \n",
      "best acc: 87.010000\n",
      "Epoch: [54][0/391]\tTime 0.766 (0.766)\tData 0.703 (0.703)\tLoss 0.2026 (0.2026)\tPrec 92.969% (92.969%)\n",
      "Epoch: [54][100/391]\tTime 0.092 (0.094)\tData 0.002 (0.009)\tLoss 0.2396 (0.2263)\tPrec 92.969% (91.894%)\n",
      "Epoch: [54][200/391]\tTime 0.083 (0.091)\tData 0.002 (0.005)\tLoss 0.3299 (0.2236)\tPrec 89.844% (92.156%)\n",
      "Epoch: [54][300/391]\tTime 0.083 (0.089)\tData 0.002 (0.004)\tLoss 0.4008 (0.2290)\tPrec 85.156% (91.925%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.870 (0.870)\tLoss 0.3427 (0.3427)\tPrec 84.375% (84.375%)\n",
      " * Prec 85.580% \n",
      "best acc: 87.010000\n",
      "Epoch: [55][0/391]\tTime 0.892 (0.892)\tData 0.825 (0.825)\tLoss 0.1904 (0.1904)\tPrec 92.969% (92.969%)\n",
      "Epoch: [55][100/391]\tTime 0.091 (0.092)\tData 0.002 (0.011)\tLoss 0.1358 (0.2246)\tPrec 94.531% (91.909%)\n",
      "Epoch: [55][200/391]\tTime 0.088 (0.090)\tData 0.002 (0.007)\tLoss 0.2160 (0.2270)\tPrec 92.188% (91.927%)\n",
      "Epoch: [55][300/391]\tTime 0.093 (0.089)\tData 0.002 (0.005)\tLoss 0.2037 (0.2313)\tPrec 92.969% (91.803%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.436 (0.436)\tLoss 0.3182 (0.3182)\tPrec 89.844% (89.844%)\n",
      " * Prec 87.060% \n",
      "best acc: 87.060000\n",
      "Epoch: [56][0/391]\tTime 1.127 (1.127)\tData 1.058 (1.058)\tLoss 0.1800 (0.1800)\tPrec 92.969% (92.969%)\n",
      "Epoch: [56][100/391]\tTime 0.084 (0.093)\tData 0.003 (0.013)\tLoss 0.1823 (0.2133)\tPrec 93.750% (92.481%)\n",
      "Epoch: [56][200/391]\tTime 0.089 (0.091)\tData 0.002 (0.008)\tLoss 0.3619 (0.2149)\tPrec 89.844% (92.463%)\n",
      "Epoch: [56][300/391]\tTime 0.087 (0.090)\tData 0.002 (0.006)\tLoss 0.1949 (0.2192)\tPrec 93.750% (92.297%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.525 (0.525)\tLoss 0.3003 (0.3003)\tPrec 89.062% (89.062%)\n",
      " * Prec 85.150% \n",
      "best acc: 87.060000\n",
      "Epoch: [57][0/391]\tTime 0.642 (0.642)\tData 0.545 (0.545)\tLoss 0.1722 (0.1722)\tPrec 93.750% (93.750%)\n",
      "Epoch: [57][100/391]\tTime 0.078 (0.090)\tData 0.002 (0.008)\tLoss 0.2590 (0.2283)\tPrec 92.188% (91.870%)\n",
      "Epoch: [57][200/391]\tTime 0.084 (0.089)\tData 0.002 (0.005)\tLoss 0.2289 (0.2299)\tPrec 92.969% (91.919%)\n",
      "Epoch: [57][300/391]\tTime 0.081 (0.089)\tData 0.002 (0.004)\tLoss 0.2667 (0.2341)\tPrec 90.625% (91.809%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 1.000 (1.000)\tLoss 0.3632 (0.3632)\tPrec 87.500% (87.500%)\n",
      " * Prec 86.730% \n",
      "best acc: 87.060000\n",
      "Epoch: [58][0/391]\tTime 0.778 (0.778)\tData 0.710 (0.710)\tLoss 0.1820 (0.1820)\tPrec 93.750% (93.750%)\n",
      "Epoch: [58][100/391]\tTime 0.084 (0.092)\tData 0.002 (0.009)\tLoss 0.1680 (0.2002)\tPrec 92.969% (93.069%)\n",
      "Epoch: [58][200/391]\tTime 0.084 (0.089)\tData 0.002 (0.006)\tLoss 0.2578 (0.2134)\tPrec 90.625% (92.514%)\n",
      "Epoch: [58][300/391]\tTime 0.083 (0.088)\tData 0.002 (0.004)\tLoss 0.2504 (0.2229)\tPrec 90.625% (92.091%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.525 (0.525)\tLoss 0.2947 (0.2947)\tPrec 86.719% (86.719%)\n",
      " * Prec 86.670% \n",
      "best acc: 87.060000\n",
      "Epoch: [59][0/391]\tTime 0.989 (0.989)\tData 0.916 (0.916)\tLoss 0.1701 (0.1701)\tPrec 95.312% (95.312%)\n",
      "Epoch: [59][100/391]\tTime 0.048 (0.089)\tData 0.002 (0.011)\tLoss 0.3169 (0.2179)\tPrec 89.062% (92.683%)\n",
      "Epoch: [59][200/391]\tTime 0.074 (0.092)\tData 0.002 (0.007)\tLoss 0.2129 (0.2139)\tPrec 92.188% (92.654%)\n",
      "Epoch: [59][300/391]\tTime 0.085 (0.090)\tData 0.002 (0.005)\tLoss 0.2448 (0.2164)\tPrec 89.844% (92.499%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.454 (0.454)\tLoss 0.3353 (0.3353)\tPrec 87.500% (87.500%)\n",
      " * Prec 86.890% \n",
      "best acc: 87.060000\n",
      "Epoch: [60][0/391]\tTime 1.024 (1.024)\tData 0.959 (0.959)\tLoss 0.3287 (0.3287)\tPrec 88.281% (88.281%)\n",
      "Epoch: [60][100/391]\tTime 0.080 (0.101)\tData 0.002 (0.012)\tLoss 0.1538 (0.2247)\tPrec 94.531% (92.048%)\n",
      "Epoch: [60][200/391]\tTime 0.085 (0.093)\tData 0.002 (0.007)\tLoss 0.3118 (0.2158)\tPrec 89.844% (92.506%)\n",
      "Epoch: [60][300/391]\tTime 0.084 (0.092)\tData 0.002 (0.005)\tLoss 0.2194 (0.2157)\tPrec 91.406% (92.468%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.468 (0.468)\tLoss 0.3360 (0.3360)\tPrec 89.844% (89.844%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Prec 86.000% \n",
      "best acc: 87.060000\n",
      "Epoch: [61][0/391]\tTime 0.624 (0.624)\tData 0.566 (0.566)\tLoss 0.1497 (0.1497)\tPrec 96.875% (96.875%)\n",
      "Epoch: [61][100/391]\tTime 0.084 (0.092)\tData 0.002 (0.007)\tLoss 0.1940 (0.2018)\tPrec 95.312% (93.062%)\n",
      "Epoch: [61][200/391]\tTime 0.087 (0.089)\tData 0.002 (0.006)\tLoss 0.3139 (0.2112)\tPrec 88.281% (92.615%)\n",
      "Epoch: [61][300/391]\tTime 0.090 (0.089)\tData 0.002 (0.004)\tLoss 0.2901 (0.2163)\tPrec 92.188% (92.455%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.499 (0.499)\tLoss 0.2348 (0.2348)\tPrec 88.281% (88.281%)\n",
      " * Prec 86.960% \n",
      "best acc: 87.060000\n",
      "Epoch: [62][0/391]\tTime 0.657 (0.657)\tData 0.590 (0.590)\tLoss 0.1531 (0.1531)\tPrec 92.969% (92.969%)\n",
      "Epoch: [62][100/391]\tTime 0.090 (0.093)\tData 0.002 (0.008)\tLoss 0.2172 (0.2106)\tPrec 91.406% (92.474%)\n",
      "Epoch: [62][200/391]\tTime 0.080 (0.089)\tData 0.002 (0.005)\tLoss 0.2888 (0.2158)\tPrec 88.281% (92.351%)\n",
      "Epoch: [62][300/391]\tTime 0.087 (0.089)\tData 0.002 (0.004)\tLoss 0.1957 (0.2171)\tPrec 93.750% (92.315%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.426 (0.426)\tLoss 0.2735 (0.2735)\tPrec 90.625% (90.625%)\n",
      " * Prec 86.520% \n",
      "best acc: 87.060000\n",
      "Epoch: [63][0/391]\tTime 0.957 (0.957)\tData 0.883 (0.883)\tLoss 0.2864 (0.2864)\tPrec 89.062% (89.062%)\n",
      "Epoch: [63][100/391]\tTime 0.088 (0.096)\tData 0.002 (0.011)\tLoss 0.1987 (0.2049)\tPrec 92.188% (92.760%)\n",
      "Epoch: [63][200/391]\tTime 0.048 (0.089)\tData 0.002 (0.006)\tLoss 0.2487 (0.2070)\tPrec 90.625% (92.677%)\n",
      "Epoch: [63][300/391]\tTime 0.084 (0.090)\tData 0.002 (0.005)\tLoss 0.3409 (0.2145)\tPrec 85.938% (92.338%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 1.337 (1.337)\tLoss 0.4778 (0.4778)\tPrec 86.719% (86.719%)\n",
      " * Prec 85.550% \n",
      "best acc: 87.060000\n",
      "Epoch: [64][0/391]\tTime 0.608 (0.608)\tData 0.513 (0.513)\tLoss 0.1423 (0.1423)\tPrec 93.750% (93.750%)\n",
      "Epoch: [64][100/391]\tTime 0.083 (0.092)\tData 0.002 (0.007)\tLoss 0.1418 (0.2056)\tPrec 96.094% (92.505%)\n",
      "Epoch: [64][200/391]\tTime 0.080 (0.089)\tData 0.002 (0.004)\tLoss 0.2062 (0.2116)\tPrec 89.844% (92.405%)\n",
      "Epoch: [64][300/391]\tTime 0.091 (0.087)\tData 0.002 (0.004)\tLoss 0.1916 (0.2130)\tPrec 92.188% (92.385%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.437 (0.437)\tLoss 0.4095 (0.4095)\tPrec 82.812% (82.812%)\n",
      " * Prec 84.530% \n",
      "best acc: 87.060000\n",
      "Epoch: [65][0/391]\tTime 0.682 (0.682)\tData 0.577 (0.577)\tLoss 0.2159 (0.2159)\tPrec 91.406% (91.406%)\n",
      "Epoch: [65][100/391]\tTime 0.096 (0.094)\tData 0.001 (0.008)\tLoss 0.2263 (0.1987)\tPrec 91.406% (92.806%)\n",
      "Epoch: [65][200/391]\tTime 0.054 (0.092)\tData 0.003 (0.005)\tLoss 0.2799 (0.2067)\tPrec 85.938% (92.565%)\n",
      "Epoch: [65][300/391]\tTime 0.090 (0.088)\tData 0.002 (0.004)\tLoss 0.1271 (0.2081)\tPrec 95.312% (92.535%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 1.034 (1.034)\tLoss 0.2704 (0.2704)\tPrec 91.406% (91.406%)\n",
      " * Prec 87.030% \n",
      "best acc: 87.060000\n",
      "Epoch: [66][0/391]\tTime 0.899 (0.899)\tData 0.827 (0.827)\tLoss 0.2142 (0.2142)\tPrec 91.406% (91.406%)\n",
      "Epoch: [66][100/391]\tTime 0.076 (0.095)\tData 0.002 (0.010)\tLoss 0.2887 (0.2061)\tPrec 88.281% (92.636%)\n",
      "Epoch: [66][200/391]\tTime 0.091 (0.091)\tData 0.003 (0.006)\tLoss 0.1819 (0.2102)\tPrec 92.969% (92.487%)\n",
      "Epoch: [66][300/391]\tTime 0.088 (0.089)\tData 0.002 (0.005)\tLoss 0.2310 (0.2102)\tPrec 92.969% (92.483%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 1.049 (1.049)\tLoss 0.3702 (0.3702)\tPrec 89.062% (89.062%)\n",
      " * Prec 86.380% \n",
      "best acc: 87.060000\n",
      "Epoch: [67][0/391]\tTime 0.788 (0.788)\tData 0.720 (0.720)\tLoss 0.2913 (0.2913)\tPrec 87.500% (87.500%)\n",
      "Epoch: [67][100/391]\tTime 0.092 (0.094)\tData 0.002 (0.009)\tLoss 0.2666 (0.1998)\tPrec 92.969% (93.108%)\n",
      "Epoch: [67][200/391]\tTime 0.082 (0.091)\tData 0.002 (0.005)\tLoss 0.1714 (0.2027)\tPrec 92.188% (92.875%)\n",
      "Epoch: [67][300/391]\tTime 0.090 (0.090)\tData 0.002 (0.005)\tLoss 0.1719 (0.2078)\tPrec 94.531% (92.657%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.596 (0.596)\tLoss 0.5068 (0.5068)\tPrec 82.812% (82.812%)\n",
      " * Prec 86.220% \n",
      "best acc: 87.060000\n",
      "Epoch: [68][0/391]\tTime 0.625 (0.625)\tData 0.533 (0.533)\tLoss 0.2488 (0.2488)\tPrec 91.406% (91.406%)\n",
      "Epoch: [68][100/391]\tTime 0.084 (0.092)\tData 0.002 (0.007)\tLoss 0.1119 (0.1902)\tPrec 96.875% (93.178%)\n",
      "Epoch: [68][200/391]\tTime 0.090 (0.090)\tData 0.002 (0.005)\tLoss 0.2341 (0.2053)\tPrec 92.969% (92.627%)\n",
      "Epoch: [68][300/391]\tTime 0.043 (0.089)\tData 0.002 (0.004)\tLoss 0.2347 (0.2108)\tPrec 90.625% (92.437%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.607 (0.607)\tLoss 0.2593 (0.2593)\tPrec 92.188% (92.188%)\n",
      " * Prec 87.660% \n",
      "best acc: 87.660000\n",
      "Epoch: [69][0/391]\tTime 1.601 (1.601)\tData 1.530 (1.530)\tLoss 0.1634 (0.1634)\tPrec 93.750% (93.750%)\n",
      "Epoch: [69][100/391]\tTime 0.076 (0.101)\tData 0.002 (0.017)\tLoss 0.2804 (0.1966)\tPrec 89.844% (92.938%)\n",
      "Epoch: [69][200/391]\tTime 0.083 (0.094)\tData 0.002 (0.009)\tLoss 0.2168 (0.1992)\tPrec 92.969% (92.724%)\n",
      "Epoch: [69][300/391]\tTime 0.080 (0.092)\tData 0.002 (0.007)\tLoss 0.1956 (0.2037)\tPrec 94.531% (92.686%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.540 (0.540)\tLoss 0.2587 (0.2587)\tPrec 90.625% (90.625%)\n",
      " * Prec 87.120% \n",
      "best acc: 87.660000\n",
      "Epoch: [70][0/391]\tTime 0.853 (0.853)\tData 0.785 (0.785)\tLoss 0.2190 (0.2190)\tPrec 92.188% (92.188%)\n",
      "Epoch: [70][100/391]\tTime 0.091 (0.096)\tData 0.002 (0.010)\tLoss 0.2183 (0.1920)\tPrec 92.188% (93.054%)\n",
      "Epoch: [70][200/391]\tTime 0.087 (0.092)\tData 0.002 (0.006)\tLoss 0.1603 (0.1941)\tPrec 92.969% (93.171%)\n",
      "Epoch: [70][300/391]\tTime 0.088 (0.091)\tData 0.002 (0.005)\tLoss 0.1202 (0.1940)\tPrec 95.312% (93.208%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.454 (0.454)\tLoss 0.3217 (0.3217)\tPrec 87.500% (87.500%)\n",
      " * Prec 85.760% \n",
      "best acc: 87.660000\n",
      "Epoch: [71][0/391]\tTime 0.612 (0.612)\tData 0.509 (0.509)\tLoss 0.1276 (0.1276)\tPrec 95.312% (95.312%)\n",
      "Epoch: [71][100/391]\tTime 0.090 (0.093)\tData 0.002 (0.007)\tLoss 0.1960 (0.1955)\tPrec 93.750% (93.239%)\n",
      "Epoch: [71][200/391]\tTime 0.076 (0.090)\tData 0.004 (0.004)\tLoss 0.1942 (0.2011)\tPrec 92.188% (92.934%)\n",
      "Epoch: [71][300/391]\tTime 0.085 (0.089)\tData 0.002 (0.004)\tLoss 0.1976 (0.2061)\tPrec 92.188% (92.733%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.473 (0.473)\tLoss 0.3051 (0.3051)\tPrec 92.188% (92.188%)\n",
      " * Prec 87.450% \n",
      "best acc: 87.660000\n",
      "Epoch: [72][0/391]\tTime 1.024 (1.024)\tData 0.949 (0.949)\tLoss 0.1661 (0.1661)\tPrec 94.531% (94.531%)\n",
      "Epoch: [72][100/391]\tTime 0.092 (0.097)\tData 0.002 (0.011)\tLoss 0.2483 (0.1845)\tPrec 91.406% (93.541%)\n",
      "Epoch: [72][200/391]\tTime 0.090 (0.093)\tData 0.002 (0.007)\tLoss 0.1949 (0.1929)\tPrec 91.406% (93.210%)\n",
      "Epoch: [72][300/391]\tTime 0.083 (0.091)\tData 0.002 (0.005)\tLoss 0.1709 (0.1993)\tPrec 93.750% (92.958%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.469 (0.469)\tLoss 0.2454 (0.2454)\tPrec 90.625% (90.625%)\n",
      " * Prec 87.950% \n",
      "best acc: 87.950000\n",
      "Epoch: [73][0/391]\tTime 0.724 (0.724)\tData 0.664 (0.664)\tLoss 0.1053 (0.1053)\tPrec 96.875% (96.875%)\n",
      "Epoch: [73][100/391]\tTime 0.082 (0.094)\tData 0.002 (0.008)\tLoss 0.2176 (0.1882)\tPrec 91.406% (93.038%)\n",
      "Epoch: [73][200/391]\tTime 0.099 (0.091)\tData 0.002 (0.005)\tLoss 0.1523 (0.1975)\tPrec 92.969% (92.891%)\n",
      "Epoch: [73][300/391]\tTime 0.090 (0.090)\tData 0.002 (0.004)\tLoss 0.2816 (0.2013)\tPrec 91.406% (92.855%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.826 (0.826)\tLoss 0.2848 (0.2848)\tPrec 91.406% (91.406%)\n",
      " * Prec 87.430% \n",
      "best acc: 87.950000\n",
      "Epoch: [74][0/391]\tTime 0.872 (0.872)\tData 0.804 (0.804)\tLoss 0.1647 (0.1647)\tPrec 96.094% (96.094%)\n",
      "Epoch: [74][100/391]\tTime 0.089 (0.095)\tData 0.003 (0.010)\tLoss 0.1947 (0.1940)\tPrec 93.750% (93.139%)\n",
      "Epoch: [74][200/391]\tTime 0.085 (0.091)\tData 0.002 (0.006)\tLoss 0.2261 (0.1948)\tPrec 90.625% (93.019%)\n",
      "Epoch: [74][300/391]\tTime 0.095 (0.090)\tData 0.002 (0.005)\tLoss 0.2987 (0.1988)\tPrec 91.406% (92.935%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.615 (0.615)\tLoss 0.2885 (0.2885)\tPrec 89.062% (89.062%)\n",
      " * Prec 87.100% \n",
      "best acc: 87.950000\n",
      "Epoch: [75][0/391]\tTime 0.777 (0.777)\tData 0.710 (0.710)\tLoss 0.1465 (0.1465)\tPrec 96.094% (96.094%)\n",
      "Epoch: [75][100/391]\tTime 0.084 (0.095)\tData 0.002 (0.009)\tLoss 0.1758 (0.1897)\tPrec 93.750% (93.201%)\n",
      "Epoch: [75][200/391]\tTime 0.085 (0.092)\tData 0.002 (0.005)\tLoss 0.1701 (0.1890)\tPrec 92.969% (93.245%)\n",
      "Epoch: [75][300/391]\tTime 0.099 (0.090)\tData 0.001 (0.004)\tLoss 0.1513 (0.1925)\tPrec 94.531% (93.086%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.637 (0.637)\tLoss 0.2539 (0.2539)\tPrec 90.625% (90.625%)\n",
      " * Prec 85.500% \n",
      "best acc: 87.950000\n",
      "Epoch: [76][0/391]\tTime 1.253 (1.253)\tData 0.619 (0.619)\tLoss 0.1085 (0.1085)\tPrec 96.875% (96.875%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [76][100/391]\tTime 0.086 (0.099)\tData 0.002 (0.008)\tLoss 0.2847 (0.1874)\tPrec 89.062% (93.332%)\n",
      "Epoch: [76][200/391]\tTime 0.089 (0.093)\tData 0.002 (0.005)\tLoss 0.1251 (0.1868)\tPrec 96.094% (93.311%)\n",
      "Epoch: [76][300/391]\tTime 0.095 (0.090)\tData 0.002 (0.004)\tLoss 0.1478 (0.1913)\tPrec 94.531% (93.233%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.421 (0.421)\tLoss 0.3073 (0.3073)\tPrec 87.500% (87.500%)\n",
      " * Prec 87.670% \n",
      "best acc: 87.950000\n",
      "Epoch: [77][0/391]\tTime 0.682 (0.682)\tData 0.615 (0.615)\tLoss 0.2127 (0.2127)\tPrec 92.188% (92.188%)\n",
      "Epoch: [77][100/391]\tTime 0.091 (0.093)\tData 0.002 (0.010)\tLoss 0.2661 (0.1913)\tPrec 92.969% (93.162%)\n",
      "Epoch: [77][200/391]\tTime 0.076 (0.090)\tData 0.002 (0.006)\tLoss 0.2522 (0.2021)\tPrec 89.062% (92.767%)\n",
      "Epoch: [77][300/391]\tTime 0.094 (0.089)\tData 0.002 (0.005)\tLoss 0.2321 (0.2036)\tPrec 91.406% (92.707%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.544 (0.544)\tLoss 0.2807 (0.2807)\tPrec 89.844% (89.844%)\n",
      " * Prec 85.960% \n",
      "best acc: 87.950000\n",
      "Epoch: [78][0/391]\tTime 1.184 (1.184)\tData 1.117 (1.117)\tLoss 0.1120 (0.1120)\tPrec 94.531% (94.531%)\n",
      "Epoch: [78][100/391]\tTime 0.088 (0.101)\tData 0.001 (0.014)\tLoss 0.1502 (0.1836)\tPrec 95.312% (93.526%)\n",
      "Epoch: [78][200/391]\tTime 0.083 (0.094)\tData 0.002 (0.008)\tLoss 0.1796 (0.1899)\tPrec 93.750% (93.268%)\n",
      "Epoch: [78][300/391]\tTime 0.090 (0.092)\tData 0.002 (0.006)\tLoss 0.2332 (0.1929)\tPrec 90.625% (93.127%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.425 (0.425)\tLoss 0.3639 (0.3639)\tPrec 90.625% (90.625%)\n",
      " * Prec 86.820% \n",
      "best acc: 87.950000\n",
      "Epoch: [79][0/391]\tTime 0.739 (0.739)\tData 0.674 (0.674)\tLoss 0.1339 (0.1339)\tPrec 94.531% (94.531%)\n",
      "Epoch: [79][100/391]\tTime 0.091 (0.095)\tData 0.003 (0.009)\tLoss 0.0947 (0.1822)\tPrec 98.438% (93.564%)\n",
      "Epoch: [79][200/391]\tTime 0.096 (0.091)\tData 0.002 (0.005)\tLoss 0.1429 (0.1876)\tPrec 96.094% (93.373%)\n",
      "Epoch: [79][300/391]\tTime 0.090 (0.090)\tData 0.002 (0.004)\tLoss 0.1898 (0.1915)\tPrec 94.531% (93.244%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.646 (0.646)\tLoss 0.3704 (0.3704)\tPrec 88.281% (88.281%)\n",
      " * Prec 85.840% \n",
      "best acc: 87.950000\n",
      "Epoch: [80][0/391]\tTime 0.923 (0.923)\tData 0.861 (0.861)\tLoss 0.2892 (0.2892)\tPrec 89.062% (89.062%)\n",
      "Epoch: [80][100/391]\tTime 0.074 (0.091)\tData 0.002 (0.011)\tLoss 0.1097 (0.1538)\tPrec 97.656% (94.554%)\n",
      "Epoch: [80][200/391]\tTime 0.091 (0.090)\tData 0.002 (0.006)\tLoss 0.1214 (0.1422)\tPrec 95.312% (94.998%)\n",
      "Epoch: [80][300/391]\tTime 0.076 (0.089)\tData 0.003 (0.005)\tLoss 0.1528 (0.1347)\tPrec 94.531% (95.364%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.450 (0.450)\tLoss 0.2071 (0.2071)\tPrec 92.969% (92.969%)\n",
      " * Prec 89.800% \n",
      "best acc: 89.800000\n",
      "Epoch: [81][0/391]\tTime 0.921 (0.921)\tData 0.854 (0.854)\tLoss 0.0856 (0.0856)\tPrec 96.875% (96.875%)\n",
      "Epoch: [81][100/391]\tTime 0.045 (0.091)\tData 0.002 (0.010)\tLoss 0.1468 (0.1132)\tPrec 96.094% (96.256%)\n",
      "Epoch: [81][200/391]\tTime 0.089 (0.090)\tData 0.002 (0.007)\tLoss 0.1624 (0.1122)\tPrec 95.312% (96.249%)\n",
      "Epoch: [81][300/391]\tTime 0.097 (0.089)\tData 0.001 (0.005)\tLoss 0.1098 (0.1124)\tPrec 96.094% (96.187%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 1.070 (1.070)\tLoss 0.1895 (0.1895)\tPrec 93.750% (93.750%)\n",
      " * Prec 90.220% \n",
      "best acc: 90.220000\n",
      "Epoch: [82][0/391]\tTime 0.800 (0.800)\tData 0.711 (0.711)\tLoss 0.1130 (0.1130)\tPrec 95.312% (95.312%)\n",
      "Epoch: [82][100/391]\tTime 0.068 (0.099)\tData 0.002 (0.009)\tLoss 0.0890 (0.0982)\tPrec 97.656% (96.720%)\n",
      "Epoch: [82][200/391]\tTime 0.090 (0.093)\tData 0.002 (0.005)\tLoss 0.1190 (0.1001)\tPrec 95.312% (96.603%)\n",
      "Epoch: [82][300/391]\tTime 0.093 (0.091)\tData 0.002 (0.004)\tLoss 0.0968 (0.0989)\tPrec 96.875% (96.641%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.592 (0.592)\tLoss 0.1530 (0.1530)\tPrec 94.531% (94.531%)\n",
      " * Prec 90.290% \n",
      "best acc: 90.290000\n",
      "Epoch: [83][0/391]\tTime 0.774 (0.774)\tData 0.718 (0.718)\tLoss 0.0296 (0.0296)\tPrec 100.000% (100.000%)\n",
      "Epoch: [83][100/391]\tTime 0.087 (0.094)\tData 0.002 (0.009)\tLoss 0.1015 (0.1035)\tPrec 96.875% (96.411%)\n",
      "Epoch: [83][200/391]\tTime 0.090 (0.091)\tData 0.002 (0.006)\tLoss 0.0978 (0.0983)\tPrec 97.656% (96.642%)\n",
      "Epoch: [83][300/391]\tTime 0.092 (0.090)\tData 0.002 (0.004)\tLoss 0.1480 (0.0969)\tPrec 94.531% (96.706%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.462 (0.462)\tLoss 0.1267 (0.1267)\tPrec 95.312% (95.312%)\n",
      " * Prec 90.090% \n",
      "best acc: 90.290000\n",
      "Epoch: [84][0/391]\tTime 0.671 (0.671)\tData 0.580 (0.580)\tLoss 0.0742 (0.0742)\tPrec 97.656% (97.656%)\n",
      "Epoch: [84][100/391]\tTime 0.092 (0.094)\tData 0.002 (0.008)\tLoss 0.0769 (0.0897)\tPrec 97.656% (97.138%)\n",
      "Epoch: [84][200/391]\tTime 0.087 (0.091)\tData 0.002 (0.005)\tLoss 0.0948 (0.0933)\tPrec 96.875% (96.906%)\n",
      "Epoch: [84][300/391]\tTime 0.071 (0.089)\tData 0.002 (0.004)\tLoss 0.0753 (0.0928)\tPrec 96.875% (96.906%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.568 (0.568)\tLoss 0.1433 (0.1433)\tPrec 94.531% (94.531%)\n",
      " * Prec 90.200% \n",
      "best acc: 90.290000\n",
      "Epoch: [85][0/391]\tTime 0.664 (0.664)\tData 0.601 (0.601)\tLoss 0.1255 (0.1255)\tPrec 95.312% (95.312%)\n",
      "Epoch: [85][100/391]\tTime 0.090 (0.093)\tData 0.002 (0.008)\tLoss 0.1043 (0.0912)\tPrec 96.094% (97.022%)\n",
      "Epoch: [85][200/391]\tTime 0.091 (0.091)\tData 0.002 (0.005)\tLoss 0.0824 (0.0902)\tPrec 96.875% (97.007%)\n",
      "Epoch: [85][300/391]\tTime 0.094 (0.089)\tData 0.002 (0.004)\tLoss 0.1376 (0.0911)\tPrec 93.750% (96.927%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.437 (0.437)\tLoss 0.1208 (0.1208)\tPrec 96.094% (96.094%)\n",
      " * Prec 90.070% \n",
      "best acc: 90.290000\n",
      "Epoch: [86][0/391]\tTime 0.820 (0.820)\tData 0.717 (0.717)\tLoss 0.1293 (0.1293)\tPrec 94.531% (94.531%)\n",
      "Epoch: [86][100/391]\tTime 0.083 (0.095)\tData 0.002 (0.009)\tLoss 0.1341 (0.0831)\tPrec 96.094% (97.386%)\n",
      "Epoch: [86][200/391]\tTime 0.092 (0.091)\tData 0.002 (0.005)\tLoss 0.0784 (0.0811)\tPrec 96.875% (97.373%)\n",
      "Epoch: [86][300/391]\tTime 0.091 (0.090)\tData 0.002 (0.004)\tLoss 0.0619 (0.0838)\tPrec 98.438% (97.254%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.647 (0.647)\tLoss 0.1250 (0.1250)\tPrec 96.875% (96.875%)\n",
      " * Prec 90.390% \n",
      "best acc: 90.390000\n",
      "Epoch: [87][0/391]\tTime 1.021 (1.021)\tData 0.958 (0.958)\tLoss 0.0326 (0.0326)\tPrec 100.000% (100.000%)\n",
      "Epoch: [87][100/391]\tTime 0.093 (0.097)\tData 0.002 (0.011)\tLoss 0.0800 (0.0806)\tPrec 95.312% (97.424%)\n",
      "Epoch: [87][200/391]\tTime 0.045 (0.090)\tData 0.002 (0.007)\tLoss 0.0723 (0.0824)\tPrec 97.656% (97.275%)\n",
      "Epoch: [87][300/391]\tTime 0.093 (0.091)\tData 0.002 (0.005)\tLoss 0.0912 (0.0857)\tPrec 95.312% (97.116%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.390 (0.390)\tLoss 0.1244 (0.1244)\tPrec 95.312% (95.312%)\n",
      " * Prec 90.430% \n",
      "best acc: 90.430000\n",
      "Epoch: [88][0/391]\tTime 0.683 (0.683)\tData 0.591 (0.591)\tLoss 0.1085 (0.1085)\tPrec 96.875% (96.875%)\n",
      "Epoch: [88][100/391]\tTime 0.089 (0.092)\tData 0.002 (0.008)\tLoss 0.0497 (0.0824)\tPrec 97.656% (97.316%)\n",
      "Epoch: [88][200/391]\tTime 0.079 (0.092)\tData 0.002 (0.005)\tLoss 0.0694 (0.0831)\tPrec 97.656% (97.201%)\n",
      "Epoch: [88][300/391]\tTime 0.083 (0.091)\tData 0.002 (0.004)\tLoss 0.1105 (0.0840)\tPrec 97.656% (97.199%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.859 (0.859)\tLoss 0.1805 (0.1805)\tPrec 93.750% (93.750%)\n",
      " * Prec 90.310% \n",
      "best acc: 90.430000\n",
      "Epoch: [89][0/391]\tTime 0.638 (0.638)\tData 0.538 (0.538)\tLoss 0.0335 (0.0335)\tPrec 99.219% (99.219%)\n",
      "Epoch: [89][100/391]\tTime 0.085 (0.093)\tData 0.002 (0.007)\tLoss 0.0608 (0.0765)\tPrec 97.656% (97.486%)\n",
      "Epoch: [89][200/391]\tTime 0.079 (0.093)\tData 0.002 (0.005)\tLoss 0.1372 (0.0783)\tPrec 93.750% (97.388%)\n",
      "Epoch: [89][300/391]\tTime 0.085 (0.090)\tData 0.004 (0.004)\tLoss 0.0803 (0.0813)\tPrec 96.875% (97.293%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.435 (0.435)\tLoss 0.1327 (0.1327)\tPrec 94.531% (94.531%)\n",
      " * Prec 90.530% \n",
      "best acc: 90.530000\n",
      "Epoch: [90][0/391]\tTime 0.677 (0.677)\tData 0.571 (0.571)\tLoss 0.0625 (0.0625)\tPrec 98.438% (98.438%)\n",
      "Epoch: [90][100/391]\tTime 0.086 (0.093)\tData 0.002 (0.008)\tLoss 0.0744 (0.0794)\tPrec 96.875% (97.262%)\n",
      "Epoch: [90][200/391]\tTime 0.081 (0.090)\tData 0.002 (0.005)\tLoss 0.1000 (0.0797)\tPrec 95.312% (97.252%)\n",
      "Epoch: [90][300/391]\tTime 0.081 (0.088)\tData 0.002 (0.004)\tLoss 0.0206 (0.0795)\tPrec 100.000% (97.288%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.646 (0.646)\tLoss 0.1706 (0.1706)\tPrec 94.531% (94.531%)\n",
      " * Prec 90.430% \n",
      "best acc: 90.530000\n",
      "Epoch: [91][0/391]\tTime 0.885 (0.885)\tData 0.822 (0.822)\tLoss 0.0822 (0.0822)\tPrec 98.438% (98.438%)\n",
      "Epoch: [91][100/391]\tTime 0.079 (0.096)\tData 0.002 (0.010)\tLoss 0.0610 (0.0792)\tPrec 98.438% (97.308%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [91][200/391]\tTime 0.089 (0.092)\tData 0.002 (0.006)\tLoss 0.1140 (0.0775)\tPrec 96.875% (97.388%)\n",
      "Epoch: [91][300/391]\tTime 0.090 (0.090)\tData 0.002 (0.005)\tLoss 0.0569 (0.0754)\tPrec 97.656% (97.501%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.446 (0.446)\tLoss 0.1526 (0.1526)\tPrec 95.312% (95.312%)\n",
      " * Prec 90.490% \n",
      "best acc: 90.530000\n",
      "Epoch: [92][0/391]\tTime 0.569 (0.569)\tData 0.503 (0.503)\tLoss 0.1323 (0.1323)\tPrec 95.312% (95.312%)\n",
      "Epoch: [92][100/391]\tTime 0.087 (0.092)\tData 0.002 (0.007)\tLoss 0.0739 (0.0696)\tPrec 96.875% (97.703%)\n",
      "Epoch: [92][200/391]\tTime 0.085 (0.090)\tData 0.002 (0.004)\tLoss 0.1183 (0.0729)\tPrec 93.750% (97.512%)\n",
      "Epoch: [92][300/391]\tTime 0.128 (0.089)\tData 0.086 (0.004)\tLoss 0.0859 (0.0729)\tPrec 96.875% (97.508%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.499 (0.499)\tLoss 0.1693 (0.1693)\tPrec 95.312% (95.312%)\n",
      " * Prec 90.270% \n",
      "best acc: 90.530000\n",
      "Epoch: [93][0/391]\tTime 0.695 (0.695)\tData 0.647 (0.647)\tLoss 0.0644 (0.0644)\tPrec 98.438% (98.438%)\n",
      "Epoch: [93][100/391]\tTime 0.091 (0.093)\tData 0.002 (0.008)\tLoss 0.0665 (0.0707)\tPrec 96.875% (97.664%)\n",
      "Epoch: [93][200/391]\tTime 0.087 (0.090)\tData 0.002 (0.005)\tLoss 0.1269 (0.0739)\tPrec 96.875% (97.516%)\n",
      "Epoch: [93][300/391]\tTime 0.083 (0.090)\tData 0.001 (0.004)\tLoss 0.0524 (0.0741)\tPrec 98.438% (97.472%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.521 (0.521)\tLoss 0.1119 (0.1119)\tPrec 94.531% (94.531%)\n",
      " * Prec 90.160% \n",
      "best acc: 90.530000\n",
      "Epoch: [94][0/391]\tTime 0.600 (0.600)\tData 0.517 (0.517)\tLoss 0.0502 (0.0502)\tPrec 99.219% (99.219%)\n",
      "Epoch: [94][100/391]\tTime 0.089 (0.093)\tData 0.002 (0.007)\tLoss 0.0624 (0.0702)\tPrec 96.875% (97.517%)\n",
      "Epoch: [94][200/391]\tTime 0.092 (0.091)\tData 0.002 (0.005)\tLoss 0.0716 (0.0707)\tPrec 96.094% (97.551%)\n",
      "Epoch: [94][300/391]\tTime 0.083 (0.090)\tData 0.002 (0.004)\tLoss 0.0643 (0.0720)\tPrec 96.875% (97.506%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.561 (0.561)\tLoss 0.1629 (0.1629)\tPrec 92.969% (92.969%)\n",
      " * Prec 90.140% \n",
      "best acc: 90.530000\n",
      "Epoch: [95][0/391]\tTime 0.726 (0.726)\tData 0.672 (0.672)\tLoss 0.0416 (0.0416)\tPrec 99.219% (99.219%)\n",
      "Epoch: [95][100/391]\tTime 0.083 (0.094)\tData 0.001 (0.009)\tLoss 0.0588 (0.0733)\tPrec 98.438% (97.525%)\n",
      "Epoch: [95][200/391]\tTime 0.083 (0.091)\tData 0.002 (0.005)\tLoss 0.0722 (0.0709)\tPrec 99.219% (97.555%)\n",
      "Epoch: [95][300/391]\tTime 0.083 (0.090)\tData 0.002 (0.004)\tLoss 0.0345 (0.0720)\tPrec 99.219% (97.526%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.654 (0.654)\tLoss 0.1207 (0.1207)\tPrec 95.312% (95.312%)\n",
      " * Prec 90.220% \n",
      "best acc: 90.530000\n",
      "Epoch: [96][0/391]\tTime 0.768 (0.768)\tData 0.701 (0.701)\tLoss 0.0935 (0.0935)\tPrec 98.438% (98.438%)\n",
      "Epoch: [96][100/391]\tTime 0.093 (0.095)\tData 0.002 (0.009)\tLoss 0.0585 (0.0731)\tPrec 99.219% (97.517%)\n",
      "Epoch: [96][200/391]\tTime 0.091 (0.091)\tData 0.004 (0.005)\tLoss 0.0862 (0.0698)\tPrec 98.438% (97.645%)\n",
      "Epoch: [96][300/391]\tTime 0.083 (0.090)\tData 0.002 (0.004)\tLoss 0.0792 (0.0693)\tPrec 96.094% (97.672%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.650 (0.650)\tLoss 0.1450 (0.1450)\tPrec 95.312% (95.312%)\n",
      " * Prec 90.150% \n",
      "best acc: 90.530000\n",
      "Epoch: [97][0/391]\tTime 0.560 (0.560)\tData 0.512 (0.512)\tLoss 0.0286 (0.0286)\tPrec 100.000% (100.000%)\n",
      "Epoch: [97][100/391]\tTime 0.094 (0.093)\tData 0.002 (0.007)\tLoss 0.1142 (0.0667)\tPrec 96.094% (97.687%)\n",
      "Epoch: [97][200/391]\tTime 0.092 (0.090)\tData 0.002 (0.005)\tLoss 0.0668 (0.0670)\tPrec 98.438% (97.691%)\n",
      "Epoch: [97][300/391]\tTime 0.088 (0.089)\tData 0.002 (0.004)\tLoss 0.0742 (0.0690)\tPrec 96.875% (97.646%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 1.353 (1.353)\tLoss 0.1306 (0.1306)\tPrec 94.531% (94.531%)\n",
      " * Prec 90.070% \n",
      "best acc: 90.530000\n",
      "Epoch: [98][0/391]\tTime 0.729 (0.729)\tData 0.626 (0.626)\tLoss 0.0411 (0.0411)\tPrec 98.438% (98.438%)\n",
      "Epoch: [98][100/391]\tTime 0.090 (0.095)\tData 0.002 (0.008)\tLoss 0.0288 (0.0680)\tPrec 100.000% (97.726%)\n",
      "Epoch: [98][200/391]\tTime 0.086 (0.091)\tData 0.002 (0.005)\tLoss 0.1713 (0.0672)\tPrec 94.531% (97.765%)\n",
      "Epoch: [98][300/391]\tTime 0.090 (0.090)\tData 0.001 (0.004)\tLoss 0.0576 (0.0693)\tPrec 99.219% (97.685%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.711 (0.711)\tLoss 0.1106 (0.1106)\tPrec 95.312% (95.312%)\n",
      " * Prec 90.090% \n",
      "best acc: 90.530000\n",
      "Epoch: [99][0/391]\tTime 0.729 (0.729)\tData 0.666 (0.666)\tLoss 0.0694 (0.0694)\tPrec 97.656% (97.656%)\n",
      "Epoch: [99][100/391]\tTime 0.083 (0.092)\tData 0.001 (0.008)\tLoss 0.1175 (0.0653)\tPrec 96.875% (97.819%)\n",
      "Epoch: [99][200/391]\tTime 0.088 (0.089)\tData 0.001 (0.005)\tLoss 0.0270 (0.0636)\tPrec 99.219% (97.913%)\n",
      "Epoch: [99][300/391]\tTime 0.079 (0.088)\tData 0.002 (0.004)\tLoss 0.0945 (0.0646)\tPrec 96.094% (97.843%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.735 (0.735)\tLoss 0.1783 (0.1783)\tPrec 93.750% (93.750%)\n",
      " * Prec 90.440% \n",
      "best acc: 90.530000\n"
     ]
    }
   ],
   "source": [
    "# This cell won't be given, but students will complete the training\n",
    "\n",
    "lr = 4e-2\n",
    "weight_decay = 1e-4\n",
    "epochs = 100\n",
    "best_prec = 0\n",
    "\n",
    "#model = nn.DataParallel(model).cuda()\n",
    "model.cuda()\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay)\n",
    "#cudnn.benchmark = True\n",
    "\n",
    "if not os.path.exists('result'):\n",
    "    os.makedirs('result')\n",
    "fdir = 'result/'+str(model_name) + \"_2bit\"\n",
    "if not os.path.exists(fdir):\n",
    "    os.makedirs(fdir)\n",
    "        \n",
    "\n",
    "for epoch in range(0, epochs):\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "\n",
    "    train(trainloader, model, criterion, optimizer, epoch)\n",
    "    \n",
    "    # evaluate on test set\n",
    "    print(\"Validation starts\")\n",
    "    prec = validate(testloader, model, criterion)\n",
    "\n",
    "    # remember best precision and save checkpoint\n",
    "    is_best = prec > best_prec\n",
    "    best_prec = max(prec,best_prec)\n",
    "    print('best acc: {:1f}'.format(best_prec))\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_prec': best_prec,\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }, is_best, fdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decreased-harris",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HW\n",
    "\n",
    "#  1. Train with 4 bits for both weight and activation to achieve >90% accuracy\n",
    "#  2. Find x_int and w_int for the 2nd convolution layer\n",
    "#  3. Check the recovered psum has similar value to the un-quantized original psum\n",
    "#     (such as example 1 in W3S2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "entertaining-queensland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Accuracy: 9053/10000 (91%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#PATH = \"result/VGG16_quant/model_best.pth.tar\"\n",
    "PATH = \"result/resnet20_quant_2bit/model_best.pth.tar\"\n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "device = torch.device(\"cuda\") \n",
    "\n",
    "model.cuda()\n",
    "model.eval()\n",
    "\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in testloader:\n",
    "        data, target = data.to(device), target.to(device) # loading to GPU\n",
    "        output = model(data)\n",
    "        pred = output.argmax(dim=1, keepdim=True)  \n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "test_loss /= len(testloader.dataset)\n",
    "\n",
    "print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        correct, len(testloader.dataset),\n",
    "        100. * correct / len(testloader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ceramic-nigeria",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prehooked\n",
      "prehooked\n",
      "prehooked\n",
      "prehooked\n",
      "prehooked\n",
      "prehooked\n",
      "prehooked\n",
      "prehooked\n",
      "prehooked\n",
      "prehooked\n",
      "prehooked\n",
      "prehooked\n",
      "prehooked\n",
      "prehooked\n",
      "prehooked\n",
      "prehooked\n",
      "prehooked\n",
      "prehooked\n",
      "prehooked\n",
      "prehooked\n",
      "prehooked\n",
      "1st convolution's input size: torch.Size([128, 3, 32, 32])\n",
      "2nd convolution's input size: torch.Size([128, 16, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "#send an input and grap the value by using prehook like HW3\n",
    "class SaveOutput:\n",
    "    def __init__(self):\n",
    "        self.outputs = []\n",
    "    def __call__(self, module, module_in):\n",
    "        self.outputs.append(module_in)\n",
    "    def clear(self):\n",
    "        self.outputs = []  \n",
    "        \n",
    "######### Save inputs from selected layer ##########\n",
    "save_output = SaveOutput()\n",
    "\n",
    "for layer in model.modules():\n",
    "    if isinstance(layer, torch.nn.Conv2d):\n",
    "        print(\"prehooked\")\n",
    "        layer.register_forward_pre_hook(save_output)       ## Input for the module will be grapped       \n",
    "####################################################\n",
    "\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "images = images.to(device)\n",
    "out = model(images)\n",
    "print(\"1st convolution's input size:\", save_output.outputs[0][0].size())\n",
    "print(\"2nd convolution's input size:\", save_output.outputs[1][0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a405dc6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d66166e",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2= model.layer1[0].conv1\n",
    "#print(conv2.weight_q)\n",
    "#print(conv2.weight_quant.wgt_alpha.data.item())\n",
    "#print(conv2.weight_quant.wgt_alpha.data.item()/ (2**4 - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "spoken-worst",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-0.0000,  0.1429, -1.0000],\n",
      "          [ 0.5714,  1.0000, -1.0000],\n",
      "          [-0.0000,  0.2857, -0.2857]],\n",
      "\n",
      "         [[-0.2857,  0.5714,  0.4286],\n",
      "          [-0.7143, -0.1429,  0.2857],\n",
      "          [-0.4286, -0.7143,  0.1429]],\n",
      "\n",
      "         [[ 1.0000, -0.1429, -0.1429],\n",
      "          [ 0.8571, -0.4286, -0.4286],\n",
      "          [-0.0000, -0.4286, -0.2857]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.5714, -0.1429, -0.2857],\n",
      "          [-0.8571,  1.0000, -0.4286],\n",
      "          [-0.1429, -0.1429, -0.7143]],\n",
      "\n",
      "         [[ 0.4286,  0.1429,  0.0000],\n",
      "          [ 0.2857, -0.1429, -0.1429],\n",
      "          [ 0.1429, -0.1429, -0.7143]],\n",
      "\n",
      "         [[ 0.1429,  0.1429,  0.4286],\n",
      "          [ 0.1429,  0.0000,  0.1429],\n",
      "          [-0.1429, -0.2857,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1429,  0.8571,  1.0000],\n",
      "          [-0.2857,  0.2857,  0.8571],\n",
      "          [-0.8571, -0.2857,  0.1429]],\n",
      "\n",
      "         [[-0.0000,  0.1429,  0.1429],\n",
      "          [ 0.0000, -0.0000, -0.2857],\n",
      "          [ 0.2857, -0.1429, -0.2857]],\n",
      "\n",
      "         [[-0.1429, -1.0000, -0.5714],\n",
      "          [ 0.2857, -0.5714, -1.0000],\n",
      "          [ 1.0000,  0.1429, -0.5714]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1429, -0.4286,  0.0000],\n",
      "          [ 0.2857, -0.4286, -0.2857],\n",
      "          [ 0.4286, -0.1429, -0.1429]],\n",
      "\n",
      "         [[ 0.1429, -0.0000,  0.0000],\n",
      "          [ 0.0000,  0.1429,  0.0000],\n",
      "          [-0.5714, -0.4286, -0.2857]],\n",
      "\n",
      "         [[ 0.1429,  0.2857,  0.0000],\n",
      "          [ 0.0000,  0.1429, -0.1429],\n",
      "          [-0.1429, -0.2857, -0.4286]]],\n",
      "\n",
      "\n",
      "        [[[-0.2857, -0.4286, -0.2857],\n",
      "          [-0.1429, -0.4286, -0.5714],\n",
      "          [-0.2857, -0.2857, -0.5714]],\n",
      "\n",
      "         [[-0.2857, -0.1429, -0.1429],\n",
      "          [-0.8571, -0.4286, -0.1429],\n",
      "          [-0.4286, -0.4286,  0.1429]],\n",
      "\n",
      "         [[-0.1429, -0.4286, -0.1429],\n",
      "          [ 0.2857, -0.2857, -0.2857],\n",
      "          [ 0.5714,  0.1429, -0.4286]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1429, -0.2857, -0.8571],\n",
      "          [ 0.0000, -0.2857, -0.1429],\n",
      "          [ 0.5714,  0.1429, -0.1429]],\n",
      "\n",
      "         [[-0.4286, -0.1429,  0.4286],\n",
      "          [-0.4286, -0.1429, -0.2857],\n",
      "          [-0.4286, -0.2857,  0.1429]],\n",
      "\n",
      "         [[-0.2857, -0.4286, -0.4286],\n",
      "          [ 0.0000, -0.1429,  0.1429],\n",
      "          [ 0.4286,  0.5714,  0.5714]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.4286,  0.1429, -0.1429],\n",
      "          [ 0.4286, -0.0000, -0.7143],\n",
      "          [-0.5714, -0.8571, -1.0000]],\n",
      "\n",
      "         [[-0.4286, -0.0000,  0.1429],\n",
      "          [-0.2857, -0.1429, -0.2857],\n",
      "          [-0.1429, -0.2857, -0.2857]],\n",
      "\n",
      "         [[-0.1429, -0.5714, -0.4286],\n",
      "          [-0.1429, -0.4286, -0.1429],\n",
      "          [ 0.5714,  0.4286,  0.5714]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4286,  0.1429, -0.1429],\n",
      "          [-0.1429,  0.4286, -0.1429],\n",
      "          [ 0.2857,  0.2857, -0.0000]],\n",
      "\n",
      "         [[-0.2857,  0.0000,  0.1429],\n",
      "          [-0.1429, -0.1429, -0.0000],\n",
      "          [-0.0000, -0.2857, -0.0000]],\n",
      "\n",
      "         [[ 0.2857, -0.2857, -0.2857],\n",
      "          [ 0.2857, -0.2857, -0.2857],\n",
      "          [ 0.4286, -0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000, -0.4286, -0.2857],\n",
      "          [ 0.1429, -0.2857, -0.4286],\n",
      "          [ 0.1429,  0.0000, -0.1429]],\n",
      "\n",
      "         [[-0.0000, -0.1429,  0.1429],\n",
      "          [-0.1429,  0.0000,  0.1429],\n",
      "          [ 0.0000, -0.0000,  0.2857]],\n",
      "\n",
      "         [[ 0.2857,  0.1429,  0.0000],\n",
      "          [ 0.1429,  0.0000,  0.1429],\n",
      "          [-0.0000,  0.1429,  0.1429]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1429, -0.0000, -0.2857],\n",
      "          [ 0.1429,  0.1429,  0.1429],\n",
      "          [ 0.1429,  0.1429, -0.1429]],\n",
      "\n",
      "         [[ 0.2857,  0.2857,  0.1429],\n",
      "          [-0.0000,  0.1429,  0.1429],\n",
      "          [ 0.1429,  0.1429,  0.1429]],\n",
      "\n",
      "         [[ 0.4286,  0.5714,  0.2857],\n",
      "          [ 0.7143,  0.5714,  0.2857],\n",
      "          [ 0.4286,  0.4286,  0.2857]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2857,  0.2857, -0.1429],\n",
      "          [ 0.4286,  0.0000, -0.1429],\n",
      "          [ 0.1429, -0.1429, -0.4286]],\n",
      "\n",
      "         [[-0.2857, -0.1429,  0.1429],\n",
      "          [ 0.0000,  0.2857,  0.5714],\n",
      "          [-0.1429,  0.0000,  0.5714]],\n",
      "\n",
      "         [[-0.5714,  0.1429,  0.2857],\n",
      "          [-0.7143, -0.1429,  0.2857],\n",
      "          [-0.4286,  0.4286,  0.5714]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.8571, -0.1429,  0.1429],\n",
      "          [ 0.1429,  0.2857,  0.2857],\n",
      "          [-0.0000, -0.0000,  0.5714]],\n",
      "\n",
      "         [[ 0.1429,  0.1429,  0.0000],\n",
      "          [ 0.1429,  0.1429,  0.2857],\n",
      "          [ 0.2857,  0.4286,  0.1429]],\n",
      "\n",
      "         [[-0.1429, -0.0000, -0.2857],\n",
      "          [-0.5714, -0.2857, -0.4286],\n",
      "          [-0.5714, -0.5714, -0.4286]]]], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "w_bit = 2\n",
    "#weight_q = model.features[3].weight_q # quantized value is stored during the training\n",
    "\n",
    "weight_q = conv2.weight_q\n",
    "w_alpha = conv2.weight_quant.wgt_alpha.data.item()\n",
    "w_delta = w_alpha / (2**(w_bit - 1) - 1)\n",
    "weight_int = weight_q / w_delta\n",
    "print(weight_int) # you should see clean integer numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3a987d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(save_output.outputs[1][0])\n",
    "#print(conv2.act_alpha.data.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "interior-oxygen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1., 1., 0.,  ..., 1., 1., 1.],\n",
      "          [1., 0., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [0., 1., 1.,  ..., 1., 1., 2.],\n",
      "          [0., 1., 1.,  ..., 1., 1., 2.],\n",
      "          [0., 1., 1.,  ..., 1., 1., 2.]],\n",
      "\n",
      "         [[1., 1., 0.,  ..., 0., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 0., 0., 1.],\n",
      "          [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [2., 2., 2.,  ..., 2., 2., 0.]],\n",
      "\n",
      "         [[1., 0., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 0., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [0., 1., 1.,  ..., 1., 1., 3.],\n",
      "          [0., 1., 1.,  ..., 1., 1., 3.],\n",
      "          [1., 2., 2.,  ..., 2., 2., 3.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[2., 1., 1.,  ..., 1., 1., 2.],\n",
      "          [2., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [2., 1., 1.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 1., 1.,  ..., 1., 1., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [2., 2., 2.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[0., 1., 1.,  ..., 0., 0., 2.],\n",
      "          [0., 1., 1.,  ..., 0., 0., 2.],\n",
      "          [0., 1., 1.,  ..., 0., 0., 2.],\n",
      "          ...,\n",
      "          [1., 0., 0.,  ..., 0., 0., 2.],\n",
      "          [2., 1., 1.,  ..., 0., 0., 2.],\n",
      "          [2., 1., 1.,  ..., 0., 0., 2.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 2., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "          [1., 1., 1.,  ..., 1., 0., 0.],\n",
      "          ...,\n",
      "          [2., 2., 2.,  ..., 3., 0., 0.],\n",
      "          [1., 1., 1.,  ..., 3., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 2., 2., 0.]],\n",
      "\n",
      "         [[1., 1., 1.,  ..., 0., 1., 3.],\n",
      "          [1., 1., 1.,  ..., 0., 1., 3.],\n",
      "          [1., 1., 1.,  ..., 0., 1., 3.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 0., 0., 3.],\n",
      "          [1., 1., 1.,  ..., 0., 0., 3.],\n",
      "          [1., 1., 1.,  ..., 0., 1., 3.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0., 0., 0.,  ..., 2., 0., 0.],\n",
      "          [0., 1., 1.,  ..., 2., 0., 0.],\n",
      "          [0., 1., 1.,  ..., 1., 0., 0.],\n",
      "          ...,\n",
      "          [1., 1., 0.,  ..., 3., 0., 0.],\n",
      "          [2., 2., 2.,  ..., 3., 0., 0.],\n",
      "          [3., 2., 2.,  ..., 1., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 1.,  ..., 0., 2., 2.],\n",
      "          [0., 0., 0.,  ..., 0., 1., 1.],\n",
      "          [0., 0., 0.,  ..., 0., 1., 1.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 1., 1.],\n",
      "          [0., 0., 0.,  ..., 0., 1., 1.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[1., 1., 1.,  ..., 0., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 0., 1., 1.],\n",
      "          [1., 0., 0.,  ..., 0., 1., 1.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 1., 1.],\n",
      "          [0., 0., 0.,  ..., 0., 1., 1.],\n",
      "          [0., 0., 0.,  ..., 0., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[0., 1., 1.,  ..., 0., 0., 1.],\n",
      "          [0., 2., 2.,  ..., 0., 0., 2.],\n",
      "          [0., 2., 2.,  ..., 0., 1., 2.],\n",
      "          ...,\n",
      "          [0., 1., 1.,  ..., 1., 1., 2.],\n",
      "          [0., 1., 1.,  ..., 1., 1., 2.],\n",
      "          [0., 1., 1.,  ..., 1., 1., 2.]],\n",
      "\n",
      "         [[0., 0., 1.,  ..., 1., 1., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [1., 0., 0.,  ..., 0., 1., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [2., 2., 2.,  ..., 2., 2., 0.]],\n",
      "\n",
      "         [[1., 1., 1.,  ..., 0., 0., 3.],\n",
      "          [1., 2., 1.,  ..., 1., 1., 3.],\n",
      "          [0., 1., 1.,  ..., 2., 1., 3.],\n",
      "          ...,\n",
      "          [0., 1., 1.,  ..., 1., 1., 3.],\n",
      "          [0., 1., 1.,  ..., 1., 1., 3.],\n",
      "          [1., 2., 2.,  ..., 2., 2., 3.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0., 0., 1.,  ..., 1., 0., 0.],\n",
      "          [0., 0., 2.,  ..., 1., 1., 0.],\n",
      "          [0., 1., 1.,  ..., 0., 1., 0.],\n",
      "          ...,\n",
      "          [0., 1., 1.,  ..., 1., 1., 0.],\n",
      "          [0., 1., 1.,  ..., 1., 1., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[1., 1., 1.,  ..., 0., 1., 1.],\n",
      "          [1., 0., 0.,  ..., 0., 0., 1.],\n",
      "          [0., 0., 0.,  ..., 1., 0., 1.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[2., 2., 2.,  ..., 0., 0., 2.],\n",
      "          [2., 1., 2.,  ..., 0., 0., 2.],\n",
      "          [2., 1., 1.,  ..., 0., 0., 2.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 0., 0., 2.],\n",
      "          [1., 1., 1.,  ..., 0., 0., 2.],\n",
      "          [1., 1., 1.,  ..., 0., 0., 2.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 3., 1., 0.],\n",
      "          [1., 0., 0.,  ..., 2., 0., 0.],\n",
      "          [1., 1., 0.,  ..., 3., 1., 0.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 2., 0., 0.],\n",
      "          [1., 1., 1.,  ..., 2., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 2., 2., 0.]],\n",
      "\n",
      "         [[1., 1., 1.,  ..., 0., 0., 3.],\n",
      "          [1., 1., 1.,  ..., 0., 1., 3.],\n",
      "          [1., 1., 1.,  ..., 0., 1., 3.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 0., 0., 3.],\n",
      "          [1., 1., 1.,  ..., 0., 0., 3.],\n",
      "          [1., 1., 1.,  ..., 0., 1., 3.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[3., 3., 3.,  ..., 3., 0., 0.],\n",
      "          [2., 1., 1.,  ..., 1., 0., 0.],\n",
      "          [2., 1., 1.,  ..., 2., 0., 0.],\n",
      "          ...,\n",
      "          [2., 1., 1.,  ..., 2., 0., 0.],\n",
      "          [1., 1., 1.,  ..., 2., 0., 0.],\n",
      "          [1., 1., 1.,  ..., 2., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 2., 2.],\n",
      "          [0., 0., 0.,  ..., 0., 1., 1.],\n",
      "          [0., 0., 0.,  ..., 0., 1., 1.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 1., 1.],\n",
      "          [0., 0., 0.,  ..., 0., 1., 1.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 1., 1., 1.],\n",
      "          [0., 0., 0.,  ..., 1., 1., 1.],\n",
      "          [0., 0., 0.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 1., 1.],\n",
      "          [0., 0., 0.,  ..., 0., 1., 1.],\n",
      "          [0., 0., 0.,  ..., 0., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1.,  ..., 0., 1., 2.],\n",
      "          [2., 1., 1.,  ..., 0., 1., 2.],\n",
      "          [2., 1., 1.,  ..., 0., 1., 2.],\n",
      "          ...,\n",
      "          [3., 1., 1.,  ..., 0., 1., 2.],\n",
      "          [3., 1., 1.,  ..., 0., 1., 2.],\n",
      "          [3., 1., 1.,  ..., 0., 1., 2.]],\n",
      "\n",
      "         [[1., 1., 1.,  ..., 0., 0., 0.],\n",
      "          [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "          [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "          [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 2., 2., 0.]],\n",
      "\n",
      "         [[1., 1., 1.,  ..., 1., 1., 3.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 3.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 3.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 0., 1., 3.],\n",
      "          [1., 0., 1.,  ..., 0., 1., 3.],\n",
      "          [1., 0., 0.,  ..., 0., 2., 3.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [1., 2., 1.,  ..., 0., 1., 0.],\n",
      "          [2., 1., 1.,  ..., 0., 1., 0.],\n",
      "          ...,\n",
      "          [3., 1., 1.,  ..., 0., 1., 0.],\n",
      "          [3., 1., 1.,  ..., 0., 1., 0.],\n",
      "          [3., 2., 2.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 2., 2., 2.],\n",
      "          [0., 0., 0.,  ..., 1., 1., 1.],\n",
      "          [0., 0., 0.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 1., 1., 1.],\n",
      "          [0., 0., 0.,  ..., 1., 1., 1.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 1., 1., 1.],\n",
      "          [0., 0., 0.,  ..., 1., 1., 1.],\n",
      "          [0., 0., 0.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 1., 1., 1.],\n",
      "          [0., 0., 0.,  ..., 1., 1., 1.],\n",
      "          [0., 0., 0.,  ..., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[0., 1., 1.,  ..., 1., 1., 2.],\n",
      "          [0., 1., 1.,  ..., 1., 1., 2.],\n",
      "          [0., 1., 1.,  ..., 1., 1., 2.],\n",
      "          ...,\n",
      "          [2., 0., 0.,  ..., 1., 0., 0.],\n",
      "          [2., 0., 0.,  ..., 1., 0., 0.],\n",
      "          [2., 1., 1.,  ..., 1., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 1., 3., 0.],\n",
      "          [1., 1., 1.,  ..., 1., 3., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 2., 0.]],\n",
      "\n",
      "         [[0., 1., 1.,  ..., 1., 1., 3.],\n",
      "          [0., 1., 1.,  ..., 1., 1., 3.],\n",
      "          [0., 1., 1.,  ..., 1., 1., 3.],\n",
      "          ...,\n",
      "          [2., 1., 1.,  ..., 1., 0., 1.],\n",
      "          [2., 1., 1.,  ..., 0., 0., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 0., 1.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 1., 1.,  ..., 1., 1., 0.],\n",
      "          [0., 1., 1.,  ..., 1., 1., 0.],\n",
      "          ...,\n",
      "          [2., 1., 1.,  ..., 1., 3., 0.],\n",
      "          [2., 1., 1.,  ..., 1., 2., 0.],\n",
      "          [3., 2., 2.,  ..., 1., 1., 0.]],\n",
      "\n",
      "         [[2., 2., 2.,  ..., 2., 2., 2.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 1.]]]], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x_bit = 2\n",
    "x =  save_output.outputs[1][0] # input of the 2nd conv layer\n",
    "x_alpha  = conv2.act_alpha.data.item()\n",
    "x_delta = x_alpha / (2**x_bit - 1)\n",
    "\n",
    "act_quant_fn = act_quantization(x_bit) # define the quantization function\n",
    "x_q = act_quant_fn(x, x_alpha)         # create the quantized value for x\n",
    "\n",
    "x_int = x_q / x_delta\n",
    "print(x_int) # you should see clean integer numbers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ranging-porter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-2.1464e+01, -3.1994e+01, -1.8629e+01,  ..., -1.3769e+01,\n",
      "           -1.2150e+01, -6.0748e+00],\n",
      "          [-1.6199e+01, -2.1464e+01, -8.9096e+00,  ..., -1.2554e+01,\n",
      "           -1.1340e+01, -8.9096e+00],\n",
      "          [-2.1869e+01, -1.6199e+01, -2.8349e+00,  ..., -9.7196e+00,\n",
      "           -1.2959e+01, -1.7009e+01],\n",
      "          ...,\n",
      "          [ 1.0983e-06, -1.6199e+00,  4.0498e-01,  ..., -1.2959e+01,\n",
      "           -7.2897e+00, -1.3364e+01],\n",
      "          [-1.8629e+01, -1.4984e+01, -1.6604e+01,  ..., -1.5389e+01,\n",
      "           -1.3364e+01, -1.6604e+01],\n",
      "          [-4.4548e+00, -4.0498e+00, -4.0498e+00,  ..., -2.8349e+00,\n",
      "           -2.8349e+00, -1.6604e+01]],\n",
      "\n",
      "         [[-2.4299e+00, -6.8847e+00, -4.4548e+00,  ..., -6.8847e+00,\n",
      "           -6.8847e+00, -4.8598e+00],\n",
      "          [-1.6199e+00, -5.2648e+00, -4.8598e+00,  ..., -5.2648e+00,\n",
      "           -6.8847e+00, -4.4548e+00],\n",
      "          [-3.2399e+00, -4.8598e+00, -7.6947e+00,  ..., -6.4797e+00,\n",
      "           -7.2897e+00, -1.0125e+01],\n",
      "          ...,\n",
      "          [-3.6449e+00,  2.4299e+00, -4.0498e-01,  ...,  1.2150e+00,\n",
      "            6.7589e-07, -1.0530e+01],\n",
      "          [-1.2554e+01, -2.8349e+00, -2.0249e+00,  ..., -1.1340e+01,\n",
      "           -1.1745e+01, -2.2679e+01],\n",
      "          [-1.4174e+01, -1.5389e+01, -1.5389e+01,  ..., -1.0935e+01,\n",
      "           -9.7196e+00, -1.3769e+01]],\n",
      "\n",
      "         [[-2.1464e+01, -2.7944e+01, -2.7539e+01,  ..., -2.1059e+01,\n",
      "           -2.4704e+01, -2.2679e+01],\n",
      "          [-1.9844e+01, -2.4299e+01, -2.4704e+01,  ..., -2.0654e+01,\n",
      "           -2.5109e+01, -2.3894e+01],\n",
      "          [-2.5514e+01, -2.7944e+01, -2.5109e+01,  ..., -1.6604e+01,\n",
      "           -1.7414e+01, -1.7819e+01],\n",
      "          ...,\n",
      "          [-3.5234e+01, -3.5639e+01, -3.3614e+01,  ..., -3.1994e+01,\n",
      "           -3.3614e+01, -4.2523e+01],\n",
      "          [-5.2243e+01, -4.8193e+01, -4.6978e+01,  ..., -3.8878e+01,\n",
      "           -3.8068e+01, -5.0623e+01],\n",
      "          [-2.3489e+01, -2.6729e+01, -2.6729e+01,  ..., -2.5109e+01,\n",
      "           -2.5514e+01, -3.5639e+01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.6604e+01, -1.8224e+01, -1.3364e+01,  ..., -1.2150e+01,\n",
      "           -1.2554e+01, -1.2959e+01],\n",
      "          [-7.6947e+00, -8.5047e+00, -9.3146e+00,  ..., -8.9096e+00,\n",
      "           -9.7196e+00, -1.4579e+01],\n",
      "          [-1.2959e+01, -1.0935e+01, -8.9096e+00,  ..., -4.0498e+00,\n",
      "           -5.2648e+00, -1.1340e+01],\n",
      "          ...,\n",
      "          [-5.2648e+00, -8.5047e+00, -5.6698e+00,  ..., -8.5047e+00,\n",
      "           -6.4797e+00, -1.1745e+01],\n",
      "          [-1.2959e+01, -1.4579e+01, -1.4984e+01,  ..., -1.1340e+01,\n",
      "           -1.2554e+01, -2.5514e+01],\n",
      "          [-2.6729e+01, -2.2679e+01, -2.2679e+01,  ..., -2.0249e+01,\n",
      "           -2.1059e+01, -3.3209e+01]],\n",
      "\n",
      "         [[ 2.5514e+01,  2.5109e+01,  2.5109e+01,  ...,  1.8224e+01,\n",
      "            1.9439e+01,  2.1059e+01],\n",
      "          [ 2.3084e+01,  1.6199e+01,  1.5794e+01,  ...,  1.7414e+01,\n",
      "            1.8224e+01,  2.2274e+01],\n",
      "          [ 1.9439e+01,  1.7414e+01,  1.6604e+01,  ...,  1.8629e+01,\n",
      "            1.9034e+01,  2.0249e+01],\n",
      "          ...,\n",
      "          [ 2.4299e+01,  2.3894e+01,  2.4299e+01,  ...,  2.7944e+01,\n",
      "            2.8349e+01,  2.9969e+01],\n",
      "          [ 1.7009e+01,  1.7414e+01,  1.9034e+01,  ...,  1.4174e+01,\n",
      "            1.5389e+01,  1.7009e+01],\n",
      "          [ 2.1869e+01,  2.7134e+01,  2.7134e+01,  ...,  1.8629e+01,\n",
      "            1.9034e+01,  1.8629e+01]],\n",
      "\n",
      "         [[-4.4548e+00,  4.0498e-01, -1.2149e+00,  ..., -3.2399e+00,\n",
      "           -3.2399e+00, -4.4548e+00],\n",
      "          [-2.0249e+00,  6.0748e+00,  1.2150e+00,  ...,  1.9432e-06,\n",
      "           -8.0997e-01, -1.2150e+00],\n",
      "          [ 1.2673e-06,  3.6449e+00,  2.0249e+00,  ..., -3.6449e+00,\n",
      "           -1.2150e+00, -8.0997e-01],\n",
      "          ...,\n",
      "          [ 8.5047e+00,  1.0125e+01,  1.0530e+01,  ...,  3.6449e+00,\n",
      "            5.2648e+00,  1.1745e+01],\n",
      "          [-9.3146e+00, -1.0935e+01, -1.0935e+01,  ..., -8.5047e+00,\n",
      "           -6.4797e+00, -4.0498e-01],\n",
      "          [ 5.6698e+00,  4.4548e+00,  4.4548e+00,  ...,  3.2399e+00,\n",
      "            2.8349e+00,  4.0498e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 2.0249e+00, -7.2897e+00, -1.0125e+01,  ..., -5.6698e+00,\n",
      "           -4.0498e-01, -6.1558e+01],\n",
      "          [-2.8349e+00, -1.9034e+01, -1.1745e+01,  ..., -6.8847e+00,\n",
      "           -1.5389e+01, -5.8723e+01],\n",
      "          [-5.2648e+00, -1.9439e+01, -7.2897e+00,  ..., -6.4797e+00,\n",
      "           -9.3146e+00, -6.2367e+01],\n",
      "          ...,\n",
      "          [-1.6604e+01, -2.6729e+01, -1.5389e+01,  ..., -4.0498e-01,\n",
      "            2.8349e+00, -7.7757e+01],\n",
      "          [-7.6947e+00, -2.0654e+01, -2.3084e+01,  ...,  1.9844e+01,\n",
      "           -6.8847e+00, -8.3022e+01],\n",
      "          [-8.5047e+00,  0.0000e+00, -3.6449e+00,  ...,  1.1340e+01,\n",
      "            4.0498e-01, -8.5047e+01]],\n",
      "\n",
      "         [[ 5.0692e-07, -3.6449e+00, -2.0249e+00,  ..., -5.2648e+00,\n",
      "           -2.0654e+01, -2.1869e+01],\n",
      "          [-3.2399e+00, -6.0748e+00, -7.6947e+00,  ..., -4.0498e-01,\n",
      "           -1.3769e+01, -1.0935e+01],\n",
      "          [-8.0997e+00, -4.8598e+00, -2.0249e+00,  ...,  1.2150e+00,\n",
      "           -1.5389e+01, -1.0125e+01],\n",
      "          ...,\n",
      "          [-1.1340e+01, -1.0125e+01, -5.6698e+00,  ..., -1.6199e+00,\n",
      "           -8.5047e+00, -1.2150e+00],\n",
      "          [-5.2648e+00,  4.0498e-01,  4.8598e+00,  ...,  1.2150e+00,\n",
      "           -7.2897e+00,  5.6698e+00],\n",
      "          [-8.0997e+00, -4.8598e+00, -2.4299e+00,  ...,  1.6199e+00,\n",
      "           -8.5047e+00,  5.2648e+00]],\n",
      "\n",
      "         [[-2.0654e+01, -2.1464e+01, -2.2679e+01,  ..., -2.1059e+01,\n",
      "            4.0498e-01, -3.1589e+01],\n",
      "          [-2.6729e+01, -2.3894e+01, -2.0654e+01,  ..., -1.7009e+01,\n",
      "           -2.8349e+00, -2.4299e+01],\n",
      "          [-1.4579e+01, -1.3769e+01, -1.5389e+01,  ..., -1.2959e+01,\n",
      "           -2.4299e+00, -2.6729e+01],\n",
      "          ...,\n",
      "          [-1.2150e+01, -1.5794e+01, -2.3489e+01,  ..., -1.4579e+01,\n",
      "            2.0249e+00, -2.7539e+01],\n",
      "          [-9.3146e+00, -1.4984e+01, -1.8224e+01,  ..., -2.8754e+01,\n",
      "           -1.2149e+00, -2.7539e+01],\n",
      "          [-1.3364e+01, -4.4548e+00, -3.6448e+00,  ..., -3.6449e+01,\n",
      "           -4.0498e+00, -3.4019e+01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.4984e+01, -1.0125e+01, -8.5047e+00,  ..., -2.0249e+00,\n",
      "            8.0997e-01, -3.1589e+01],\n",
      "          [-1.7009e+01, -1.6604e+01, -1.6604e+01,  ...,  2.4299e+00,\n",
      "            4.0498e-01, -2.9969e+01],\n",
      "          [-1.1745e+01, -1.6604e+01, -1.4984e+01,  ..., -4.0498e-01,\n",
      "            2.4299e+00, -3.5639e+01],\n",
      "          ...,\n",
      "          [-1.1340e+01, -1.1340e+01, -1.8224e+01,  ...,  8.0997e-01,\n",
      "           -8.9096e+00, -3.7663e+01],\n",
      "          [-1.6199e+01, -1.7819e+01, -1.9439e+01,  ...,  8.0997e-01,\n",
      "           -6.8847e+00, -3.7258e+01],\n",
      "          [-7.6947e+00, -1.0935e+01, -1.8629e+01,  ...,  8.0997e-01,\n",
      "           -2.0249e+00, -3.8878e+01]],\n",
      "\n",
      "         [[ 1.7009e+01,  2.1464e+01,  1.9844e+01,  ...,  6.0748e+00,\n",
      "            1.5794e+01,  1.7009e+01],\n",
      "          [ 6.0748e+00,  5.2648e+00,  6.8847e+00,  ...,  6.0748e+00,\n",
      "            1.3364e+01,  1.4174e+01],\n",
      "          [-4.0498e-01, -4.0498e-01,  4.0498e+00,  ...,  7.6947e+00,\n",
      "            1.1340e+01,  1.3364e+01],\n",
      "          ...,\n",
      "          [ 2.4299e+00,  7.2897e+00,  8.5047e+00,  ...,  4.0498e+00,\n",
      "            1.0935e+01,  1.4174e+01],\n",
      "          [ 4.0498e-01,  4.4548e+00,  1.6199e+00,  ...,  1.1745e+01,\n",
      "            1.7414e+01,  1.5389e+01],\n",
      "          [ 9.7196e+00,  8.0997e+00,  8.9096e+00,  ...,  1.0935e+01,\n",
      "            1.7009e+01,  1.2150e+01]],\n",
      "\n",
      "         [[ 2.8349e+00,  8.5047e+00,  8.0997e+00,  ...,  1.7414e+01,\n",
      "            5.2648e+00,  1.0125e+01],\n",
      "          [ 4.0498e+00,  6.4797e+00,  5.9140e-07,  ...,  1.7414e+01,\n",
      "            1.2149e+00,  6.8847e+00],\n",
      "          [ 5.2648e+00,  5.2648e+00,  2.4299e+00,  ...,  1.5389e+01,\n",
      "            8.0997e-01,  1.0935e+01],\n",
      "          ...,\n",
      "          [ 6.0748e+00,  4.0498e-01, -1.2150e+00,  ...,  2.0654e+01,\n",
      "            1.6199e+00,  8.9096e+00],\n",
      "          [ 1.8629e+01,  2.0654e+01,  1.9844e+01,  ...,  2.5109e+01,\n",
      "           -1.6199e+00,  3.2399e+00],\n",
      "          [ 1.5794e+01,  1.3364e+01,  1.8629e+01,  ...,  2.0249e+01,\n",
      "           -5.6698e+00,  8.0997e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.8349e+00,  2.3489e+01, -3.0374e+01,  ..., -6.8847e+00,\n",
      "           -2.3894e+01, -2.7134e+01],\n",
      "          [-1.3769e+01,  2.4299e+00, -2.6324e+01,  ..., -3.6044e+01,\n",
      "           -2.3489e+01, -1.4579e+01],\n",
      "          [-9.7196e+00, -1.5794e+01, -3.8473e+01,  ..., -1.9439e+01,\n",
      "           -8.0997e-01, -4.0498e+00],\n",
      "          ...,\n",
      "          [-1.8224e+01, -2.1464e+01, -2.3894e+01,  ..., -1.7009e+01,\n",
      "           -1.7414e+01, -1.9439e+01],\n",
      "          [ 8.0997e-01, -2.4299e+00, -1.2149e+00,  ..., -5.2648e+00,\n",
      "           -5.2648e+00, -1.6199e+01],\n",
      "          [-1.1745e+01, -1.1340e+01, -1.1340e+01,  ..., -1.1340e+01,\n",
      "           -1.1340e+01, -2.1059e+01]],\n",
      "\n",
      "         [[-6.8847e+00, -1.5794e+01, -2.0249e+01,  ..., -4.4548e+00,\n",
      "           -8.0997e+00, -1.9844e+01],\n",
      "          [ 2.0249e+00, -3.2399e+00, -1.0125e+01,  ..., -1.3364e+01,\n",
      "           -8.5047e+00, -1.7414e+01],\n",
      "          [-2.0249e+00, -6.0748e+00, -1.0530e+01,  ..., -1.5794e+01,\n",
      "           -6.8847e+00, -1.7819e+01],\n",
      "          ...,\n",
      "          [-1.0935e+01, -4.4548e+00, -5.6698e+00,  ..., -1.2150e+01,\n",
      "           -8.0997e+00, -1.9034e+01],\n",
      "          [-1.7414e+01, -1.2959e+01, -1.1340e+01,  ..., -4.8598e+00,\n",
      "           -4.8598e+00, -1.1745e+01],\n",
      "          [-3.6449e+00, -4.4548e+00, -4.4548e+00,  ..., -4.4548e+00,\n",
      "           -4.4548e+00, -6.8847e+00]],\n",
      "\n",
      "         [[-3.1589e+01, -1.7009e+01, -3.3209e+01,  ..., -2.1059e+01,\n",
      "           -1.1340e+01, -2.4299e+01],\n",
      "          [-4.1713e+01, -2.5919e+01, -2.9564e+01,  ..., -2.1059e+01,\n",
      "           -1.9439e+01, -2.5514e+01],\n",
      "          [-2.9969e+01, -3.4424e+01, -3.4424e+01,  ..., -1.7819e+01,\n",
      "           -2.2679e+01, -2.7944e+01],\n",
      "          ...,\n",
      "          [-5.0623e+01, -3.8473e+01, -3.6044e+01,  ..., -2.3894e+01,\n",
      "           -2.7134e+01, -2.5514e+01],\n",
      "          [-2.8754e+01, -2.6324e+01, -2.6324e+01,  ..., -2.3894e+01,\n",
      "           -2.3894e+01, -3.3614e+01],\n",
      "          [-2.3894e+01, -2.5514e+01, -2.5514e+01,  ..., -2.5514e+01,\n",
      "           -2.5514e+01, -3.4424e+01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.3084e+01, -1.2149e+00, -2.6729e+01,  ..., -2.0249e+00,\n",
      "           -2.4299e+00, -2.9564e+01],\n",
      "          [-2.2274e+01, -7.2897e+00, -1.4174e+01,  ..., -7.6947e+00,\n",
      "           -8.9096e+00, -2.8754e+01],\n",
      "          [-1.8629e+01, -2.0249e+01, -2.5514e+01,  ..., -1.0935e+01,\n",
      "           -1.7414e+01, -2.9564e+01],\n",
      "          ...,\n",
      "          [-1.3769e+01, -1.2150e+01, -9.7196e+00,  ..., -7.2897e+00,\n",
      "           -1.2554e+01, -1.8224e+01],\n",
      "          [-2.3894e+01, -1.8224e+01, -1.7414e+01,  ..., -1.3364e+01,\n",
      "           -1.3364e+01, -2.4704e+01],\n",
      "          [-2.3894e+01, -2.1059e+01, -2.1059e+01,  ..., -2.1059e+01,\n",
      "           -2.1059e+01, -2.9564e+01]],\n",
      "\n",
      "         [[ 2.0249e+00,  6.8847e+00,  6.4797e+00,  ...,  5.6698e+00,\n",
      "            6.8847e+00,  4.8598e+00],\n",
      "          [-4.8598e+00,  7.6947e+00,  8.0997e+00,  ...,  1.1340e+01,\n",
      "            5.6698e+00,  7.6947e+00],\n",
      "          [-2.4299e+00,  4.4548e+00,  3.6449e+00,  ...,  9.7196e+00,\n",
      "            4.8598e+00,  1.0530e+01],\n",
      "          ...,\n",
      "          [ 1.9034e+01,  2.0654e+01,  2.1869e+01,  ...,  1.5389e+01,\n",
      "            1.5794e+01,  2.1464e+01],\n",
      "          [ 2.4299e+01,  2.9564e+01,  2.9564e+01,  ...,  2.4704e+01,\n",
      "            2.4704e+01,  2.4299e+01],\n",
      "          [ 1.9844e+01,  2.2679e+01,  2.2679e+01,  ...,  2.2679e+01,\n",
      "            2.2679e+01,  2.1059e+01]],\n",
      "\n",
      "         [[ 4.4548e+00,  7.6947e+00,  1.6604e+01,  ...,  1.5389e+01,\n",
      "            9.3146e+00,  3.6449e+00],\n",
      "          [ 8.9096e+00,  6.8847e+00,  1.1745e+01,  ...,  6.8847e+00,\n",
      "           -2.0249e+00, -2.8349e+00],\n",
      "          [ 1.0530e+01,  1.1340e+01,  8.0997e+00,  ..., -4.0498e-01,\n",
      "            5.2648e+00,  4.0498e+00],\n",
      "          ...,\n",
      "          [-8.9096e+00, -8.9096e+00, -8.0997e+00,  ..., -5.2648e+00,\n",
      "           -6.4797e+00, -1.6199e+00],\n",
      "          [ 8.9096e+00,  8.0997e+00,  8.0997e+00,  ...,  6.0748e+00,\n",
      "            6.0748e+00,  1.0125e+01],\n",
      "          [ 8.0997e-01, -3.2399e+00, -3.2399e+00,  ..., -3.2399e+00,\n",
      "           -3.2399e+00, -1.6199e+00]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-3.4424e+01, -1.7009e+01,  4.8598e+00,  ..., -2.6729e+01,\n",
      "           -1.9844e+01, -6.9252e+01],\n",
      "          [-2.6324e+01, -2.4299e+01,  6.0748e+00,  ..., -1.1745e+01,\n",
      "            8.0997e-01, -7.1277e+01],\n",
      "          [-1.4174e+01, -2.1869e+01, -1.4579e+01,  ...,  4.0498e-01,\n",
      "            6.4797e+00, -7.3302e+01],\n",
      "          ...,\n",
      "          [-2.0249e+01, -9.7196e+00, -7.2897e+00,  ..., -3.6449e+00,\n",
      "           -4.8598e+00, -6.8442e+01],\n",
      "          [-2.1464e+01, -1.8629e+01, -2.2274e+01,  ..., -5.6698e+00,\n",
      "           -9.7196e+00, -7.0467e+01],\n",
      "          [-1.4174e+01, -1.2959e+01, -1.1340e+01,  ..., -1.6199e+00,\n",
      "           -2.0249e+00, -7.6137e+01]],\n",
      "\n",
      "         [[ 6.8847e+00,  1.1745e+01,  1.4579e+01,  ..., -2.0249e+00,\n",
      "           -1.9034e+01, -1.5389e+01],\n",
      "          [-7.2897e+00,  3.6449e+00,  4.4548e+00,  ..., -1.2959e+01,\n",
      "           -2.1059e+01, -1.3769e+01],\n",
      "          [-9.7196e+00, -5.6698e+00, -2.0249e+00,  ..., -7.6947e+00,\n",
      "           -1.7819e+01, -1.0935e+01],\n",
      "          ...,\n",
      "          [ 1.6199e+00,  8.0997e-01, -1.2150e+00,  ...,  4.0498e-01,\n",
      "           -1.0530e+01, -3.6449e+00],\n",
      "          [ 4.0498e-01, -8.0997e-01, -3.2399e+00,  ...,  8.0997e-01,\n",
      "           -1.0530e+01, -4.0498e+00],\n",
      "          [-3.2399e+00,  4.0498e-01, -1.6199e+00,  ...,  4.0498e-01,\n",
      "           -7.2897e+00,  3.2399e+00]],\n",
      "\n",
      "         [[-5.1433e+01, -4.7383e+01, -3.4829e+01,  ..., -1.2150e+01,\n",
      "            3.3794e-07, -3.8473e+01],\n",
      "          [-4.1308e+01, -4.7788e+01, -3.6449e+01,  ..., -4.0498e+00,\n",
      "           -2.0249e+00, -4.0093e+01],\n",
      "          [-2.7944e+01, -4.0093e+01, -4.2928e+01,  ..., -1.5389e+01,\n",
      "           -2.4299e+00, -4.0903e+01],\n",
      "          ...,\n",
      "          [-2.2274e+01, -1.8629e+01, -2.3084e+01,  ..., -2.6729e+01,\n",
      "            4.0498e-01, -2.7944e+01],\n",
      "          [-2.5109e+01, -2.5514e+01, -2.9159e+01,  ..., -2.2274e+01,\n",
      "            1.6199e+00, -2.4704e+01],\n",
      "          [-2.2274e+01, -2.1059e+01, -2.5919e+01,  ..., -2.0249e+01,\n",
      "            4.4548e+00, -2.6324e+01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.7009e+01, -1.1745e+01, -2.0249e+00,  ..., -1.1340e+01,\n",
      "            5.6698e+00, -2.3084e+01],\n",
      "          [-7.6947e+00, -2.1869e+01, -7.6947e+00,  ..., -1.2959e+01,\n",
      "            4.8598e+00, -2.5514e+01],\n",
      "          [ 4.0498e-01, -1.7819e+01, -1.7414e+01,  ..., -1.1745e+01,\n",
      "            5.2648e+00, -2.4299e+01],\n",
      "          ...,\n",
      "          [-6.8847e+00, -1.1340e+01, -5.2648e+00,  ..., -1.6199e+00,\n",
      "           -8.0997e+00, -3.7663e+01],\n",
      "          [-1.2150e+01, -1.4174e+01, -1.0125e+01,  ..., -2.8349e+00,\n",
      "           -8.5047e+00, -3.7663e+01],\n",
      "          [-6.0748e+00, -9.3146e+00, -5.6698e+00,  ..., -4.0498e+00,\n",
      "           -5.2648e+00, -3.7663e+01]],\n",
      "\n",
      "         [[ 6.4797e+00,  6.4797e+00,  1.0935e+01,  ...,  2.9564e+01,\n",
      "            3.3209e+01,  2.1464e+01],\n",
      "          [ 6.8847e+00,  4.4548e+00,  1.2554e+01,  ...,  4.1713e+01,\n",
      "            3.8473e+01,  2.2274e+01],\n",
      "          [ 6.4797e+00,  1.6199e+00,  6.4797e+00,  ...,  4.6573e+01,\n",
      "            4.0903e+01,  2.3084e+01],\n",
      "          ...,\n",
      "          [ 2.4299e+00,  1.2150e+00,  3.2399e+00,  ...,  3.6449e+00,\n",
      "            9.7196e+00,  1.0530e+01],\n",
      "          [ 4.0498e+00,  2.4299e+00,  4.0498e+00,  ...,  6.0748e+00,\n",
      "            1.2150e+01,  1.2959e+01],\n",
      "          [ 1.2150e+00,  4.0498e-01,  1.2150e+00,  ...,  6.4797e+00,\n",
      "            1.4174e+01,  1.3364e+01]],\n",
      "\n",
      "         [[ 9.3146e+00,  3.2399e+00,  4.0498e-01,  ...,  4.0498e-01,\n",
      "           -1.8629e+01, -6.0748e+00],\n",
      "          [ 1.7009e+01,  1.8629e+01,  1.3769e+01,  ...,  1.2149e+00,\n",
      "           -1.0530e+01,  2.8349e+00],\n",
      "          [ 1.5794e+01,  1.7819e+01,  1.8629e+01,  ..., -4.0498e-01,\n",
      "           -1.4174e+01, -1.2150e+00],\n",
      "          ...,\n",
      "          [ 6.4797e+00,  6.8847e+00,  1.3364e+01,  ...,  2.1059e+01,\n",
      "           -4.0498e+00,  4.0498e+00],\n",
      "          [ 1.2554e+01,  1.4579e+01,  1.1745e+01,  ...,  2.1059e+01,\n",
      "           -4.0498e+00,  5.2648e+00],\n",
      "          [ 8.5047e+00,  1.3364e+01,  1.3364e+01,  ...,  1.9844e+01,\n",
      "           -8.0997e-01,  6.0748e+00]]],\n",
      "\n",
      "\n",
      "        [[[-2.8349e+00, -1.9439e+01, -9.3146e+00,  ...,  1.2150e+00,\n",
      "           -5.1838e+01, -4.0498e-01],\n",
      "          [-1.7009e+01, -2.3489e+01, -1.7819e+01,  ...,  8.0997e-01,\n",
      "           -5.9938e+01, -6.8847e+00],\n",
      "          [-1.3364e+01, -1.6199e+01, -1.1340e+01,  ..., -8.0997e-01,\n",
      "           -5.7913e+01, -9.3146e+00],\n",
      "          ...,\n",
      "          [-1.6604e+01, -6.0748e+00, -1.2150e+01,  ..., -1.0530e+01,\n",
      "           -6.9657e+01, -6.0748e+00],\n",
      "          [-1.7009e+01, -8.5047e+00, -1.0935e+01,  ..., -1.0935e+01,\n",
      "           -7.3707e+01, -5.6698e+00],\n",
      "          [-1.1340e+01, -5.6698e+00, -2.8349e+00,  ...,  1.2149e+00,\n",
      "           -7.4517e+01, -1.7414e+01]],\n",
      "\n",
      "         [[-2.0249e+00,  1.6199e+00,  3.2399e+00,  ..., -2.4299e+01,\n",
      "           -1.1745e+01, -1.8224e+01],\n",
      "          [ 4.2243e-07,  2.0249e+00, -3.6449e+00,  ..., -1.7819e+01,\n",
      "           -6.8847e+00, -1.4579e+01],\n",
      "          [ 8.0997e-01, -4.0498e-01, -7.2897e+00,  ..., -1.0125e+01,\n",
      "           -1.2150e+00, -1.4579e+01],\n",
      "          ...,\n",
      "          [ 8.0997e+00,  1.5389e+01,  1.6604e+01,  ..., -1.5794e+01,\n",
      "            7.2897e+00, -1.2959e+01],\n",
      "          [ 4.8598e+00,  1.0125e+01,  1.6199e+01,  ..., -1.2959e+01,\n",
      "            8.5047e+00, -1.3364e+01],\n",
      "          [ 4.8598e+00,  6.0748e+00,  1.0125e+01,  ..., -1.2554e+01,\n",
      "            6.0748e+00, -7.2897e+00]],\n",
      "\n",
      "         [[-1.6604e+01, -2.0249e+01, -3.7663e+01,  ..., -2.0249e+00,\n",
      "           -2.4299e+01, -3.6449e+01],\n",
      "          [-2.5109e+01, -3.2399e+01, -3.3209e+01,  ..., -2.4299e+00,\n",
      "           -2.1869e+01, -3.5234e+01],\n",
      "          [-2.6324e+01, -2.6324e+01, -2.8754e+01,  ..., -2.8349e+00,\n",
      "           -2.0249e+01, -3.6044e+01],\n",
      "          ...,\n",
      "          [-3.2399e+01, -2.4704e+01, -2.2679e+01,  ..., -3.6449e+00,\n",
      "           -2.3489e+01, -3.4019e+01],\n",
      "          [-3.3614e+01, -2.7944e+01, -2.6324e+01,  ..., -2.0249e+00,\n",
      "           -2.3894e+01, -3.4019e+01],\n",
      "          [-3.5234e+01, -3.0779e+01, -2.9969e+01,  ...,  4.0498e+00,\n",
      "           -2.4299e+01, -3.3614e+01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-8.5047e+00, -2.0654e+01, -2.1059e+01,  ...,  1.6199e+00,\n",
      "           -2.5514e+01, -3.7258e+01],\n",
      "          [-1.0125e+01, -1.4984e+01, -1.7414e+01,  ..., -5.6698e+00,\n",
      "           -2.5919e+01, -3.5639e+01],\n",
      "          [-1.0125e+01, -1.3769e+01, -1.4174e+01,  ..., -6.8847e+00,\n",
      "           -2.3084e+01, -3.4019e+01],\n",
      "          ...,\n",
      "          [-6.0748e+00, -6.8847e+00, -5.6698e+00,  ..., -6.0748e+00,\n",
      "           -2.6324e+01, -3.2804e+01],\n",
      "          [-8.0997e+00, -1.3364e+01, -1.1745e+01,  ..., -2.8349e+00,\n",
      "           -2.3894e+01, -3.2804e+01],\n",
      "          [-6.4797e+00, -1.1745e+01, -1.0935e+01,  ..., -2.0249e+00,\n",
      "           -2.7539e+01, -3.6854e+01]],\n",
      "\n",
      "         [[ 4.0498e-01, -2.4299e+00, -2.8349e+00,  ...,  1.1340e+01,\n",
      "            1.4174e+01,  2.0654e+01],\n",
      "          [ 7.6947e+00,  4.0498e-01,  3.6449e+00,  ...,  1.0935e+01,\n",
      "            1.4579e+01,  1.9439e+01],\n",
      "          [ 1.1340e+01,  3.2399e+00,  6.8847e+00,  ...,  1.1745e+01,\n",
      "            1.4579e+01,  1.9439e+01],\n",
      "          ...,\n",
      "          [ 1.7009e+01,  1.2959e+01,  8.9096e+00,  ...,  1.3769e+01,\n",
      "            1.2150e+01,  1.4984e+01],\n",
      "          [ 1.6604e+01,  1.2959e+01,  1.0125e+01,  ...,  1.3364e+01,\n",
      "            1.0935e+01,  1.4984e+01],\n",
      "          [ 1.8224e+01,  1.3769e+01,  1.3364e+01,  ...,  1.7009e+01,\n",
      "            1.2150e+01,  1.2554e+01]],\n",
      "\n",
      "         [[ 1.7414e+01,  1.9034e+01,  2.2679e+01,  ...,  4.0498e-01,\n",
      "            4.0498e+00,  7.2897e+00],\n",
      "          [ 8.9096e+00,  6.0748e+00,  1.4579e+01,  ..., -3.2399e+00,\n",
      "            4.0498e-01,  4.8598e+00],\n",
      "          [ 6.0748e+00,  7.6947e+00,  1.6199e+01,  ..., -3.6449e+00,\n",
      "            4.0498e-01,  6.8847e+00],\n",
      "          ...,\n",
      "          [ 1.7819e+01,  1.8224e+01,  2.3084e+01,  ...,  1.2150e+00,\n",
      "           -8.0997e-01,  5.2648e+00],\n",
      "          [ 1.8224e+01,  1.8629e+01,  1.9439e+01,  ..., -4.0498e-01,\n",
      "           -3.6449e+00,  5.6698e+00],\n",
      "          [ 1.9034e+01,  2.0654e+01,  1.9844e+01,  ...,  2.4299e+00,\n",
      "           -1.2150e+00,  3.2399e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 5.6698e+00,  2.8349e+00,  2.8349e+00,  ...,  2.8349e+00,\n",
      "            2.8349e+00, -8.9096e+00],\n",
      "          [-2.8349e+00, -6.0748e+00, -8.9096e+00,  ..., -1.0125e+01,\n",
      "           -9.3146e+00, -1.7414e+01],\n",
      "          [-5.6698e+00, -8.9096e+00, -1.0125e+01,  ..., -9.3146e+00,\n",
      "           -8.5047e+00, -1.7819e+01],\n",
      "          ...,\n",
      "          [-1.6604e+01, -2.1464e+01, -1.4174e+01,  ..., -1.3364e+01,\n",
      "           -3.6449e+00, -6.8847e+00],\n",
      "          [-1.8224e+01, -1.7414e+01, -1.6604e+01,  ..., -6.8847e+00,\n",
      "            1.2149e+00, -4.0498e+00],\n",
      "          [-9.3146e+00, -1.0125e+01, -1.1745e+01,  ..., -8.5047e+00,\n",
      "            3.2399e+00, -4.8598e+00]],\n",
      "\n",
      "         [[-1.5794e+01, -1.2150e+01, -1.2150e+01,  ..., -1.2150e+01,\n",
      "           -1.2150e+01, -1.9034e+01],\n",
      "          [-5.2648e+00, -2.0249e+00, -4.4548e+00,  ..., -1.2150e+00,\n",
      "           -8.0997e-01, -9.7196e+00],\n",
      "          [-2.4299e+00, -3.2399e+00, -7.2897e+00,  ..., -5.2648e+00,\n",
      "           -3.6449e+00, -1.1340e+01],\n",
      "          ...,\n",
      "          [ 1.6199e+00,  6.4797e+00,  9.7196e+00,  ...,  6.4797e+00,\n",
      "            5.2648e+00, -1.1745e+01],\n",
      "          [-8.5047e+00, -4.0498e+00, -8.0997e-01,  ...,  1.2149e+00,\n",
      "           -1.2150e+00, -1.9034e+01],\n",
      "          [-1.6604e+01, -1.2554e+01, -1.1745e+01,  ...,  7.2897e+00,\n",
      "            3.2399e+00, -1.2150e+01]],\n",
      "\n",
      "         [[-2.7539e+01, -2.5919e+01, -2.5919e+01,  ..., -2.5919e+01,\n",
      "           -2.5919e+01, -3.6854e+01],\n",
      "          [-2.5109e+01, -2.2274e+01, -2.3084e+01,  ..., -2.1869e+01,\n",
      "           -2.2679e+01, -3.2399e+01],\n",
      "          [-2.2679e+01, -1.8629e+01, -2.0249e+01,  ..., -2.5514e+01,\n",
      "           -2.3894e+01, -3.6044e+01],\n",
      "          ...,\n",
      "          [-3.8473e+01, -3.3209e+01, -3.8878e+01,  ..., -3.7258e+01,\n",
      "           -2.7134e+01, -6.8847e+00],\n",
      "          [-3.4019e+01, -3.0374e+01, -2.8754e+01,  ..., -3.9283e+01,\n",
      "           -3.3209e+01, -8.9096e+00],\n",
      "          [-2.6324e+01, -2.1869e+01, -2.0654e+01,  ..., -2.9969e+01,\n",
      "           -2.7134e+01, -2.0249e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.5514e+01, -1.6604e+01, -1.6604e+01,  ..., -1.6604e+01,\n",
      "           -1.6604e+01, -2.9564e+01],\n",
      "          [-2.0249e+01, -1.6199e+01, -1.4579e+01,  ..., -1.6604e+01,\n",
      "           -1.7009e+01, -2.5514e+01],\n",
      "          [-1.8629e+01, -1.4174e+01, -1.3769e+01,  ..., -1.6199e+01,\n",
      "           -1.4984e+01, -2.3084e+01],\n",
      "          ...,\n",
      "          [-5.6698e+00, -9.3146e+00, -9.3146e+00,  ..., -1.7009e+01,\n",
      "           -8.5047e+00, -9.7196e+00],\n",
      "          [ 1.2149e+00, -1.0125e+01, -9.3146e+00,  ..., -1.9034e+01,\n",
      "           -1.2150e+01, -1.1745e+01],\n",
      "          [ 1.2150e+00, -1.0935e+01, -1.4984e+01,  ..., -4.8598e+00,\n",
      "           -6.4797e+00, -1.2150e+01]],\n",
      "\n",
      "         [[ 1.9844e+01,  2.6324e+01,  2.6324e+01,  ...,  2.6324e+01,\n",
      "            2.6324e+01,  2.5919e+01],\n",
      "          [ 1.7414e+01,  1.9844e+01,  2.0654e+01,  ...,  2.3894e+01,\n",
      "            2.2679e+01,  2.2679e+01],\n",
      "          [ 1.2554e+01,  1.5389e+01,  1.7009e+01,  ...,  1.6199e+01,\n",
      "            1.6604e+01,  1.8629e+01],\n",
      "          ...,\n",
      "          [ 1.4579e+01,  1.0125e+01,  7.2897e+00,  ...,  1.0125e+01,\n",
      "            1.4174e+01,  1.9844e+01],\n",
      "          [ 9.7196e+00,  4.0498e+00,  3.2399e+00,  ...,  1.4174e+01,\n",
      "            1.6199e+01,  2.0654e+01],\n",
      "          [ 1.0530e+01,  3.6449e+00,  3.2399e+00,  ...,  1.1745e+01,\n",
      "            1.3364e+01,  1.8224e+01]],\n",
      "\n",
      "         [[ 8.0997e+00,  8.0997e+00,  8.0997e+00,  ...,  8.0997e+00,\n",
      "            8.0997e+00,  1.2554e+01],\n",
      "          [-5.9140e-07, -2.0249e+00, -1.2673e-06,  ..., -2.4299e+00,\n",
      "           -5.2648e+00,  2.0249e+00],\n",
      "          [ 2.4299e+00,  2.8349e+00,  4.0498e+00,  ...,  4.0498e-01,\n",
      "            8.0997e-01,  5.2648e+00],\n",
      "          ...,\n",
      "          [ 8.5047e+00,  6.0748e+00,  9.3146e+00,  ...,  1.2150e+01,\n",
      "            1.9844e+01, -4.0498e+00],\n",
      "          [ 1.2554e+01,  1.1745e+01,  1.2150e+01,  ...,  1.6199e+01,\n",
      "            2.6729e+01,  2.8349e+00],\n",
      "          [ 1.7414e+01,  1.9034e+01,  1.9439e+01,  ...,  2.0249e+01,\n",
      "            2.7539e+01,  3.6449e+00]]]], device='cuda:0',\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "conv_int = torch.nn.Conv2d(in_channels = 16, out_channels=16, kernel_size = 3, bias = False)\n",
    "conv_int.weight = torch.nn.parameter.Parameter(weight_int)\n",
    "\n",
    "output_int =  conv_int(x_int)\n",
    "output_recovered = output_int * x_delta * w_delta\n",
    "print(output_recovered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designed-auction",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### input floating number / weight quantized version\n",
    "\n",
    "#conv_ref = torch.nn.Conv2d(in_channels = 16, out_channels=16, kernel_size = 3, bias = False)\n",
    "#conv_ref.weight = torch.nn.parameter.Parameter(weight_int)\n",
    "\n",
    "#output_ref = conv_ref(x)\n",
    "#print(output_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "sorted-niger",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-2.4125e+01, -2.4126e+01, -2.0180e+01,  ..., -1.5358e+01,\n",
      "           -1.0014e+01, -5.1404e+00],\n",
      "          [-2.5405e+01, -1.4761e+01, -1.0680e+01,  ..., -8.6709e+00,\n",
      "           -1.1456e+01, -1.0104e+01],\n",
      "          [-2.4110e+01, -1.0237e+01, -6.3433e+00,  ..., -1.1045e+01,\n",
      "           -1.6476e+01, -1.2275e+01],\n",
      "          ...,\n",
      "          [-4.1727e+00, -4.0139e+00, -5.6855e+00,  ..., -1.3655e+01,\n",
      "           -5.7615e+00, -1.1215e+01],\n",
      "          [-2.4244e+01, -2.1316e+01, -2.1341e+01,  ..., -1.5370e+01,\n",
      "           -1.4013e+01, -2.3980e+01],\n",
      "          [-4.0870e+00, -3.6631e+00, -3.5516e+00,  ..., -3.3250e+00,\n",
      "           -3.6847e+00, -1.6156e+01]],\n",
      "\n",
      "         [[-1.0068e+00, -3.5434e+00, -4.6018e+00,  ..., -3.1536e+00,\n",
      "           -2.7975e+00, -2.3760e+00],\n",
      "          [-2.6514e+00, -3.4339e+00, -3.8551e+00,  ..., -4.8918e+00,\n",
      "           -4.3300e+00, -6.2175e+00],\n",
      "          [-3.4571e+00, -2.5807e+00, -3.0288e+00,  ..., -7.5374e+00,\n",
      "           -6.4359e+00, -9.2570e+00],\n",
      "          ...,\n",
      "          [-3.5482e+00,  9.7050e-01,  6.6211e-01,  ..., -2.6480e+00,\n",
      "           -1.9913e+00, -7.9744e+00],\n",
      "          [-1.7941e+01, -1.1482e+01, -1.1926e+01,  ..., -1.0538e+01,\n",
      "           -1.0386e+01, -1.7179e+01],\n",
      "          [-2.0852e+01, -2.0734e+01, -2.0678e+01,  ..., -1.5860e+01,\n",
      "           -1.5981e+01, -1.8910e+01]],\n",
      "\n",
      "         [[-1.8800e+01, -1.9004e+01, -2.2124e+01,  ..., -2.5716e+01,\n",
      "           -2.6164e+01, -2.1452e+01],\n",
      "          [-1.9422e+01, -2.0177e+01, -2.3773e+01,  ..., -2.5483e+01,\n",
      "           -2.6501e+01, -2.3262e+01],\n",
      "          [-2.4205e+01, -2.5294e+01, -2.3883e+01,  ..., -2.5387e+01,\n",
      "           -2.4981e+01, -2.3885e+01],\n",
      "          ...,\n",
      "          [-3.9362e+01, -3.8098e+01, -3.9564e+01,  ..., -3.8087e+01,\n",
      "           -4.2681e+01, -4.4291e+01],\n",
      "          [-5.0563e+01, -4.5952e+01, -4.6037e+01,  ..., -4.3658e+01,\n",
      "           -4.4382e+01, -5.1295e+01],\n",
      "          [-2.6526e+01, -2.8723e+01, -2.8706e+01,  ..., -2.9107e+01,\n",
      "           -2.8767e+01, -3.9654e+01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.1588e+01, -1.5902e+01, -1.6305e+01,  ..., -8.3588e+00,\n",
      "           -8.4704e+00, -8.5292e+00],\n",
      "          [-9.1460e+00, -1.1367e+01, -1.1103e+01,  ..., -6.0988e+00,\n",
      "           -1.0576e+01, -1.0596e+01],\n",
      "          [-1.3444e+01, -1.2112e+01, -8.8605e+00,  ..., -8.0008e+00,\n",
      "           -1.0852e+01, -1.1600e+01],\n",
      "          ...,\n",
      "          [-4.8990e+00, -7.3810e+00, -6.5625e+00,  ..., -1.2185e+01,\n",
      "           -1.0843e+01, -9.8661e+00],\n",
      "          [-1.1866e+01, -1.2455e+01, -1.2147e+01,  ..., -1.2055e+01,\n",
      "           -1.2803e+01, -2.3010e+01],\n",
      "          [-2.6146e+01, -2.2434e+01, -2.2562e+01,  ..., -2.1575e+01,\n",
      "           -2.1566e+01, -3.4703e+01]],\n",
      "\n",
      "         [[ 2.2318e+01,  2.3158e+01,  2.5919e+01,  ...,  2.0982e+01,\n",
      "            1.9802e+01,  2.1869e+01],\n",
      "          [ 2.0231e+01,  1.8102e+01,  1.8219e+01,  ...,  2.4310e+01,\n",
      "            2.3285e+01,  2.5453e+01],\n",
      "          [ 1.7220e+01,  1.6872e+01,  1.7813e+01,  ...,  2.5261e+01,\n",
      "            2.4836e+01,  2.5803e+01],\n",
      "          ...,\n",
      "          [ 2.3511e+01,  2.3120e+01,  2.3597e+01,  ...,  2.9675e+01,\n",
      "            2.9704e+01,  2.9659e+01],\n",
      "          [ 1.6627e+01,  1.6332e+01,  1.7035e+01,  ...,  1.5171e+01,\n",
      "            1.5846e+01,  1.7443e+01],\n",
      "          [ 1.8892e+01,  2.3773e+01,  2.3673e+01,  ...,  1.7477e+01,\n",
      "            1.7933e+01,  1.6393e+01]],\n",
      "\n",
      "         [[-4.7786e-01, -3.0864e+00, -2.6149e+00,  ..., -1.4022e+00,\n",
      "           -1.2076e+00,  1.1257e+00],\n",
      "          [-2.2055e-01, -4.1640e-02,  1.1213e+00,  ..., -1.8001e-01,\n",
      "            1.8747e+00,  1.1011e+00],\n",
      "          [ 1.6054e+00,  1.6385e+00,  1.8436e+00,  ..., -3.9590e+00,\n",
      "           -2.9044e+00, -2.3346e+00],\n",
      "          ...,\n",
      "          [ 9.8098e+00,  1.2835e+01,  1.3010e+01,  ...,  6.0818e+00,\n",
      "            8.3097e+00,  1.1537e+01],\n",
      "          [-7.4568e+00, -8.9046e+00, -8.8681e+00,  ..., -6.9813e+00,\n",
      "           -4.9001e+00, -2.0772e+00],\n",
      "          [ 6.1443e+00,  5.3397e+00,  5.3257e+00,  ...,  2.9941e+00,\n",
      "            3.0127e+00,  3.5532e+00]]],\n",
      "\n",
      "\n",
      "        [[[-2.3892e+00, -1.0128e+01, -1.2990e+01,  ..., -4.0248e+00,\n",
      "            7.3079e-01, -6.0869e+01],\n",
      "          [-6.6501e+00, -1.8862e+01, -1.7387e+01,  ..., -3.1620e+00,\n",
      "           -9.0933e+00, -6.2282e+01],\n",
      "          [-1.0249e+01, -1.8964e+01, -8.2495e+00,  ..., -8.3623e+00,\n",
      "           -6.4771e+00, -6.3964e+01],\n",
      "          ...,\n",
      "          [-2.0894e+01, -2.8264e+01, -1.8053e+01,  ..., -8.0083e-01,\n",
      "            7.9693e+00, -8.7710e+01],\n",
      "          [-8.6745e+00, -2.0617e+01, -2.4620e+01,  ...,  2.3689e+01,\n",
      "            7.4750e+00, -9.9687e+01],\n",
      "          [-4.5098e+00, -5.6754e-01, -8.3739e+00,  ...,  1.2031e+01,\n",
      "           -6.8446e-01, -9.5326e+01]],\n",
      "\n",
      "         [[-6.3733e+00, -6.5929e+00, -3.9426e+00,  ..., -6.6515e+00,\n",
      "           -1.9005e+01, -2.1044e+01],\n",
      "          [-4.5804e+00, -5.3378e+00, -3.2964e+00,  ..., -2.9563e+00,\n",
      "           -1.2483e+01, -1.1668e+01],\n",
      "          [-7.3894e+00, -7.6361e+00, -5.2492e+00,  ..., -1.0789e+00,\n",
      "           -1.2526e+01, -1.1952e+01],\n",
      "          ...,\n",
      "          [-1.0611e+01, -1.1874e+01, -9.3770e+00,  ..., -8.5118e-01,\n",
      "           -1.1918e+01, -2.6940e+00],\n",
      "          [-2.8592e+00, -3.4854e+00, -2.4097e+00,  ...,  4.7974e+00,\n",
      "           -1.1921e+01, -4.5883e-01],\n",
      "          [-3.3144e+00, -4.3166e+00, -3.5401e+00,  ...,  7.3123e+00,\n",
      "           -1.1648e+01, -1.1073e+00]],\n",
      "\n",
      "         [[-2.1626e+01, -2.1973e+01, -2.3171e+01,  ..., -2.2568e+01,\n",
      "           -4.3292e+00, -3.4293e+01],\n",
      "          [-2.4982e+01, -2.4367e+01, -2.6395e+01,  ..., -1.7660e+01,\n",
      "           -4.2829e+00, -3.2945e+01],\n",
      "          [-1.8729e+01, -2.1661e+01, -2.1227e+01,  ..., -1.4898e+01,\n",
      "           -3.3164e+00, -3.3318e+01],\n",
      "          ...,\n",
      "          [-1.5647e+01, -1.7222e+01, -2.6945e+01,  ..., -1.0994e+01,\n",
      "           -6.1331e-01, -3.4705e+01],\n",
      "          [-1.0154e+01, -1.7058e+01, -2.1216e+01,  ..., -2.6276e+01,\n",
      "            3.0207e+00, -3.4076e+01],\n",
      "          [-1.4646e+01, -9.5058e+00, -1.0390e+01,  ..., -3.6527e+01,\n",
      "            1.4934e+00, -3.5976e+01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2922e+01, -1.2119e+01, -1.2859e+01,  ..., -3.9553e+00,\n",
      "           -7.6150e-01, -3.1525e+01],\n",
      "          [-1.4751e+01, -1.4720e+01, -1.7104e+01,  ..., -1.4932e+00,\n",
      "           -2.4568e+00, -3.2750e+01],\n",
      "          [-1.7520e+01, -1.7671e+01, -1.6458e+01,  ..., -2.9282e+00,\n",
      "            6.1048e-01, -3.5549e+01],\n",
      "          ...,\n",
      "          [-1.3023e+01, -1.3147e+01, -2.3360e+01,  ...,  8.4342e+00,\n",
      "           -6.4919e+00, -4.6480e+01],\n",
      "          [-1.9755e+01, -2.0717e+01, -2.4317e+01,  ...,  3.3107e+00,\n",
      "           -1.5994e+00, -4.3936e+01],\n",
      "          [-9.6558e+00, -8.8248e+00, -1.5611e+01,  ..., -1.3887e+00,\n",
      "            5.2714e-01, -4.0396e+01]],\n",
      "\n",
      "         [[ 1.3586e+01,  1.7043e+01,  1.6480e+01,  ...,  7.8643e+00,\n",
      "            1.5319e+01,  1.4170e+01],\n",
      "          [ 5.3339e+00,  8.1192e+00,  9.0561e+00,  ...,  7.1318e+00,\n",
      "            1.3941e+01,  1.1265e+01],\n",
      "          [-2.8335e-01,  2.4974e+00,  3.8815e+00,  ...,  9.8468e+00,\n",
      "            1.4845e+01,  1.1784e+01],\n",
      "          ...,\n",
      "          [ 7.4671e+00,  8.4237e+00,  8.4681e+00,  ...,  5.1447e+00,\n",
      "            9.3297e+00,  1.0268e+01],\n",
      "          [ 5.8968e+00,  7.1469e+00,  6.1256e+00,  ...,  1.3484e+01,\n",
      "            1.8858e+01,  1.3671e+01],\n",
      "          [ 1.0098e+01,  9.1370e+00,  8.0421e+00,  ...,  1.2709e+01,\n",
      "            1.9563e+01,  1.0755e+01]],\n",
      "\n",
      "         [[ 5.6658e+00,  8.7035e+00,  9.5954e+00,  ...,  1.5558e+01,\n",
      "            3.8573e+00,  9.1578e+00],\n",
      "          [ 5.2533e+00,  5.6318e+00,  2.9476e+00,  ...,  1.7157e+01,\n",
      "            1.1136e+00,  5.2943e+00],\n",
      "          [ 7.7170e+00,  6.6542e+00,  5.8079e+00,  ...,  1.4596e+01,\n",
      "           -2.2202e+00,  6.6364e+00],\n",
      "          ...,\n",
      "          [ 6.1318e+00, -1.4662e+00,  3.2018e-02,  ...,  1.9309e+01,\n",
      "            4.1090e+00,  1.4073e+01],\n",
      "          [ 2.0363e+01,  2.0661e+01,  1.8290e+01,  ...,  2.0968e+01,\n",
      "           -1.5514e-01,  7.1081e+00],\n",
      "          [ 1.3998e+01,  1.5008e+01,  1.9004e+01,  ...,  1.9787e+01,\n",
      "           -4.0506e+00,  1.7568e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.4085e+00,  2.0480e+01, -2.8863e+01,  ..., -7.8791e+00,\n",
      "           -2.2889e+01, -2.4882e+01],\n",
      "          [-9.3392e+00,  7.7663e+00, -2.3363e+01,  ..., -3.4116e+01,\n",
      "           -1.8667e+01, -1.1781e+01],\n",
      "          [-6.8745e+00, -1.7671e+01, -3.6992e+01,  ..., -2.3753e+01,\n",
      "           -5.3368e-02, -6.7490e+00],\n",
      "          ...,\n",
      "          [-2.5704e+01, -2.4314e+01, -2.4796e+01,  ..., -1.9400e+01,\n",
      "           -1.7701e+01, -2.3626e+01],\n",
      "          [ 1.2960e+00, -1.5805e+00, -2.3595e+00,  ..., -6.8243e+00,\n",
      "           -7.4169e+00, -1.8256e+01],\n",
      "          [-1.0008e+01, -1.1540e+01, -1.1540e+01,  ..., -1.1540e+01,\n",
      "           -1.1540e+01, -2.3015e+01]],\n",
      "\n",
      "         [[-7.1623e+00, -1.3181e+01, -1.7131e+01,  ..., -5.7805e+00,\n",
      "           -9.3094e+00, -1.8272e+01],\n",
      "          [ 1.1056e+00, -5.3072e+00, -1.1210e+01,  ..., -9.1686e+00,\n",
      "           -7.8718e+00, -1.6915e+01],\n",
      "          [-1.1742e+00, -5.6330e+00, -1.2170e+01,  ..., -1.3654e+01,\n",
      "           -6.4481e+00, -1.8312e+01],\n",
      "          ...,\n",
      "          [-1.8147e+01, -1.2375e+01, -1.2810e+01,  ..., -6.7980e+00,\n",
      "           -7.0516e+00, -1.6910e+01],\n",
      "          [-2.4841e+01, -2.1498e+01, -2.0602e+01,  ..., -1.2534e+01,\n",
      "           -1.2574e+01, -1.7522e+01],\n",
      "          [-1.0133e+01, -1.0067e+01, -1.0067e+01,  ..., -1.0067e+01,\n",
      "           -1.0067e+01, -1.3473e+01]],\n",
      "\n",
      "         [[-3.1865e+01, -1.8762e+01, -3.4519e+01,  ..., -2.1022e+01,\n",
      "           -1.1504e+01, -2.1587e+01],\n",
      "          [-3.9782e+01, -2.7508e+01, -3.1957e+01,  ..., -1.5913e+01,\n",
      "           -1.8029e+01, -2.3655e+01],\n",
      "          [-3.1392e+01, -3.4804e+01, -3.6680e+01,  ..., -1.8692e+01,\n",
      "           -2.1230e+01, -2.2065e+01],\n",
      "          ...,\n",
      "          [-4.9061e+01, -4.0093e+01, -3.6284e+01,  ..., -2.7038e+01,\n",
      "           -2.9584e+01, -2.9367e+01],\n",
      "          [-2.7706e+01, -2.6257e+01, -2.6202e+01,  ..., -2.5097e+01,\n",
      "           -2.5086e+01, -3.6784e+01],\n",
      "          [-2.7619e+01, -2.9944e+01, -2.9944e+01,  ..., -2.9944e+01,\n",
      "           -2.9944e+01, -3.8983e+01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.9227e+01, -1.6124e+00, -2.3241e+01,  ..., -4.8731e+00,\n",
      "           -2.6294e+00, -2.3180e+01],\n",
      "          [-2.2209e+01, -5.6260e+00, -1.1515e+01,  ..., -8.6192e+00,\n",
      "           -6.1951e+00, -2.5782e+01],\n",
      "          [-1.8719e+01, -1.7765e+01, -2.2026e+01,  ..., -1.2709e+01,\n",
      "           -1.4973e+01, -2.6986e+01],\n",
      "          ...,\n",
      "          [-1.3410e+01, -1.1988e+01, -1.0989e+01,  ..., -6.8635e+00,\n",
      "           -7.6054e+00, -2.1185e+01],\n",
      "          [-2.3118e+01, -1.7263e+01, -1.7300e+01,  ..., -1.3829e+01,\n",
      "           -1.4001e+01, -2.7063e+01],\n",
      "          [-2.5752e+01, -2.1431e+01, -2.1431e+01,  ..., -2.1431e+01,\n",
      "           -2.1431e+01, -3.2710e+01]],\n",
      "\n",
      "         [[ 4.2055e+00,  7.3038e+00,  5.5639e+00,  ...,  6.7041e+00,\n",
      "            7.5662e+00,  7.2744e+00],\n",
      "          [ 1.1696e+00,  1.0056e+01,  9.0532e+00,  ...,  1.1904e+01,\n",
      "            6.4923e+00,  7.0124e+00],\n",
      "          [ 5.4815e-01,  6.0719e+00,  4.4597e+00,  ...,  8.0273e+00,\n",
      "            3.7465e+00,  8.4546e+00],\n",
      "          ...,\n",
      "          [ 2.0863e+01,  2.1570e+01,  2.2262e+01,  ...,  1.6813e+01,\n",
      "            1.6356e+01,  1.9327e+01],\n",
      "          [ 2.0790e+01,  2.6199e+01,  2.6265e+01,  ...,  2.2292e+01,\n",
      "            2.1306e+01,  2.0263e+01],\n",
      "          [ 1.3681e+01,  1.7632e+01,  1.7632e+01,  ...,  1.7632e+01,\n",
      "            1.7632e+01,  1.5952e+01]],\n",
      "\n",
      "         [[ 4.6375e+00,  6.1122e+00,  1.8504e+01,  ...,  1.5887e+01,\n",
      "            7.0519e+00,  2.3824e+00],\n",
      "          [ 5.8058e+00,  6.7820e+00,  1.3587e+01,  ...,  5.5193e+00,\n",
      "           -1.2366e+00, -2.2742e+00],\n",
      "          [ 8.5065e+00,  1.1025e+01,  9.8660e+00,  ...,  5.0821e-01,\n",
      "            3.4981e+00,  2.1058e+00],\n",
      "          ...,\n",
      "          [-6.9227e+00, -9.3349e+00, -9.0460e+00,  ..., -2.2929e+00,\n",
      "           -2.6083e+00, -1.1504e+00],\n",
      "          [ 7.8093e+00,  8.1789e+00,  7.9168e+00,  ...,  6.2399e+00,\n",
      "            6.0767e+00,  7.4120e+00],\n",
      "          [ 1.4408e+00, -2.5982e+00, -2.5982e+00,  ..., -2.5982e+00,\n",
      "           -2.5982e+00, -2.5006e+00]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-2.7053e+01, -1.5310e+01, -2.4034e+00,  ..., -3.2031e+01,\n",
      "           -2.0448e+01, -8.0228e+01],\n",
      "          [-2.0969e+01, -2.2472e+01,  2.5896e+00,  ..., -1.0663e+01,\n",
      "            2.1630e+00, -7.8777e+01],\n",
      "          [-1.7232e+01, -2.1362e+01, -1.0880e+01,  ..., -5.7296e+00,\n",
      "            5.6439e+00, -7.8450e+01],\n",
      "          ...,\n",
      "          [-2.0374e+01, -1.4733e+01, -1.0540e+01,  ..., -2.9199e+00,\n",
      "            7.3455e-01, -8.1309e+01],\n",
      "          [-1.9435e+01, -1.7688e+01, -1.6228e+01,  ..., -4.7526e+00,\n",
      "           -2.7226e-01, -8.2080e+01],\n",
      "          [-1.6319e+01, -1.5468e+01, -9.6445e+00,  ..., -2.3056e+00,\n",
      "            6.9691e+00, -8.9269e+01]],\n",
      "\n",
      "         [[ 7.7394e+00,  1.0619e+01,  1.0116e+01,  ...,  3.2266e+00,\n",
      "           -1.7193e+01, -1.9093e+01],\n",
      "          [-2.4258e+00,  2.6673e+00,  2.2635e+00,  ..., -8.8561e+00,\n",
      "           -1.4779e+01, -1.3577e+01],\n",
      "          [-2.9897e+00, -5.0283e-01,  2.7469e-01,  ..., -7.0572e+00,\n",
      "           -1.4681e+01, -1.2388e+01],\n",
      "          ...,\n",
      "          [-1.4832e+00, -2.4776e+00, -2.4969e+00,  ..., -5.5243e-01,\n",
      "           -1.2355e+01, -5.2967e+00],\n",
      "          [-1.6771e+00, -1.5518e+00, -1.7491e+00,  ..., -3.7152e-02,\n",
      "           -1.3405e+01, -5.2945e+00],\n",
      "          [-3.9423e+00, -2.8563e+00, -3.0156e+00,  ...,  9.9402e-01,\n",
      "           -1.3486e+01, -1.8376e+00]],\n",
      "\n",
      "         [[-5.5290e+01, -5.1831e+01, -4.0575e+01,  ..., -1.4190e+01,\n",
      "            9.8072e+00, -3.8587e+01],\n",
      "          [-3.6282e+01, -4.6444e+01, -3.9922e+01,  ..., -8.5849e+00,\n",
      "           -1.6775e+00, -4.4442e+01],\n",
      "          [-2.4405e+01, -3.4343e+01, -3.8729e+01,  ..., -1.8043e+01,\n",
      "           -4.0503e+00, -4.4903e+01],\n",
      "          ...,\n",
      "          [-2.2870e+01, -2.1497e+01, -2.2565e+01,  ..., -2.3576e+01,\n",
      "           -3.9742e-01, -3.4363e+01],\n",
      "          [-2.3543e+01, -2.4526e+01, -2.6040e+01,  ..., -2.1987e+01,\n",
      "            6.9601e-01, -3.4446e+01],\n",
      "          [-2.1372e+01, -1.9965e+01, -2.2905e+01,  ..., -1.9468e+01,\n",
      "            2.8287e+00, -3.3865e+01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.0404e+01, -1.8654e+01, -8.3300e+00,  ..., -1.6353e+01,\n",
      "            7.7506e+00, -1.8579e+01],\n",
      "          [-8.2557e+00, -2.3366e+01, -1.1194e+01,  ..., -1.2053e+01,\n",
      "            4.6409e+00, -2.5040e+01],\n",
      "          [-4.7140e+00, -1.4880e+01, -1.5539e+01,  ..., -1.1536e+01,\n",
      "            9.0360e+00, -2.3993e+01],\n",
      "          ...,\n",
      "          [-7.0920e+00, -1.0790e+01, -1.0146e+01,  ..., -4.4625e+00,\n",
      "           -4.7536e+00, -4.0041e+01],\n",
      "          [-8.3576e+00, -1.2575e+01, -1.0734e+01,  ..., -4.5583e+00,\n",
      "           -3.9533e+00, -4.0230e+01],\n",
      "          [-4.5415e+00, -8.6988e+00, -7.6091e+00,  ..., -1.4994e+00,\n",
      "           -2.6985e+00, -4.4067e+01]],\n",
      "\n",
      "         [[ 7.6460e+00,  9.2654e+00,  1.3854e+01,  ...,  3.2090e+01,\n",
      "            3.6855e+01,  2.3804e+01],\n",
      "          [ 5.3741e+00,  4.2705e+00,  1.2430e+01,  ...,  4.4304e+01,\n",
      "            4.2699e+01,  2.5428e+01],\n",
      "          [ 6.7373e+00,  2.5762e+00,  6.5444e+00,  ...,  4.5544e+01,\n",
      "            4.3181e+01,  2.4511e+01],\n",
      "          ...,\n",
      "          [ 5.3796e+00,  3.4892e+00,  3.5794e+00,  ...,  5.3569e+00,\n",
      "            1.2536e+01,  1.0180e+01],\n",
      "          [ 5.7322e+00,  3.1564e+00,  3.8064e+00,  ...,  5.3277e+00,\n",
      "            1.2858e+01,  1.0394e+01],\n",
      "          [ 5.4390e+00,  2.9970e+00,  3.3893e+00,  ...,  6.1759e+00,\n",
      "            1.4586e+01,  9.3135e+00]],\n",
      "\n",
      "         [[ 5.0372e+00,  1.0611e+00, -3.0541e+00,  ..., -1.3157e+00,\n",
      "           -2.2358e+01, -6.1733e+00],\n",
      "          [ 1.2336e+01,  1.6138e+01,  1.2106e+01,  ...,  3.4228e+00,\n",
      "           -1.0591e+01,  3.3215e+00],\n",
      "          [ 1.1729e+01,  1.5692e+01,  1.7474e+01,  ...,  3.1137e+00,\n",
      "           -1.3954e+01, -1.4181e-01],\n",
      "          ...,\n",
      "          [ 8.1563e+00,  7.5101e+00,  1.0453e+01,  ...,  2.1391e+01,\n",
      "           -2.6360e+00,  4.8950e+00],\n",
      "          [ 1.1956e+01,  1.1798e+01,  9.5785e+00,  ...,  2.1855e+01,\n",
      "           -4.0987e+00,  4.8886e+00],\n",
      "          [ 9.8114e+00,  1.1524e+01,  1.0832e+01,  ...,  2.0801e+01,\n",
      "            1.0758e+00,  7.6203e+00]]],\n",
      "\n",
      "\n",
      "        [[[-3.1660e+00, -1.8376e+01, -9.7658e+00,  ...,  5.1839e+00,\n",
      "           -4.9768e+01, -1.0244e+01],\n",
      "          [-1.7048e+01, -3.1486e+01, -1.6792e+01,  ...,  4.8920e+00,\n",
      "           -5.8259e+01, -1.5884e+01],\n",
      "          [-1.6333e+01, -2.0332e+01, -1.3564e+01,  ...,  4.9603e+00,\n",
      "           -6.3883e+01, -1.6293e+01],\n",
      "          ...,\n",
      "          [-1.5568e+01, -8.0252e+00, -1.7119e+01,  ..., -1.1940e+00,\n",
      "           -7.9298e+01, -1.5759e+01],\n",
      "          [-1.4553e+01, -1.3398e+01, -1.3737e+01,  ..., -9.8491e-01,\n",
      "           -7.9690e+01, -1.5430e+01],\n",
      "          [-1.1248e+01, -9.5803e+00, -4.8095e+00,  ...,  5.4237e+00,\n",
      "           -8.4546e+01, -2.2634e+01]],\n",
      "\n",
      "         [[-3.7128e+00, -1.0686e+00,  7.3339e-01,  ..., -1.7522e+01,\n",
      "           -1.4398e+01, -2.7629e+01],\n",
      "          [ 1.2836e-01,  1.7464e+00,  2.1017e+00,  ..., -1.2047e+01,\n",
      "           -3.7337e+00, -1.8984e+01],\n",
      "          [ 1.5235e+00,  1.8474e+00,  4.0452e+00,  ..., -1.1497e+01,\n",
      "           -2.4974e+00, -1.9030e+01],\n",
      "          ...,\n",
      "          [ 5.8312e+00,  4.0577e+00,  4.3081e+00,  ..., -1.3872e+01,\n",
      "            1.2918e+00, -1.9093e+01],\n",
      "          [ 5.4520e+00,  5.0549e+00,  5.4959e+00,  ..., -1.3954e+01,\n",
      "            1.0983e+00, -1.8968e+01],\n",
      "          [ 5.8233e+00,  7.9573e+00,  8.5938e+00,  ..., -1.2530e+01,\n",
      "            2.6933e+00, -1.3859e+01]],\n",
      "\n",
      "         [[-1.6605e+01, -2.3801e+01, -3.2776e+01,  ..., -3.3248e+00,\n",
      "           -2.2724e+01, -3.8306e+01],\n",
      "          [-2.0510e+01, -2.9711e+01, -2.7930e+01,  ..., -3.7538e+00,\n",
      "           -2.3912e+01, -3.7882e+01],\n",
      "          [-2.2592e+01, -2.7846e+01, -3.2390e+01,  ..., -1.5009e+00,\n",
      "           -2.3335e+01, -3.8040e+01],\n",
      "          ...,\n",
      "          [-2.9539e+01, -2.4103e+01, -2.3525e+01,  ..., -1.8040e+00,\n",
      "           -3.0348e+01, -3.9118e+01],\n",
      "          [-3.0256e+01, -2.4354e+01, -2.6215e+01,  ..., -1.2126e+00,\n",
      "           -3.0022e+01, -3.9003e+01],\n",
      "          [-3.0315e+01, -2.5549e+01, -2.6689e+01,  ...,  3.7069e+00,\n",
      "           -2.8388e+01, -3.7743e+01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.0881e+01, -1.9232e+01, -1.8959e+01,  ..., -1.3963e-01,\n",
      "           -2.0761e+01, -3.6256e+01],\n",
      "          [-8.9773e+00, -1.7124e+01, -1.6189e+01,  ..., -2.2692e+00,\n",
      "           -2.4652e+01, -3.4737e+01],\n",
      "          [-5.5753e+00, -1.3234e+01, -1.8266e+01,  ..., -1.8375e+00,\n",
      "           -2.5145e+01, -3.4546e+01],\n",
      "          ...,\n",
      "          [-3.9987e+00, -1.0483e+01, -1.2055e+01,  ..., -5.1320e+00,\n",
      "           -2.9227e+01, -3.5110e+01],\n",
      "          [-6.1793e+00, -1.3508e+01, -1.1145e+01,  ..., -5.3081e+00,\n",
      "           -2.9036e+01, -3.5567e+01],\n",
      "          [-3.1371e+00, -7.9989e+00, -6.4989e+00,  ..., -2.6694e+00,\n",
      "           -3.3670e+01, -3.9422e+01]],\n",
      "\n",
      "         [[ 1.9820e+00, -9.5042e-01, -1.9390e+00,  ...,  1.3169e+01,\n",
      "            1.3050e+01,  1.7122e+01],\n",
      "          [ 8.5865e+00,  3.1400e+00,  3.2888e+00,  ...,  1.3248e+01,\n",
      "            1.0315e+01,  1.4074e+01],\n",
      "          [ 1.1921e+01,  5.1313e+00,  4.8442e+00,  ...,  1.4888e+01,\n",
      "            1.1276e+01,  1.4212e+01],\n",
      "          ...,\n",
      "          [ 1.8214e+01,  1.3245e+01,  1.1173e+01,  ...,  1.6601e+01,\n",
      "            1.2091e+01,  1.2768e+01],\n",
      "          [ 1.7874e+01,  1.3455e+01,  1.1630e+01,  ...,  1.6267e+01,\n",
      "            1.1709e+01,  1.2568e+01],\n",
      "          [ 1.8815e+01,  1.3562e+01,  1.2726e+01,  ...,  1.7758e+01,\n",
      "            1.1559e+01,  1.0107e+01]],\n",
      "\n",
      "         [[ 1.3851e+01,  1.6961e+01,  1.7544e+01,  ..., -2.2308e+00,\n",
      "            5.6904e+00,  1.0187e+01],\n",
      "          [ 9.2656e+00,  7.8820e+00,  8.5614e+00,  ..., -3.3709e+00,\n",
      "            4.5503e+00,  5.9520e+00],\n",
      "          [ 8.2411e+00,  9.2699e+00,  1.3778e+01,  ..., -3.6460e+00,\n",
      "            3.9536e+00,  6.0549e+00],\n",
      "          ...,\n",
      "          [ 1.0849e+01,  1.2346e+01,  1.2964e+01,  ..., -2.9146e+00,\n",
      "            2.0421e+00,  6.2361e+00],\n",
      "          [ 1.0528e+01,  1.2241e+01,  1.1372e+01,  ..., -2.8701e+00,\n",
      "            1.6104e+00,  6.2099e+00],\n",
      "          [ 1.4463e+01,  1.5943e+01,  1.6394e+01,  ...,  1.5933e+00,\n",
      "            6.7375e+00,  3.5369e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4824e+00, -1.0567e+00, -1.0567e+00,  ..., -1.0567e+00,\n",
      "           -1.0567e+00, -1.3692e+01],\n",
      "          [-5.6058e+00, -9.5930e+00, -9.5625e+00,  ..., -1.0020e+01,\n",
      "           -1.0130e+01, -2.1184e+01],\n",
      "          [-6.6099e+00, -1.0143e+01, -1.0130e+01,  ..., -1.0862e+01,\n",
      "           -1.0322e+01, -1.9992e+01],\n",
      "          ...,\n",
      "          [-1.5127e+01, -1.8900e+01, -1.3489e+01,  ..., -1.6480e+01,\n",
      "           -2.2855e+00, -4.7148e+00],\n",
      "          [-2.1006e+01, -2.1766e+01, -1.8333e+01,  ..., -9.5482e+00,\n",
      "            6.2718e-01, -2.4703e+00],\n",
      "          [-1.0537e+01, -1.0682e+01, -7.7490e+00,  ..., -8.0211e+00,\n",
      "            6.7735e-01, -3.6394e+00]],\n",
      "\n",
      "         [[-2.3044e+01, -2.0147e+01, -2.0147e+01,  ..., -2.0147e+01,\n",
      "           -2.0147e+01, -2.5011e+01],\n",
      "          [-1.2761e+01, -1.0004e+01, -9.9671e+00,  ..., -1.0091e+01,\n",
      "           -9.8011e+00, -1.5593e+01],\n",
      "          [-1.2416e+01, -9.4345e+00, -9.2214e+00,  ..., -9.2549e+00,\n",
      "           -8.3427e+00, -1.4636e+01],\n",
      "          ...,\n",
      "          [ 4.0523e+00,  5.0401e+00,  5.2574e+00,  ...,  3.4894e+00,\n",
      "            6.4760e+00, -2.1455e+01],\n",
      "          [-4.1708e+00, -2.3482e+00, -4.3468e+00,  ...,  4.6440e+00,\n",
      "            6.0265e+00, -2.1179e+01],\n",
      "          [-1.3418e+01, -1.0616e+01, -9.3374e+00,  ...,  4.7997e+00,\n",
      "            7.5330e+00, -1.9196e+01]],\n",
      "\n",
      "         [[-2.7103e+01, -2.5599e+01, -2.5599e+01,  ..., -2.5599e+01,\n",
      "           -2.5599e+01, -3.7410e+01],\n",
      "          [-2.8245e+01, -2.7168e+01, -2.7084e+01,  ..., -2.7306e+01,\n",
      "           -2.7325e+01, -3.7536e+01],\n",
      "          [-2.8627e+01, -2.6739e+01, -2.6804e+01,  ..., -2.5652e+01,\n",
      "           -2.5579e+01, -3.6913e+01],\n",
      "          ...,\n",
      "          [-3.2548e+01, -3.1041e+01, -3.4152e+01,  ..., -3.1540e+01,\n",
      "           -3.1498e+01, -1.2129e+00],\n",
      "          [-3.4029e+01, -3.1474e+01, -2.8603e+01,  ..., -2.8976e+01,\n",
      "           -3.0341e+01, -1.6744e+00],\n",
      "          [-2.6237e+01, -2.2874e+01, -2.2521e+01,  ..., -2.6070e+01,\n",
      "           -2.6232e+01,  3.0545e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.2133e+01, -1.6237e+01, -1.6237e+01,  ..., -1.6237e+01,\n",
      "           -1.6237e+01, -2.9530e+01],\n",
      "          [-2.2256e+01, -1.6016e+01, -1.5652e+01,  ..., -1.6911e+01,\n",
      "           -1.6898e+01, -2.8050e+01],\n",
      "          [-2.1742e+01, -1.5248e+01, -1.5549e+01,  ..., -1.5893e+01,\n",
      "           -1.4601e+01, -2.6588e+01],\n",
      "          ...,\n",
      "          [-4.2857e+00, -1.0246e+01, -1.1213e+01,  ..., -1.4967e+01,\n",
      "           -7.2716e+00, -9.4752e+00],\n",
      "          [-5.6043e-01, -1.2184e+01, -1.0548e+01,  ..., -1.2261e+01,\n",
      "           -8.1735e+00, -9.0114e+00],\n",
      "          [-2.2275e+00, -1.0604e+01, -1.1165e+01,  ..., -6.4932e+00,\n",
      "           -3.7284e+00, -1.1456e+01]],\n",
      "\n",
      "         [[ 1.8525e+01,  2.3442e+01,  2.3442e+01,  ...,  2.3442e+01,\n",
      "            2.3442e+01,  2.2484e+01],\n",
      "          [ 1.4154e+01,  1.8011e+01,  1.7890e+01,  ...,  1.7916e+01,\n",
      "            1.7828e+01,  1.7683e+01],\n",
      "          [ 1.2618e+01,  1.6487e+01,  1.6352e+01,  ...,  1.5606e+01,\n",
      "            1.5374e+01,  1.5861e+01],\n",
      "          ...,\n",
      "          [ 1.4990e+01,  9.9592e+00,  9.1030e+00,  ...,  9.5150e+00,\n",
      "            1.1930e+01,  2.0058e+01],\n",
      "          [ 1.0123e+01,  4.3258e+00,  4.4026e+00,  ...,  1.2730e+01,\n",
      "            1.5269e+01,  2.2876e+01],\n",
      "          [ 6.6473e+00,  1.8967e+00,  2.5088e+00,  ...,  1.3256e+01,\n",
      "            1.4151e+01,  2.0960e+01]],\n",
      "\n",
      "         [[ 7.1448e+00,  7.8230e+00,  7.8230e+00,  ...,  7.8230e+00,\n",
      "            7.8230e+00,  1.0606e+01],\n",
      "          [ 2.7550e+00, -1.2488e-01, -2.4608e-01,  ..., -4.7058e-01,\n",
      "           -7.9950e-01,  1.3424e+00],\n",
      "          [ 3.9730e+00,  9.2949e-01,  6.5945e-01,  ...,  8.4274e-01,\n",
      "            3.4876e-01,  1.3831e+00],\n",
      "          ...,\n",
      "          [ 8.6238e+00,  8.5796e+00,  9.7038e+00,  ...,  4.3150e+00,\n",
      "            1.7381e+01, -8.4779e+00],\n",
      "          [ 8.1420e+00,  9.7481e+00,  9.5067e+00,  ...,  1.3835e+01,\n",
      "            2.5568e+01, -5.2382e-01],\n",
      "          [ 1.5427e+01,  1.7399e+01,  1.7417e+01,  ...,  1.4091e+01,\n",
      "            2.4044e+01,  6.4085e-01]]]], device='cuda:0',\n",
      "       grad_fn=<CudnnConvolutionBackward>)\n"
     ]
    }
   ],
   "source": [
    "#### input floating number / weight floating number version\n",
    "\n",
    "conv_ref = torch.nn.Conv2d(in_channels = 16, out_channels=16, kernel_size = 3, bias = False)\n",
    "#weight = model.features[3].weight\n",
    "#mean = weight.data.mean()\n",
    "#std = weight.data.std()\n",
    "#conv_ref.weight = torch.nn.parameter.Parameter(weight.add(-mean).div(std))\n",
    "conv_ref.weight = torch.nn.parameter.Parameter(weight_q)\n",
    "output_ref = conv_ref(x)\n",
    "print(output_ref)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "significant-whole",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.9977, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "difference = abs( output_ref - output_recovered )\n",
    "print(difference.mean()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corresponding-significance",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exposed-witch",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entitled-barbados",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minimal-serbia",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
